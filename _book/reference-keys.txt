eq:additiveModel
eq:huberLoss
fig:lossComp
eq:treeDef
fig:exampleAdditiveTree
eq:oneStepTreeBoost
eq:numOptSol
eq:oneStepTreeBoostnew
eq:gammaLineSearch
tab:lossGradients
eq:shrinkage
eq:regLoss
eq:oneStepXGBoost
eq:oneappStepXGBoost
tab:xgboostHyper
prerequisites
intro
theory
the-powerful-idea-of-gradient-boosting
forward-stagewise-additive-modeling
robust-loss-functions-for-regression
general-gradient-tree-boosting
numOpt
single-tree-depth
combOver
shrinkage
subsampling
xgboost-a-highly-efficient-implementation
regularized-loss
shrinkage-and-subsampling
even-more-tweaks
hyperparameters-overview
eda
burnout-data
train-test-split
visualize-the-data
create-recipe
modeling
conclusion
references
