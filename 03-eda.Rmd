# Explore the data {#eda}

Before one starts with the actual modeling it is crucial to get to know the data and to bring it to the correct format. This process of getting familiar with the data is well known as Exploratory Data Analysis (EDA). To do this many packages are used.[@tidyverse; @tidymodels; @viridis; @ggtext; @viridisLite ; @patchwork; @visdat] The most important ones will be loaded below.

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse) # general data handling tools
library(tidymodels) # data modeling and preprocessing
# color palettes
library(viridis)
library(viridisLite)
library(patchwork) # composing of ggplots
```

## Burnout data

The data is from the machine learning challenge bla from Kaggle. <https://www.kaggle.com/blurredmachine/are-your-employees-burning-out?select=train.csv>

```{r loadBurn, message=FALSE}
burnout_data <- read_csv("_data/burn_out_train.csv")
colnames(burnout_data) <- tolower(
  stringr::str_replace_all(
    colnames(burnout_data),
    " ",
    "_"
  ))
# omit missing values in the outcome variable
burnout_data <- burnout_data[!is.na(burnout_data$burn_rate),]
```

### Train-test split

```{r traintest}
set.seed(2)
burnout_split <- rsample::initial_split(burnout_data, prop = 0.80)
burnout_train <- rsample::training(burnout_split)
burnout_test  <- rsample::testing(burnout_split)
```

```{r, include=FALSE}
remove(burnout_data)
remove(burnout_split)
```

The training data set contains `r nrow(burnout_train)` rows and `r ncol(burnout_train)` variables.

The test data set contains `r nrow(burnout_test)` observations and naturally also `r ncol(burnout_test)` variables.

First look at the classes of the variables.

```{r, echo=FALSE}
col_classes_burn <- burnout_train %>%
  summarise_all(class)
knitr::kable(
  data.frame(column = colnames(burnout_train),
             class = as.character(col_classes_burn[1, ]))
)
```

A general visualization to detect missing values.

```{r visdat, echo=FALSE}
visdat::vis_dat(burnout_train)
```

```{r}
# percentage of missing values in the training data set
mean(rowSums(is.na(burnout_train)) > 0)
```
As we know that XGBoost can handle missing values we do not have to be concerned. Although one can think about imputation. But more on that later.

What about the outcome variable?

`burn_rate`: For each employee telling the rate of burnout should be in $[0,1]$. The greater the score the worse the burnout. As the variable is continuous we have a regression task.

The five point summary below shows that the full range is covered and no not allowed values are in the data.

```{r, echo=FALSE}
summary(burnout_train$burn_rate)
```


```{r , echo=FALSE}
burn_rate_box <- ggplot(burnout_train, aes(x = 1, y = burn_rate)) +
  geom_jitter(alpha = 0.05, col = plasma(1)) +
  geom_boxplot(col = "black", size = .8, fill = NA) +
  labs(x = "", y = "Burn rate") +
  coord_flip() +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank())


burn_rate_hist <- ggplot(burnout_train, aes(x = burn_rate)) +
  geom_histogram(fill = plasma(1), binwidth = 0.05) +
  labs(x = "", y = "", subtitle = "binwidth = 0.05",
       title = "Outcome variable: **Burn Rate**") +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))
burn_rate_hist / burn_rate_box
remove(burn_rate_box)
remove(burn_rate_hist)
```

The distribution of the outcome is very much symmetrical and bell shaped around 0.5 and the whole defined region $[0,1]$ is quite well covered.


Look at every feature and its main effects individually:

`employee_id` is just an ID variable and thus is not useful for any prediction model. But one has to check for duplicates.

```{r}
burnout_train %>%
  group_by(employee_id) %>%
  summarise(n = n()) %>%
  nrow() == nrow(burnout_train)
```
Thus there are no duplicates which is good.

`date_of_joining` is the Date the employee has joined the company. Thus a continuous variable that most likely needs some kind of feature engineering.

```{r, echo=FALSE}
burnout_train %>%
  group_by(date_of_joining) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = date_of_joining, y = count)) +
  geom_line(col = plasma(1), na.rm = TRUE) +
  theme_light() +
  labs(title = "Distribution of the variable **Date of joining**",
       x = "Date of joining") +
  theme(plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))
```

Although there is a lot of variation no major trends in hirings are visible from this plot. Overall the variable seems to be quite equally distributed over the year 2008.


```{r echo=FALSE}
ggplot(burnout_train,
       aes(y = date_of_joining,
           x = burn_rate)) +
  geom_point(alpha = 0.1, col = plasma(1),
             na.rm = TRUE) +
  labs(y = "Date of joining", x = "Burn rate",
       title = "Main effect of variable **Date of joining**") +
  theme_light() +
  theme(legend.position = "None",
        plot.title = ggtext::element_markdown(size = 11))
```
In its raw form the variable `date_of_joining` seems not to have a notable main effect on the outcome variable. Nevertheless the feature will be used in the model and as tree-based model have an in-built feature selection one can see after the fitting if the feature was helpful overall. The feature will not be included just as an integer (the default format how Dates are represented) but rather some more features like weekday or month will be extracted from the raw variable further down the road.

`gender` represents the gender of the employee. Definitely a categorical variable.

```{r}
# have a look at the discrete distribution
summary(factor(burnout_train$gender))
```

The two classes are well balanced. Now a look at the main effect of the feature.

```{r echo=FALSE}
gender_burn_rate_box <- ggplot(burnout_train,
                               aes(x = as.factor(gender),
                                   y = burn_rate,
                                   col = as.factor(gender))) +
  geom_jitter(alpha = 0.05) +
  geom_boxplot(size = 0.8, col = "black", fill = NA) +
  labs(x = "", y = "Burn rate", col = "") +
  scale_color_viridis_d(option = "C") +
  coord_flip() +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "None",
        axis.text.y = element_blank())

gender_burn_rate_hist <- ggplot(burnout_train,
                                aes(x = burn_rate,
                                    fill = as.factor(gender))) +
  geom_histogram(binwidth = 0.05, alpha = 0.7,
                 position = "identity") +
  scale_fill_viridis_d(option = "C") +
  labs(x = "", y = "", subtitle = "binwidth = 0.05",
       fill = "",title = "Main effect of variable **gender**") +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank(),
        plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))

gender_burn_rate_hist / gender_burn_rate_box
remove(gender_burn_rate_hist)
remove(gender_burn_rate_box)
```

For both classes the distributions are very similar and symmetrical. It seems like the male employees have overall a slightly higher risk of having a higher burn score i.e. a burnout.



`company_type` is a binary categorical variable that indicates whether the company is a service or product company.

```{r}
# have a look at the discrete distribution
summary(factor(burnout_train$company_type))
```
In this case the classes are not fully balanced but each class is still well represented. Now a look at the main effect of the feature.

```{r echo=FALSE}
comptype_burn_rate_box <- ggplot(burnout_train,
                               aes(x = as.factor(company_type),
                                   y = burn_rate,
                                   col = as.factor(company_type))) +
  geom_jitter(alpha = 0.05) +
  geom_boxplot(size = 0.8, col = "black", fill = NA) +
  labs(x = "", y = "Burn rate", col = "") +
  scale_color_viridis_d(option = "C") +
  coord_flip() +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "None",
        axis.text.y = element_blank())

comptype_burn_rate_hist <- ggplot(burnout_train,
                                aes(x = burn_rate,
                                    fill = as.factor(company_type))) +
  geom_histogram(binwidth = 0.05, alpha = 0.6,
                 position = "identity") +
  scale_fill_viridis_d(option = "C") +
  labs(x = "", y = "", subtitle = "binwidth = 0.05",
       fill = "",title = "Main effect of variable **Company Type**") +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank(),
        plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))

comptype_burn_rate_hist / comptype_burn_rate_box
remove(comptype_burn_rate_hist)
remove(comptype_burn_rate_box)
```

For both classes the distributions are almost identical and symmetrical. From an univariate point of view no notable main effect is visible from these visualizations. 


`wfh_setup_available` indicates whether a working from home setup is available for the employee. So this is again a binary variable.

```{r}
# have a look at the discrete distribution
summary(factor(burnout_train$wfh_setup_available))
```

The two classes are well balanced. Now a look at the main effect of the feature.

```{r echo=FALSE}
wfh_burn_rate_box <- ggplot(burnout_train,
                               aes(x = as.factor(wfh_setup_available),
                                   y = burn_rate,
                                   col = as.factor(wfh_setup_available))) +
  geom_jitter(alpha = 0.05) +
  geom_boxplot(size = 0.8, col = "black", fill = NA) +
  labs(x = "", y = "Burn rate", col = "") +
  scale_color_viridis_d(option = "C") +
  coord_flip() +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "None",
        axis.text.y = element_blank())

wfh_burn_rate_hist <- ggplot(burnout_train,
                                aes(x = burn_rate,
                                    fill = as.factor(wfh_setup_available))) +
  geom_histogram(binwidth = 0.05, alpha = 0.6,
                 position = "identity") +
  scale_fill_viridis_d(option = "C") +
  labs(x = "", y = "", subtitle = "binwidth = 0.05",
       fill = "",title = "Main effect of variable **Work from home setup**") +
  theme_light() +
  theme(axis.ticks.y = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank(),
        plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))

wfh_burn_rate_hist / wfh_burn_rate_box
remove(wfh_burn_rate_hist)
remove(wfh_burn_rate_box)
```
Again both distributions are quite similar i.e. bell shaped and symmetrical. Here quite a main effect is visible. A work from home setup most likely has a positive influence on the wellbeing and thus lowers the risk for a high burn rate.


`designation` A rate within $[0,5]$ that represents the designation in the company for the employee. High values indicate a greater amount of designation.

```{r}
# unique values of the feature
unique(burnout_train$designation)
```
As the feature has a natural encoding this variable will be treated as an ordinal one i.e. be encoded with the integers and not by one-hot-encoding.

```{r, echo=FALSE}
burnout_train %>%
  group_by(designation) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = factor(designation), y = count)) +
  geom_bar(fill = plasma(1), stat = "identity") +
  coord_flip() +
  theme_light() +
  labs(title = "Distribution of the variable **Designation**",
       x = "level of designation") +
  theme(plot.title = ggtext::element_markdown(size = 11))
```

```{r echo=FALSE}
ggplot(burnout_train,
       aes(x = as.factor(designation),
           y = burn_rate,
           col = as.factor(designation))) +
  geom_jitter(alpha = 0.1) +
  geom_boxplot(size = 0.8, col = "black", fill = NA) +
  labs(x = "level of designation", y = "Burn rate", col = "",
       title = "Main effect of variable **Designation**") +
  scale_color_viridis_d(option = "C") +
  coord_flip() +
  theme_light() +
  theme(legend.position = "None",
        plot.title = ggtext::element_markdown(size = 11))
```

A strong main effect is visible in the plot. The plot also further strengthens the hypothesis that we should treat the feature as ordinal. A higher level of designation seems to have an influence on the risk of having a burnout.


`resource_allocation` A rate within $[1,10]$ that represents the resource allocation to the employee. High values indicate more resources allocated to the employee.

```{r}
# unique values of the feature
unique(burnout_train$resource_allocation)
```
Here again the question is whether one should encode this variable as a categorical or an ordinal categorical feature. In this case as there are quite some levels and again a natural ordering the variable will be used as a continuous integer score.

```{r, echo=FALSE}
burnout_train %>%
  group_by(resource_allocation) %>%
  summarize(count = n()) %>%
  ggplot(aes(x = factor(resource_allocation), y = count)) +
  geom_bar(fill = plasma(1), stat = "identity") +
  coord_flip() +
  theme_light() +
  labs(title = "Distribution of the variable **Resource Allocation**",
       x = "Resource Allocation") +
  theme(plot.title = ggtext::element_markdown(size = 11))
```

```{r echo=FALSE}
burnout_train %>%
  mutate(resource_allocation = as.character(resource_allocation),
         resource_allocation = if_else(is.na(resource_allocation),
                                       "NA",
                                       resource_allocation),
         resource_allocation = as_factor(resource_allocation),
         resource_allocation = fct_relevel(resource_allocation,
                                           c("NA", paste(1:10)))) %>%
  ggplot(
       aes(x = resource_allocation,
           y = burn_rate,
           col = resource_allocation)) +
  geom_jitter(alpha = 0.1, na.rm = TRUE) +
  geom_boxplot(size = 0.8, col = "black", fill = NA, na.rm = TRUE) +
  labs(x = "Resource Allocation", y = "Burn rate", col = "",
       title = "Main effect of variable **Resource Allocation**") +
  scale_color_viridis_d(option = "C") +
  coord_flip() +
  theme_light() +
  theme(legend.position = "None",
        plot.title = ggtext::element_markdown(size = 11))
```
A strong main effect is visible in the plot. The plot again further strengthens the hypothesis that we should treat this feature as ordinal. A higher amount of resources assigned to an employee seems to have a positive influence on the risk of having a burnout.

`mental_fatigue_score` is the level of mental fatigue the employee is facing.

```{r}
# number of unique values
length(unique(burnout_train$mental_fatigue_score)) 
```
This variable will be treated in a continuous way.

```{r, echo=FALSE}
ggplot(burnout_train, aes(x = mental_fatigue_score)) +
  geom_density(fill = plasma(1), col = plasma(1),
               na.rm = TRUE, bw = .8) +
  theme_light() +
  labs(title = "Distribution of the variable **Mental Fatigue Score**",
       subtitle = "bw = 0.8",
       x = "Mental Fatigue Score") +
  theme(plot.title = ggtext::element_markdown(size = 11),
        plot.subtitle = ggtext::element_markdown(size = 8))
```
Although there is a very slight skew towards a higher mental fatigue score the overall distribution is still more or less bell shaped and quite symmetrical. Moreover the whole allowed range is covered and the bounds are not violated. Next the main effect of the variable.

```{r echo=FALSE}
ggplot(burnout_train,
       aes(y = mental_fatigue_score,
           x = burn_rate)) +
  geom_point(alpha = 0.1, col = plasma(1),
             na.rm = TRUE) +
  labs(y = "Mental Fatigue Score", x = "Burn rate",
       title = "Main effect of variable **Mental Fatigue Score**") +
  annotate("text", x = .75, y = 2.5,
           label = paste("Pearson Correlation:",
                         round(
                           cor(burnout_train$burn_rate,
                               burnout_train$mental_fatigue_score,
                               use = "comp"),
                           3
                         )),
           col = plasma(1), size = 5) +
  theme_light() +
  theme(legend.position = "None",
        plot.title = ggtext::element_markdown(size = 11))
```

This scatterplot shows drastic results! The mental fatigue score has an almost perfect linear relationship with the outcome variable. This is also underlined by the very high pearson correlation. This indicates that mental fatigue score will be a most important predictor. If a communication with the data collector would be possible it would be important to check whether the two scores have common confounding variables as then one would have to question the practical usability of this predictor. This comes from the fact that no model would be needed if it was as hard to collect the data about the predictors as the outcome data. Moreover there are `r sum(is.na(burnout_train$mental_fatigue_score))` missing values in the feature so for those the model has to rely on the other maybe more weak predictors. It should be noted that when evaluating the final model one should consider to compare its performance to a trivial model (like a single intercept model). When constructing such a trivial model one could and maybe should also use this variable (when available) to get a trivial prediction by scaling the `mental_fatigue_score` feature by a simple scalar.

```{r, include=FALSE}
sum(is.na(burnout_train$mental_fatigue_score))
```



### Visualize the data

-   pair plots

    -   indiviual main effects

    -   correlations

-   correlation plot

-   feature engineering



### Create recipe

one for lm (dummify categorical features) and one for the tree based approaches

```{r recipes}
# ames_rec <- 
#   recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + 
#            Latitude + Longitude, data = ames_train) %>%
#   step_log(Gr_Liv_Area, base = 10) %>% 
#   step_other(Neighborhood, threshold = 0.01) %>% 
#   step_dummy(all_nominal()) %>% 
#   step_interact( ~ Gr_Liv_Area:starts_with("Bldg_Type_") ) %>% 
#   step_ns(Latitude, Longitude, deg_free = 20)
```
