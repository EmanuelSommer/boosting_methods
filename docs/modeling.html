<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Let’s boost the models | Boosting methods: Theory and application in R</title>
  <meta name="description" content="Boosting methods: Theory and Application in R (XGBoost)" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Let’s boost the models | Boosting methods: Theory and application in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Boosting methods: Theory and Application in R (XGBoost)" />
  <meta name="github-repo" content="EmanuelSommer/boosting_methods" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Let’s boost the models | Boosting methods: Theory and application in R" />
  
  <meta name="twitter:description" content="Boosting methods: Theory and Application in R (XGBoost)" />
  

<meta name="author" content="Emanuel Sommer" />


<meta name="date" content="2021-06-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="eda.html"/>
<link rel="next" href="conclusion.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Boosting methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="theory.html"><a href="theory.html"><i class="fa fa-check"></i><b>3</b> Theory</a>
<ul>
<li class="chapter" data-level="3.1" data-path="theory.html"><a href="theory.html#the-powerful-idea-of-gradient-boosting"><i class="fa fa-check"></i><b>3.1</b> The powerful idea of gradient boosting</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="theory.html"><a href="theory.html#forward-stagewise-additive-modeling"><i class="fa fa-check"></i><b>3.1.1</b> Forward Stagewise Additive Modeling</a></li>
<li class="chapter" data-level="3.1.2" data-path="theory.html"><a href="theory.html#robust-loss-functions-for-regression"><i class="fa fa-check"></i><b>3.1.2</b> Robust loss functions for regression</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="theory.html"><a href="theory.html#general-gradient-tree-boosting"><i class="fa fa-check"></i><b>3.2</b> General gradient tree boosting</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="theory.html"><a href="theory.html#numOpt"><i class="fa fa-check"></i><b>3.2.1</b> Numerical optimization</a></li>
<li class="chapter" data-level="3.2.2" data-path="theory.html"><a href="theory.html#single-tree-depth"><i class="fa fa-check"></i><b>3.2.2</b> Single tree depth</a></li>
<li class="chapter" data-level="3.2.3" data-path="theory.html"><a href="theory.html#combOver"><i class="fa fa-check"></i><b>3.2.3</b> Combat overfitting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="theory.html"><a href="theory.html#xgboost-a-highly-efficient-implementation"><i class="fa fa-check"></i><b>3.3</b> XGBoost a highly efficient implementation</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="theory.html"><a href="theory.html#regularized-loss"><i class="fa fa-check"></i><b>3.3.1</b> Regularized loss</a></li>
<li class="chapter" data-level="3.3.2" data-path="theory.html"><a href="theory.html#shrinkage-and-subsampling"><i class="fa fa-check"></i><b>3.3.2</b> Shrinkage and subsampling</a></li>
<li class="chapter" data-level="3.3.3" data-path="theory.html"><a href="theory.html#even-more-tweaks"><i class="fa fa-check"></i><b>3.3.3</b> Even more tweaks</a></li>
<li class="chapter" data-level="3.3.4" data-path="theory.html"><a href="theory.html#hyperparameters-overview"><i class="fa fa-check"></i><b>3.3.4</b> Hyperparameters overview</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>4</b> Explore the data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="eda.html"><a href="eda.html#burnout-data"><i class="fa fa-check"></i><b>4.1</b> Burnout data</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="eda.html"><a href="eda.html#train-test-split"><i class="fa fa-check"></i><b>4.1.1</b> Train-test split</a></li>
<li class="chapter" data-level="4.1.2" data-path="eda.html"><a href="eda.html#quick-general-overview"><i class="fa fa-check"></i><b>4.1.2</b> Quick general overview</a></li>
<li class="chapter" data-level="4.1.3" data-path="eda.html"><a href="eda.html#what-about-the-outcome-variable"><i class="fa fa-check"></i><b>4.1.3</b> What about the outcome variable?</a></li>
<li class="chapter" data-level="4.1.4" data-path="eda.html"><a href="eda.html#distribution-and-main-effects-of-the-predictors"><i class="fa fa-check"></i><b>4.1.4</b> Distribution and main effects of the predictors</a></li>
<li class="chapter" data-level="4.1.5" data-path="eda.html"><a href="eda.html#relationships-between-the-predictors"><i class="fa fa-check"></i><b>4.1.5</b> Relationships between the predictors</a></li>
<li class="chapter" data-level="4.1.6" data-path="eda.html"><a href="eda.html#some-feature-engineering"><i class="fa fa-check"></i><b>4.1.6</b> Some feature engineering</a></li>
<li class="chapter" data-level="4.1.7" data-path="eda.html"><a href="eda.html#create-the-recipe"><i class="fa fa-check"></i><b>4.1.7</b> Create the recipe</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eda.html"><a href="eda.html#insurence-data"><i class="fa fa-check"></i><b>4.2</b> Insurence data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="eda.html"><a href="eda.html#train-test-split-1"><i class="fa fa-check"></i><b>4.2.1</b> Train-test split</a></li>
<li class="chapter" data-level="4.2.2" data-path="eda.html"><a href="eda.html#a-general-overview"><i class="fa fa-check"></i><b>4.2.2</b> A general overview</a></li>
<li class="chapter" data-level="4.2.3" data-path="eda.html"><a href="eda.html#what-about-the-outcome"><i class="fa fa-check"></i><b>4.2.3</b> What about the outcome?</a></li>
<li class="chapter" data-level="4.2.4" data-path="eda.html"><a href="eda.html#distribution-and-main-effects-of-the-predictors-1"><i class="fa fa-check"></i><b>4.2.4</b> Distribution and main effects of the predictors</a></li>
<li class="chapter" data-level="4.2.5" data-path="eda.html"><a href="eda.html#relationships-between-the-predictors-1"><i class="fa fa-check"></i><b>4.2.5</b> Relationships between the predictors</a></li>
<li class="chapter" data-level="4.2.6" data-path="eda.html"><a href="eda.html#create-the-recipe-1"><i class="fa fa-check"></i><b>4.2.6</b> Create the recipe</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modeling.html"><a href="modeling.html"><i class="fa fa-check"></i><b>5</b> Let’s boost the models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="modeling.html"><a href="modeling.html#burnout-data-1"><i class="fa fa-check"></i><b>5.1</b> Burnout data</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="modeling.html"><a href="modeling.html#baseline-models"><i class="fa fa-check"></i><b>5.1.1</b> Baseline models</a></li>
<li class="chapter" data-level="5.1.2" data-path="modeling.html"><a href="modeling.html#model-specification"><i class="fa fa-check"></i><b>5.1.2</b> Model specification</a></li>
<li class="chapter" data-level="5.1.3" data-path="modeling.html"><a href="modeling.html#tuning"><i class="fa fa-check"></i><b>5.1.3</b> Tuning</a></li>
<li class="chapter" data-level="5.1.4" data-path="modeling.html"><a href="modeling.html#evaluate-and-understand-the-model"><i class="fa fa-check"></i><b>5.1.4</b> Evaluate and understand the model</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modeling.html"><a href="modeling.html#insurance-data"><i class="fa fa-check"></i><b>5.2</b> Insurance data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="modeling.html"><a href="modeling.html#baseline-models-1"><i class="fa fa-check"></i><b>5.2.1</b> Baseline models</a></li>
<li class="chapter" data-level="5.2.2" data-path="modeling.html"><a href="modeling.html#model-specification-1"><i class="fa fa-check"></i><b>5.2.2</b> Model specification</a></li>
<li class="chapter" data-level="5.2.3" data-path="modeling.html"><a href="modeling.html#tuning-1"><i class="fa fa-check"></i><b>5.2.3</b> Tuning</a></li>
<li class="chapter" data-level="5.2.4" data-path="modeling.html"><a href="modeling.html#evaluate-and-understand-the-model-1"><i class="fa fa-check"></i><b>5.2.4</b> Evaluate and understand the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a>
<ul>
<li class="chapter" data-level="6.1" data-path="conclusion.html"><a href="conclusion.html#pros"><i class="fa fa-check"></i><b>6.1</b> Pros</a></li>
<li class="chapter" data-level="6.2" data-path="conclusion.html"><a href="conclusion.html#cons"><i class="fa fa-check"></i><b>6.2</b> Cons</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Boosting methods: Theory and application in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modeling" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Let’s boost the models</h1>
<p>Beside the XGBoost model also a random forest model will be fitted here for comparison. The whole modeling approach and procedure is closely following the principles that are outlined in the <strong>great</strong> book <em>Tidy modeling with R</em> by Max Kuhn and Julia Silge.</p>
<p>For the modeling three additional packages are required.<span class="citation">[<a href="#ref-xgboost_package" role="doc-biblioref">5</a>, <a href="#ref-ranger_package" role="doc-biblioref">17</a>, <a href="#ref-vipPack" role="doc-biblioref">18</a>]</span></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="modeling.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost) <span class="co"># for the xgboost model</span></span>
<span id="cb42-2"><a href="modeling.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger) <span class="co"># for the random forest model</span></span>
<span id="cb42-3"><a href="modeling.html#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># + the vip package but it will not be loaded into</span></span>
<span id="cb42-4"><a href="modeling.html#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># the namespace</span></span></code></pre></div>
<p>For parallel computations the <code>doParallel</code> package is used.<span class="citation">[<a href="#ref-doParallel_package" role="doc-biblioref">19</a>]</span>
This is most useful for the tuning part.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="modeling.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb43-2"><a href="modeling.html#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="modeling.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a cluster object and then register: </span></span>
<span id="cb43-4"><a href="modeling.html#cb43-4" aria-hidden="true" tabindex="-1"></a>cl <span class="ot">&lt;-</span> <span class="fu">makePSOCKcluster</span>(<span class="dv">2</span>)</span>
<span id="cb43-5"><a href="modeling.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cl)</span></code></pre></div>
<p>First one has to set a <strong>metric</strong> for the evaluation of the final performance. As one knows from the EDA that not a lot of outliers are present in the data one can leave the default for XGBoost as the optimization metric for regression which is the root mean squared error (RMSE) which basically corresponds to the <span class="math inline">\(L_2\)</span> loss. Besides also the mean average error (MAE) which is kind of the <span class="math inline">\(L_1\)</span> norm will be covered but the optimization and tuning will focus on the RMSE.</p>
<div id="burnout-data-1" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Burnout data</h2>
<div id="baseline-models" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Baseline models</h3>
<p>The first thing is to set up the trivial <strong>baseline models</strong>.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="modeling.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the trivial intercept only model:</span></span>
<span id="cb44-2"><a href="modeling.html#cb44-2" aria-hidden="true" tabindex="-1"></a>bout_predict_trivial_mean <span class="ot">&lt;-</span> <span class="cf">function</span>(new_data) {</span>
<span id="cb44-3"><a href="modeling.html#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">mean</span>(burnout_train<span class="sc">$</span>burn_rate), <span class="fu">nrow</span>(new_data))</span>
<span id="cb44-4"><a href="modeling.html#cb44-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb44-5"><a href="modeling.html#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="modeling.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co"># the trivial scoring of mental fatigue score (if missing intercept model)</span></span>
<span id="cb44-7"><a href="modeling.html#cb44-7" aria-hidden="true" tabindex="-1"></a>bout_predict_trivial_mfs <span class="ot">&lt;-</span> <span class="cf">function</span>(new_data) {</span>
<span id="cb44-8"><a href="modeling.html#cb44-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># these two scoring parameters are correspondint to the </span></span>
<span id="cb44-9"><a href="modeling.html#cb44-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># simple linear regression model containing only one predictor</span></span>
<span id="cb44-10"><a href="modeling.html#cb44-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># i.e. mfs</span></span>
<span id="cb44-11"><a href="modeling.html#cb44-11" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> new_data[[<span class="st">&quot;mental_fatigue_score&quot;</span>]] <span class="sc">*</span> <span class="fl">0.097</span> <span class="sc">-</span> <span class="fl">0.1</span></span>
<span id="cb44-12"><a href="modeling.html#cb44-12" aria-hidden="true" tabindex="-1"></a>  pred[<span class="fu">is.na</span>(pred)] <span class="ot">&lt;-</span> <span class="fu">mean</span>(burnout_train<span class="sc">$</span>burn_rate)</span>
<span id="cb44-13"><a href="modeling.html#cb44-13" aria-hidden="true" tabindex="-1"></a>  pred</span>
<span id="cb44-14"><a href="modeling.html#cb44-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>The predictions of these baseline models on the test data set will be compared with the predictions of the tree-based models that will be constructed.</p>
</div>
<div id="model-specification" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Model specification</h3>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="modeling.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Models:</span></span>
<span id="cb45-2"><a href="modeling.html#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="modeling.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model for comparison</span></span>
<span id="cb45-4"><a href="modeling.html#cb45-4" aria-hidden="true" tabindex="-1"></a>bout_rf_model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-5"><a href="modeling.html#cb45-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">mtry =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb45-6"><a href="modeling.html#cb45-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb45-7"><a href="modeling.html#cb45-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb45-8"><a href="modeling.html#cb45-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-9"><a href="modeling.html#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost model </span></span>
<span id="cb45-10"><a href="modeling.html#cb45-10" aria-hidden="true" tabindex="-1"></a>bout_boost_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-11"><a href="modeling.html#cb45-11" aria-hidden="true" tabindex="-1"></a>                               <span class="at">learn_rate =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-12"><a href="modeling.html#cb45-12" aria-hidden="true" tabindex="-1"></a>                               <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-13"><a href="modeling.html#cb45-13" aria-hidden="true" tabindex="-1"></a>                               <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-14"><a href="modeling.html#cb45-14" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-15"><a href="modeling.html#cb45-15" aria-hidden="true" tabindex="-1"></a>                               <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb45-16"><a href="modeling.html#cb45-16" aria-hidden="true" tabindex="-1"></a>                               <span class="at">stop_iter =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-17"><a href="modeling.html#cb45-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb45-18"><a href="modeling.html#cb45-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="modeling.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflows: model + recipe</span></span>
<span id="cb46-2"><a href="modeling.html#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="modeling.html#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest workflow</span></span>
<span id="cb46-4"><a href="modeling.html#cb46-4" aria-hidden="true" tabindex="-1"></a>bout_rf_wflow <span class="ot">&lt;-</span></span>
<span id="cb46-5"><a href="modeling.html#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb46-6"><a href="modeling.html#cb46-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(bout_rf_model) <span class="sc">%&gt;%</span></span>
<span id="cb46-7"><a href="modeling.html#cb46-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(burnout_rec_rf)</span>
<span id="cb46-8"><a href="modeling.html#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="modeling.html#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost workflow with the untransformed target</span></span>
<span id="cb46-10"><a href="modeling.html#cb46-10" aria-hidden="true" tabindex="-1"></a>bout_boost_wflow <span class="ot">&lt;-</span></span>
<span id="cb46-11"><a href="modeling.html#cb46-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb46-12"><a href="modeling.html#cb46-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(bout_boost_model) <span class="sc">%&gt;%</span></span>
<span id="cb46-13"><a href="modeling.html#cb46-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(burnout_rec_boost)</span>
<span id="cb46-14"><a href="modeling.html#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="modeling.html#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost workflow with the transformed target (empirical logit)</span></span>
<span id="cb46-16"><a href="modeling.html#cb46-16" aria-hidden="true" tabindex="-1"></a>bout_boost_wflow_trans <span class="ot">&lt;-</span></span>
<span id="cb46-17"><a href="modeling.html#cb46-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb46-18"><a href="modeling.html#cb46-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(bout_boost_model) <span class="sc">%&gt;%</span></span>
<span id="cb46-19"><a href="modeling.html#cb46-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(burnout_rec_boost_trans)</span></code></pre></div>
</div>
<div id="tuning" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Tuning</h3>
<p>For the hyperparameter tuning one needs validation sets to monitor the models on unseen data. To do this 5-fold cross validation (CV) is used here.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="modeling.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Resampling object</span></span>
<span id="cb47-2"><a href="modeling.html#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb47-3"><a href="modeling.html#cb47-3" aria-hidden="true" tabindex="-1"></a>burnout_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(burnout_train, <span class="at">v =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>Now adjust or check the hyperparameter ranges that the tuning will use. First the Random forest model.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="modeling.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Have a look at the hyperparameters that have to be tuned and finalize them</span></span>
<span id="cb48-2"><a href="modeling.html#cb48-2" aria-hidden="true" tabindex="-1"></a>bout_rf_params <span class="ot">&lt;-</span> bout_rf_wflow <span class="sc">%&gt;%</span></span>
<span id="cb48-3"><a href="modeling.html#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>()</span>
<span id="cb48-4"><a href="modeling.html#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="modeling.html#cb48-5" aria-hidden="true" tabindex="-1"></a>bout_rf_params </span></code></pre></div>
<pre><code>## Collection of 2 parameters for tuning
## 
##  identifier  type    object
##        mtry  mtry nparam[?]
##       trees trees nparam[+]
## 
## Model parameters needing finalization:
##    # Randomly Selected Predictors (&#39;mtry&#39;)
## 
## See `?dials::finalize` or `?dials::update.parameters` for more information.</code></pre>
<p>This shows that the <code>mtry</code> hyperparameter has to be adjusted depending on the data. Moreover with the <code>dials::update</code> function one can manually set the ranges that should be used for tuning.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="modeling.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># default range for tuning is 1 up to 2000 for the trees argument</span></span>
<span id="cb50-2"><a href="modeling.html#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># set the lower bound of the range to 100. Then finalize the</span></span>
<span id="cb50-3"><a href="modeling.html#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters using the training data.</span></span>
<span id="cb50-4"><a href="modeling.html#cb50-4" aria-hidden="true" tabindex="-1"></a>bout_rf_params <span class="ot">&lt;-</span> bout_rf_params <span class="sc">%&gt;%</span></span>
<span id="cb50-5"><a href="modeling.html#cb50-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">trees =</span> <span class="fu">trees</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">2000</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb50-6"><a href="modeling.html#cb50-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(burnout_train)</span>
<span id="cb50-7"><a href="modeling.html#cb50-7" aria-hidden="true" tabindex="-1"></a>bout_rf_params</span></code></pre></div>
<pre><code>## Collection of 2 parameters for tuning
## 
##  identifier  type    object
##        mtry  mtry nparam[+]
##       trees trees nparam[+]</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="modeling.html#cb52-1" aria-hidden="true" tabindex="-1"></a>bout_rf_params <span class="sc">%&gt;%</span> <span class="fu">pull_dials_object</span>(<span class="st">&quot;mtry&quot;</span>)</span></code></pre></div>
<pre><code>## # Randomly Selected Predictors (quantitative)
## Range: [1, 10]</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="modeling.html#cb54-1" aria-hidden="true" tabindex="-1"></a>bout_rf_params <span class="sc">%&gt;%</span> <span class="fu">pull_dials_object</span>(<span class="st">&quot;trees&quot;</span>)</span></code></pre></div>
<pre><code>## # Trees (quantitative)
## Range: [100, 2000]</code></pre>
<p>Now this parameter object is ready for tuning and the same steps have to be performed on the main boosting workflow. The parameter set for the untransformed target can then also be used for the transformed one.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="modeling.html#cb56-1" aria-hidden="true" tabindex="-1"></a>bout_boost_params <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb56-2"><a href="modeling.html#cb56-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>()</span>
<span id="cb56-3"><a href="modeling.html#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="modeling.html#cb56-4" aria-hidden="true" tabindex="-1"></a>bout_boost_params </span></code></pre></div>
<pre><code>## Collection of 6 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[?]
##           trees          trees nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]
## 
## Model parameters needing finalization:
##    # Randomly Selected Predictors (&#39;mtry&#39;)
## 
## See `?dials::finalize` or `?dials::update.parameters` for more information.</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="modeling.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># first a look at the default ranges</span></span>
<span id="cb58-2"><a href="modeling.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">trees</span>()</span></code></pre></div>
<pre><code>## # Trees (quantitative)
## Range: [1, 2000]</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="modeling.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tree_depth</span>()</span></code></pre></div>
<pre><code>## Tree Depth (quantitative)
## Range: [1, 15]</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="modeling.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">learn_rate</span>()</span></code></pre></div>
<pre><code>## Learning Rate (quantitative)
## Transformer:  log-10 
## Range (transformed scale): [-10, -1]</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="modeling.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loss_reduction</span>()</span></code></pre></div>
<pre><code>## Minimum Loss Reduction (quantitative)
## Transformer:  log-10 
## Range (transformed scale): [-10, 1.5]</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="modeling.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample_size</span>()</span></code></pre></div>
<pre><code>## # Observations Sampled (quantitative)
## Range: [?, ?]</code></pre>
<p>So <code>sample_size</code> must also be finalized. Again the lower bound on the number of trees will be raised to 100. The other scales are really sensible and will be left as is.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="modeling.html#cb68-1" aria-hidden="true" tabindex="-1"></a>bout_boost_params <span class="ot">&lt;-</span> bout_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb68-2"><a href="modeling.html#cb68-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">trees =</span> <span class="fu">trees</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">2000</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb68-3"><a href="modeling.html#cb68-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(burnout_train)</span>
<span id="cb68-4"><a href="modeling.html#cb68-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-5"><a href="modeling.html#cb68-5" aria-hidden="true" tabindex="-1"></a>bout_boost_params</span></code></pre></div>
<pre><code>## Collection of 6 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[+]
##           trees          trees nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="modeling.html#cb70-1" aria-hidden="true" tabindex="-1"></a>bout_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb70-2"><a href="modeling.html#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_dials_object</span>(<span class="st">&quot;sample_size&quot;</span>)</span></code></pre></div>
<pre><code>## Proportion Observations Sampled (quantitative)
## Range: [0.1, 1]</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="modeling.html#cb72-1" aria-hidden="true" tabindex="-1"></a>bout_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb72-2"><a href="modeling.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_dials_object</span>(<span class="st">&quot;mtry&quot;</span>)</span></code></pre></div>
<pre><code>## # Randomly Selected Predictors (quantitative)
## Range: [1, 10]</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="modeling.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use the same object for the tuning of the boosted model</span></span>
<span id="cb74-2"><a href="modeling.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="co"># with the transformed target</span></span>
<span id="cb74-3"><a href="modeling.html#cb74-3" aria-hidden="true" tabindex="-1"></a>bout_boost_params_trans <span class="ot">&lt;-</span> bout_boost_params</span></code></pre></div>
<p>Now also these parameter objects are ready to be used. The next step is to define the metrics used for evaluation while tuning.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="modeling.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define a metrics set used for evaluation of the hyperparameters</span></span>
<span id="cb75-2"><a href="modeling.html#cb75-2" aria-hidden="true" tabindex="-1"></a>regr_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(rmse, mae)</span></code></pre></div>
<p>Now the actual tuning begins. The models will be tuned by a space filling grid search. As one has defined ranges for each parameter one can then use different algorithms to construct a grid of combinations of parameter values that tries to best fill the defined ranges by random sampling also in a high dimensional setting. In the following the function <code>tune::grid_latin_hypercube</code> is used for this. So basically one tries out all hyperparameter values for each fold and saves the performance of the performance metrics on the hold out fold. These metrics are then aggregated for each combination and with the resulting estimates of performance one can choose the final set of hyperparameters. The more hyperparameters the model has the more tuning rounds might be needed to refine the grid. Besides the classical grid search there are also iterative methods for tuning. These are mainly good to tune a single hyperparameter at once and not for a bunch of them simultaneously. They will not be used in the following.</p>
<p>The <strong>random forest model</strong> goes first with the tuning.</p>
<p>Here there are as seen above only two hyperparameters to be tuned thus 30 combinations should suffice.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="modeling.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 30 minutes</span></span>
<span id="cb76-2"><a href="modeling.html#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb76-3"><a href="modeling.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb76-4"><a href="modeling.html#cb76-4" aria-hidden="true" tabindex="-1"></a>  bout_rf_tune <span class="ot">&lt;-</span> bout_rf_wflow <span class="sc">%&gt;%</span></span>
<span id="cb76-5"><a href="modeling.html#cb76-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb76-6"><a href="modeling.html#cb76-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  burnout_folds,</span>
<span id="cb76-7"><a href="modeling.html#cb76-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> bout_rf_params <span class="sc">%&gt;%</span></span>
<span id="cb76-8"><a href="modeling.html#cb76-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(<span class="at">size =</span> <span class="dv">30</span>, <span class="at">original =</span> <span class="cn">FALSE</span>),</span>
<span id="cb76-9"><a href="modeling.html#cb76-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb76-10"><a href="modeling.html#cb76-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb76-11"><a href="modeling.html#cb76-11" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb76-12"><a href="modeling.html#cb76-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-13"><a href="modeling.html#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization of the tuning results (snapshot of the output below)</span></span>
<span id="cb76-14"><a href="modeling.html#cb76-14" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bout_rf_tune) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb76-15"><a href="modeling.html#cb76-15" aria-hidden="true" tabindex="-1"></a><span class="co"># this functions shows the best combinations wrt the rmse metric of all the</span></span>
<span id="cb76-16"><a href="modeling.html#cb76-16" aria-hidden="true" tabindex="-1"></a><span class="co"># combinations in the grid</span></span>
<span id="cb76-17"><a href="modeling.html#cb76-17" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_rf_tune, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rfburntuneplot"></span>
<img src="_pictures/rf_burn_tune_plot.png" alt="Result of a spacefilling grid search for the random forest model." width="70%" />
<p class="caption">
Figure 5.1: Result of a spacefilling grid search for the random forest model.
</p>
</div>
<p>The visualization alongside the best performing results suggest that a value of <code>mtry</code>of 3 and 1000 <code>trees</code> should give good results. Thus one can finalize and fit this model.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="modeling.html#cb77-1" aria-hidden="true" tabindex="-1"></a>final_bout_rf_wflow <span class="ot">&lt;-</span> </span>
<span id="cb77-2"><a href="modeling.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  bout_rf_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb77-3"><a href="modeling.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(<span class="fu">tibble</span>(</span>
<span id="cb77-4"><a href="modeling.html#cb77-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb77-5"><a href="modeling.html#cb77-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">3</span></span>
<span id="cb77-6"><a href="modeling.html#cb77-6" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb77-7"><a href="modeling.html#cb77-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(burnout_train)</span></code></pre></div>
<p>Now the main <strong>boosting model</strong>.</p>
<p>First tune only the number of trees in order to detect a number of
trees that is ‘large enough.’ Then tune the tree specific arguments.
If one tunes all parameters at the same time the grid grows to large. Moreover a tuning of the trees argument could encourage overfitting. See the book <em>Hands-on Machine Learning with R</em> for a detailed explenation of the tuning strategies.<span class="citation">[<a href="#ref-HandsOnMLwithR" role="doc-biblioref">2</a>]</span></p>
<p>The first tuning round:</p>
<p>To display the discussed impact of different maximum tree depths the first grid search for a good number of trees will besides the kind of standard value 6 also be performed for regression stumps i.e. a value of 1 for the maximum tree depth.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="modeling.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tuning grid just for the #trees one with max tree depth 6 and one with</span></span>
<span id="cb78-2"><a href="modeling.html#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="co"># only stumps for comparison</span></span>
<span id="cb78-3"><a href="modeling.html#cb78-3" aria-hidden="true" tabindex="-1"></a>first_grid_boost_burn_depth6 <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb78-4"><a href="modeling.html#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">250</span>, <span class="dv">2000</span>, <span class="dv">250</span>),</span>
<span id="cb78-5"><a href="modeling.html#cb78-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">9</span>,</span>
<span id="cb78-6"><a href="modeling.html#cb78-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="dv">6</span>,</span>
<span id="cb78-7"><a href="modeling.html#cb78-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fl">0.000001</span>,</span>
<span id="cb78-8"><a href="modeling.html#cb78-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb78-9"><a href="modeling.html#cb78-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb78-10"><a href="modeling.html#cb78-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-11"><a href="modeling.html#cb78-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-12"><a href="modeling.html#cb78-12" aria-hidden="true" tabindex="-1"></a>first_grid_boost_burn_stumps <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb78-13"><a href="modeling.html#cb78-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">250</span>, <span class="dv">2000</span>, <span class="dv">250</span>),</span>
<span id="cb78-14"><a href="modeling.html#cb78-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">9</span>,</span>
<span id="cb78-15"><a href="modeling.html#cb78-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="dv">1</span>,</span>
<span id="cb78-16"><a href="modeling.html#cb78-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fl">0.000001</span>,</span>
<span id="cb78-17"><a href="modeling.html#cb78-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb78-18"><a href="modeling.html#cb78-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb78-19"><a href="modeling.html#cb78-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="modeling.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 1 minute</span></span>
<span id="cb79-2"><a href="modeling.html#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb79-3"><a href="modeling.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb79-4"><a href="modeling.html#cb79-4" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_first_stumps <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb79-5"><a href="modeling.html#cb79-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb79-6"><a href="modeling.html#cb79-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  burnout_folds,</span>
<span id="cb79-7"><a href="modeling.html#cb79-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> first_grid_boost_burn_stumps,</span>
<span id="cb79-8"><a href="modeling.html#cb79-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb79-9"><a href="modeling.html#cb79-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb79-10"><a href="modeling.html#cb79-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb79-11"><a href="modeling.html#cb79-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-12"><a href="modeling.html#cb79-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-13"><a href="modeling.html#cb79-13" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bout_boost_tune_first_stumps) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb79-14"><a href="modeling.html#cb79-14" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_first_stumps)</span></code></pre></div>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="modeling.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 1 minute</span></span>
<span id="cb80-2"><a href="modeling.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb80-3"><a href="modeling.html#cb80-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb80-4"><a href="modeling.html#cb80-4" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_first_depth6 <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb80-5"><a href="modeling.html#cb80-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb80-6"><a href="modeling.html#cb80-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  burnout_folds,</span>
<span id="cb80-7"><a href="modeling.html#cb80-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> first_grid_boost_burn_depth6,</span>
<span id="cb80-8"><a href="modeling.html#cb80-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb80-9"><a href="modeling.html#cb80-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb80-10"><a href="modeling.html#cb80-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb80-11"><a href="modeling.html#cb80-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-12"><a href="modeling.html#cb80-12" aria-hidden="true" tabindex="-1"></a><span class="co"># plot output is shown in the figure below</span></span>
<span id="cb80-13"><a href="modeling.html#cb80-13" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bout_boost_tune_first_depth6) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb80-14"><a href="modeling.html#cb80-14" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_first_depth6)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:boostburntuneplot1"></span>
<img src="_pictures/burn_boost_tune_first.png" alt="Result of the first grid search for the XGBoost model (max depth 6)." width="70%" />
<p class="caption">
Figure 5.2: Result of the first grid search for the XGBoost model (max depth 6).
</p>
</div>
<p>Compare the two different first tuning rounds:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="modeling.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># output of this code shown in the figure below</span></span>
<span id="cb81-2"><a href="modeling.html#cb81-2" aria-hidden="true" tabindex="-1"></a>bout_boost_tune_first_stumps <span class="sc">%&gt;%</span></span>
<span id="cb81-3"><a href="modeling.html#cb81-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb81-4"><a href="modeling.html#cb81-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">tree_depth =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb81-5"><a href="modeling.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb81-6"><a href="modeling.html#cb81-6" aria-hidden="true" tabindex="-1"></a>    bout_boost_tune_first_depth6 <span class="sc">%&gt;%</span></span>
<span id="cb81-7"><a href="modeling.html#cb81-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb81-8"><a href="modeling.html#cb81-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">tree_depth =</span> <span class="dv">6</span>)</span>
<span id="cb81-9"><a href="modeling.html#cb81-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb81-10"><a href="modeling.html#cb81-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> trees, <span class="at">y =</span> mean, <span class="at">col =</span> <span class="fu">factor</span>(tree_depth))) <span class="sc">+</span></span>
<span id="cb81-11"><a href="modeling.html#cb81-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb81-12"><a href="modeling.html#cb81-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb81-13"><a href="modeling.html#cb81-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> std_err, <span class="at">ymax =</span> mean <span class="sc">+</span> std_err)) <span class="sc">+</span></span>
<span id="cb81-14"><a href="modeling.html#cb81-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">col =</span> <span class="st">&quot;Max tree depth&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Number of trees&quot;</span>,</span>
<span id="cb81-15"><a href="modeling.html#cb81-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb81-16"><a href="modeling.html#cb81-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">option =</span> <span class="st">&quot;C&quot;</span>) <span class="sc">+</span></span>
<span id="cb81-17"><a href="modeling.html#cb81-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric) <span class="sc">+</span></span>
<span id="cb81-18"><a href="modeling.html#cb81-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bouttuningstumpsVs6"></span>
<img src="_pictures/bout_tuning_stumpsVs6.png" alt="Comparison of the initial grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates." width="70%" />
<p class="caption">
Figure 5.3: Comparison of the initial grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates.
</p>
</div>
<p>This shows that the model with just stumps converges much slower or may even never reach the low level of when using deeper trees. One reason for this could be that these stumps do not account for interactions and of course the same number of deep trees encode much more information than the same number of stumps.</p>
<p>So 1500 trees should suffice here. Thus the workflow and model will be adjusted accordingly.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="modeling.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix the number of trees by redefining the boosted model with a </span></span>
<span id="cb82-2"><a href="modeling.html#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fixed number of trees.</span></span>
<span id="cb82-3"><a href="modeling.html#cb82-3" aria-hidden="true" tabindex="-1"></a>bout_boost_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="dv">1500</span>,</span>
<span id="cb82-4"><a href="modeling.html#cb82-4" aria-hidden="true" tabindex="-1"></a>                               <span class="at">learn_rate =</span> <span class="fu">tune</span>(),</span>
<span id="cb82-5"><a href="modeling.html#cb82-5" aria-hidden="true" tabindex="-1"></a>                               <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb82-6"><a href="modeling.html#cb82-6" aria-hidden="true" tabindex="-1"></a>                               <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb82-7"><a href="modeling.html#cb82-7" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb82-8"><a href="modeling.html#cb82-8" aria-hidden="true" tabindex="-1"></a>                               <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb82-9"><a href="modeling.html#cb82-9" aria-hidden="true" tabindex="-1"></a>                               <span class="at">stop_iter =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb82-10"><a href="modeling.html#cb82-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb82-11"><a href="modeling.html#cb82-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb82-12"><a href="modeling.html#cb82-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-13"><a href="modeling.html#cb82-13" aria-hidden="true" tabindex="-1"></a><span class="co"># update the workflow</span></span>
<span id="cb82-14"><a href="modeling.html#cb82-14" aria-hidden="true" tabindex="-1"></a>bout_boost_wflow <span class="ot">&lt;-</span></span>
<span id="cb82-15"><a href="modeling.html#cb82-15" aria-hidden="true" tabindex="-1"></a>  bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb82-16"><a href="modeling.html#cb82-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(bout_boost_model)</span>
<span id="cb82-17"><a href="modeling.html#cb82-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-18"><a href="modeling.html#cb82-18" aria-hidden="true" tabindex="-1"></a>bout_boost_params <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb82-19"><a href="modeling.html#cb82-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb82-20"><a href="modeling.html#cb82-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(burnout_train)</span>
<span id="cb82-21"><a href="modeling.html#cb82-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-22"><a href="modeling.html#cb82-22" aria-hidden="true" tabindex="-1"></a><span class="co"># reduced hyperparameter space</span></span>
<span id="cb82-23"><a href="modeling.html#cb82-23" aria-hidden="true" tabindex="-1"></a>bout_boost_params</span></code></pre></div>
<pre><code>## Collection of 5 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]</code></pre>
<p>Now perform the first major grid search over all the other hyperparameters.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="modeling.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now tune all the remaining hyperparameters with a large space filling grid</span></span>
<span id="cb84-2"><a href="modeling.html#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="modeling.html#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 1.5 hours</span></span>
<span id="cb84-4"><a href="modeling.html#cb84-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb84-5"><a href="modeling.html#cb84-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb84-6"><a href="modeling.html#cb84-6" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_second <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb84-7"><a href="modeling.html#cb84-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb84-8"><a href="modeling.html#cb84-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span> burnout_folds,</span>
<span id="cb84-9"><a href="modeling.html#cb84-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> bout_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb84-10"><a href="modeling.html#cb84-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(</span>
<span id="cb84-11"><a href="modeling.html#cb84-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">size =</span> <span class="dv">200</span>),</span>
<span id="cb84-12"><a href="modeling.html#cb84-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb84-13"><a href="modeling.html#cb84-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-14"><a href="modeling.html#cb84-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb84-15"><a href="modeling.html#cb84-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-16"><a href="modeling.html#cb84-16" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_second, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<p>Now refine the grid i.e. the parameter space according to the results of the last grid search and perform a third one.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="modeling.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now tune all the remaining hyperparameters with a refined space filling grid</span></span>
<span id="cb85-2"><a href="modeling.html#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="modeling.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 2 hours</span></span>
<span id="cb85-4"><a href="modeling.html#cb85-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb85-5"><a href="modeling.html#cb85-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb85-6"><a href="modeling.html#cb85-6" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_third <span class="ot">&lt;-</span> bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb85-7"><a href="modeling.html#cb85-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb85-8"><a href="modeling.html#cb85-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span> burnout_folds,</span>
<span id="cb85-9"><a href="modeling.html#cb85-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> bout_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb85-10"><a href="modeling.html#cb85-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">update</span>(</span>
<span id="cb85-11"><a href="modeling.html#cb85-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">mtry =</span> <span class="fu">mtry</span>(<span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">9</span>)),</span>
<span id="cb85-12"><a href="modeling.html#cb85-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">tree_depth =</span> <span class="fu">tree_depth</span>(<span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">5</span>)),</span>
<span id="cb85-13"><a href="modeling.html#cb85-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">learn_rate =</span> <span class="fu">learn_rate</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.7</span>, <span class="sc">-</span><span class="fl">1.3</span>)),</span>
<span id="cb85-14"><a href="modeling.html#cb85-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">loss_reduction =</span> <span class="fu">loss_reduction</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">8</span>,<span class="sc">-</span><span class="dv">3</span>)),</span>
<span id="cb85-15"><a href="modeling.html#cb85-15" aria-hidden="true" tabindex="-1"></a>          <span class="at">sample_size =</span> <span class="fu">sample_prop</span>(<span class="fu">c</span>(<span class="fl">0.4</span>, <span class="fl">0.9</span>))</span>
<span id="cb85-16"><a href="modeling.html#cb85-16" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">%&gt;%</span></span>
<span id="cb85-17"><a href="modeling.html#cb85-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(</span>
<span id="cb85-18"><a href="modeling.html#cb85-18" aria-hidden="true" tabindex="-1"></a>          <span class="at">size =</span> <span class="dv">200</span>),</span>
<span id="cb85-19"><a href="modeling.html#cb85-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb85-20"><a href="modeling.html#cb85-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb85-21"><a href="modeling.html#cb85-21" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb85-22"><a href="modeling.html#cb85-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-23"><a href="modeling.html#cb85-23" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_third, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<p>With this final grid search one is ready to finalize the model.</p>
<p>The results of the three grid searches suggest that no column-subsampling should be applied, the maximum tree depth should be 4, the learning rate should be small but not extremely small (<span class="math inline">\(\sim 0.02\)</span>), the loss reduction regularization effect is not needed here (very small) and the sample size for each tree should be set to 0.8.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="modeling.html#cb86-1" aria-hidden="true" tabindex="-1"></a>final_bout_boost_wflow <span class="ot">&lt;-</span> </span>
<span id="cb86-2"><a href="modeling.html#cb86-2" aria-hidden="true" tabindex="-1"></a>  bout_boost_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb86-3"><a href="modeling.html#cb86-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(<span class="fu">tibble</span>(</span>
<span id="cb86-4"><a href="modeling.html#cb86-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">9</span>,</span>
<span id="cb86-5"><a href="modeling.html#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tree_depth =</span> <span class="dv">4</span>,</span>
<span id="cb86-6"><a href="modeling.html#cb86-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">learn_rate =</span> <span class="fl">0.02</span>,</span>
<span id="cb86-7"><a href="modeling.html#cb86-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss_reduction =</span> <span class="fl">0.0000003</span>,</span>
<span id="cb86-8"><a href="modeling.html#cb86-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> <span class="fl">0.8</span></span>
<span id="cb86-9"><a href="modeling.html#cb86-9" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb86-10"><a href="modeling.html#cb86-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(burnout_train)</span></code></pre></div>
<p>Now tune the <strong>transformed outcome boosting model</strong>.</p>
<p>Again start with the <code>trees</code>.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="modeling.html#cb87-1" aria-hidden="true" tabindex="-1"></a>first_grid_boost_burn_trans <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb87-2"><a href="modeling.html#cb87-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">250</span>, <span class="dv">2000</span>, <span class="dv">250</span>),</span>
<span id="cb87-3"><a href="modeling.html#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">9</span>,</span>
<span id="cb87-4"><a href="modeling.html#cb87-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="dv">6</span>,</span>
<span id="cb87-5"><a href="modeling.html#cb87-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fl">0.000001</span>,</span>
<span id="cb87-6"><a href="modeling.html#cb87-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb87-7"><a href="modeling.html#cb87-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb87-8"><a href="modeling.html#cb87-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="modeling.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 1 minute</span></span>
<span id="cb88-2"><a href="modeling.html#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb88-3"><a href="modeling.html#cb88-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb88-4"><a href="modeling.html#cb88-4" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_first_trans <span class="ot">&lt;-</span> bout_boost_wflow_trans <span class="sc">%&gt;%</span></span>
<span id="cb88-5"><a href="modeling.html#cb88-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb88-6"><a href="modeling.html#cb88-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  burnout_folds,</span>
<span id="cb88-7"><a href="modeling.html#cb88-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> first_grid_boost_burn_trans,</span>
<span id="cb88-8"><a href="modeling.html#cb88-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb88-9"><a href="modeling.html#cb88-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb88-10"><a href="modeling.html#cb88-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb88-11"><a href="modeling.html#cb88-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-12"><a href="modeling.html#cb88-12" aria-hidden="true" tabindex="-1"></a><span class="co"># plot output in the figure below</span></span>
<span id="cb88-13"><a href="modeling.html#cb88-13" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(bout_boost_tune_first_trans) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb88-14"><a href="modeling.html#cb88-14" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_first_trans)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:burnboosttunefirsttrans"></span>
<img src="_pictures/burn_boost_tune_first_trans.png" alt="Result of the first grid search for the XGBoost model with transformed outcome." width="70%" />
<p class="caption">
Figure 5.4: Result of the first grid search for the XGBoost model with transformed outcome.
</p>
</div>
<p>Again 1500 trees should easily suffice.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="modeling.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix the number of trees by redefining the boosted model with a </span></span>
<span id="cb89-2"><a href="modeling.html#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fixed number of trees.</span></span>
<span id="cb89-3"><a href="modeling.html#cb89-3" aria-hidden="true" tabindex="-1"></a>bout_boost_model_trans <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="dv">1500</span>,</span>
<span id="cb89-4"><a href="modeling.html#cb89-4" aria-hidden="true" tabindex="-1"></a>                               <span class="at">learn_rate =</span> <span class="fu">tune</span>(),</span>
<span id="cb89-5"><a href="modeling.html#cb89-5" aria-hidden="true" tabindex="-1"></a>                               <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb89-6"><a href="modeling.html#cb89-6" aria-hidden="true" tabindex="-1"></a>                               <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb89-7"><a href="modeling.html#cb89-7" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb89-8"><a href="modeling.html#cb89-8" aria-hidden="true" tabindex="-1"></a>                               <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb89-9"><a href="modeling.html#cb89-9" aria-hidden="true" tabindex="-1"></a>                               <span class="at">stop_iter =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb89-10"><a href="modeling.html#cb89-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb89-11"><a href="modeling.html#cb89-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb89-12"><a href="modeling.html#cb89-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-13"><a href="modeling.html#cb89-13" aria-hidden="true" tabindex="-1"></a><span class="co"># update the workflow</span></span>
<span id="cb89-14"><a href="modeling.html#cb89-14" aria-hidden="true" tabindex="-1"></a>bout_boost_wflow_trans <span class="ot">&lt;-</span></span>
<span id="cb89-15"><a href="modeling.html#cb89-15" aria-hidden="true" tabindex="-1"></a>  bout_boost_wflow_trans <span class="sc">%&gt;%</span></span>
<span id="cb89-16"><a href="modeling.html#cb89-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(bout_boost_model_trans)</span>
<span id="cb89-17"><a href="modeling.html#cb89-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-18"><a href="modeling.html#cb89-18" aria-hidden="true" tabindex="-1"></a>bout_boost_params_trans <span class="ot">&lt;-</span> bout_boost_wflow_trans <span class="sc">%&gt;%</span></span>
<span id="cb89-19"><a href="modeling.html#cb89-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb89-20"><a href="modeling.html#cb89-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(burnout_train)</span>
<span id="cb89-21"><a href="modeling.html#cb89-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-22"><a href="modeling.html#cb89-22" aria-hidden="true" tabindex="-1"></a><span class="co"># reduced hyperparameter space</span></span>
<span id="cb89-23"><a href="modeling.html#cb89-23" aria-hidden="true" tabindex="-1"></a>bout_boost_params_trans</span></code></pre></div>
<pre><code>## Collection of 5 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]</code></pre>
<p>Now perform the first major grid search over all the other hyperparameters and the second one overall.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="modeling.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now tune all the remaining hyperparameters with a large space filling grid</span></span>
<span id="cb91-2"><a href="modeling.html#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="modeling.html#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 2 hours</span></span>
<span id="cb91-4"><a href="modeling.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb91-5"><a href="modeling.html#cb91-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb91-6"><a href="modeling.html#cb91-6" aria-hidden="true" tabindex="-1"></a>  bout_boost_tune_second_trans <span class="ot">&lt;-</span> bout_boost_wflow_trans <span class="sc">%&gt;%</span></span>
<span id="cb91-7"><a href="modeling.html#cb91-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb91-8"><a href="modeling.html#cb91-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span> burnout_folds,</span>
<span id="cb91-9"><a href="modeling.html#cb91-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> bout_boost_params_trans <span class="sc">%&gt;%</span></span>
<span id="cb91-10"><a href="modeling.html#cb91-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(</span>
<span id="cb91-11"><a href="modeling.html#cb91-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">size =</span> <span class="dv">200</span>),</span>
<span id="cb91-12"><a href="modeling.html#cb91-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb91-13"><a href="modeling.html#cb91-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb91-14"><a href="modeling.html#cb91-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb91-15"><a href="modeling.html#cb91-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-16"><a href="modeling.html#cb91-16" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(bout_boost_tune_second_trans, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<p>From the tuning results one can conclude that in this setting actually the same hyperparameter setting as for the raw target variable seems appropriate. So one finalizes the workflow with the same hyperparameters and fits the model.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="modeling.html#cb92-1" aria-hidden="true" tabindex="-1"></a>final_bout_boost_wflow_trans <span class="ot">&lt;-</span> </span>
<span id="cb92-2"><a href="modeling.html#cb92-2" aria-hidden="true" tabindex="-1"></a>  bout_boost_wflow_trans <span class="sc">%&gt;%</span> </span>
<span id="cb92-3"><a href="modeling.html#cb92-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(<span class="fu">tibble</span>(</span>
<span id="cb92-4"><a href="modeling.html#cb92-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">9</span>,</span>
<span id="cb92-5"><a href="modeling.html#cb92-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tree_depth =</span> <span class="dv">4</span>,</span>
<span id="cb92-6"><a href="modeling.html#cb92-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">learn_rate =</span> <span class="fl">0.02</span>,</span>
<span id="cb92-7"><a href="modeling.html#cb92-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss_reduction =</span> <span class="fl">0.0000003</span>,</span>
<span id="cb92-8"><a href="modeling.html#cb92-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> <span class="fl">0.8</span></span>
<span id="cb92-9"><a href="modeling.html#cb92-9" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb92-10"><a href="modeling.html#cb92-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(burnout_train)</span></code></pre></div>
<p>Now all models w.r.t. the burnout data set are fitted.</p>
</div>
<div id="evaluate-and-understand-the-model" class="section level3" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Evaluate and understand the model</h3>
<p>First a visualization of the variable importance. The variable importance is basically calculated by measuring the gain w.r.t. the loss of each feature in the single trees and splits.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="modeling.html#cb93-1" aria-hidden="true" tabindex="-1"></a>vip_burn <span class="ot">&lt;-</span> final_bout_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb93-2"><a href="modeling.html#cb93-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() <span class="sc">%&gt;%</span></span>
<span id="cb93-3"><a href="modeling.html#cb93-3" aria-hidden="true" tabindex="-1"></a>  vip<span class="sc">::</span><span class="fu">vip</span>() <span class="sc">+</span> </span>
<span id="cb93-4"><a href="modeling.html#cb93-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb93-5"><a href="modeling.html#cb93-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Variable importance of the XGBoost model&quot;</span>)</span>
<span id="cb93-6"><a href="modeling.html#cb93-6" aria-hidden="true" tabindex="-1"></a>vip_burn</span></code></pre></div>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="modeling.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">&quot;_pictures/vip_burn.png&quot;</span>,<span class="at">plot =</span> vip_burn)</span>
<span id="cb94-2"><a href="modeling.html#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="fu">remove</span>(vip_burn)</span></code></pre></div>
<p>This shows that indeed the <code>mental_fatigue_score</code> is the most influential predictor by far followed by the <code>ressource_allocation</code> and <code>designation</code> features. These results are not at all surprising as the EDA exactly came to these conclusions. Especially the very few appearances of the features connected to <code>company_type</code> and <code>date_of_joining</code> are most likely just some minor overfitting.</p>
<p>Now compare the variable importance of the model with the raw and the transformed target variable.</p>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<p>One can observe the exact same ordering. The only difference seems to be a higher influence of the designation variable for the transformed target. This is not surprising as the resource allocation and designation variable are highly correlated.</p>
<p>Now have a look at the performance of the main boosting model w.r.t. missing values in the most influential variable.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="modeling.html#cb95-1" aria-hidden="true" tabindex="-1"></a>miss_vals_burn_no <span class="ot">&lt;-</span> burnout_test <span class="sc">%&gt;%</span></span>
<span id="cb95-2"><a href="modeling.html#cb95-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">boost_pred =</span> <span class="fu">predict</span>(final_bout_boost_wflow,</span>
<span id="cb95-3"><a href="modeling.html#cb95-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">new_data =</span> .)[[<span class="st">&quot;.pred&quot;</span>]]) <span class="sc">%&gt;%</span></span>
<span id="cb95-4"><a href="modeling.html#cb95-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(mental_fatigue_score)) <span class="sc">%&gt;%</span></span>
<span id="cb95-5"><a href="modeling.html#cb95-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> burn_rate, <span class="at">y =</span> boost_pred)) <span class="sc">+</span></span>
<span id="cb95-6"><a href="modeling.html#cb95-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="fu">plasma</span>(<span class="dv">1</span>), <span class="at">alpha =</span> <span class="fl">0.1</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb95-7"><a href="modeling.html#cb95-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb95-8"><a href="modeling.html#cb95-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb95-9"><a href="modeling.html#cb95-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb95-10"><a href="modeling.html#cb95-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;XGBoost predictions&quot;</span>,</span>
<span id="cb95-11"><a href="modeling.html#cb95-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;True score&quot;</span>,</span>
<span id="cb95-12"><a href="modeling.html#cb95-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;XGBoost performance for non missing mental fatigue score&quot;</span>) <span class="sc">+</span></span>
<span id="cb95-13"><a href="modeling.html#cb95-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb95-14"><a href="modeling.html#cb95-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> ggtext<span class="sc">::</span><span class="fu">element_markdown</span>(<span class="at">size =</span> <span class="dv">11</span>))</span>
<span id="cb95-15"><a href="modeling.html#cb95-15" aria-hidden="true" tabindex="-1"></a>miss_vals_burn_no</span></code></pre></div>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-87-1.png" width="672" /></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="modeling.html#cb96-1" aria-hidden="true" tabindex="-1"></a>miss_vals_burn_yes <span class="ot">&lt;-</span> burnout_test <span class="sc">%&gt;%</span></span>
<span id="cb96-2"><a href="modeling.html#cb96-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">boost_pred =</span> <span class="fu">predict</span>(final_bout_boost_wflow,</span>
<span id="cb96-3"><a href="modeling.html#cb96-3" aria-hidden="true" tabindex="-1"></a>                              <span class="at">new_data =</span> .)[[<span class="st">&quot;.pred&quot;</span>]]) <span class="sc">%&gt;%</span></span>
<span id="cb96-4"><a href="modeling.html#cb96-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">is.na</span>(mental_fatigue_score)) <span class="sc">%&gt;%</span></span>
<span id="cb96-5"><a href="modeling.html#cb96-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> burn_rate, <span class="at">y =</span> boost_pred)) <span class="sc">+</span></span>
<span id="cb96-6"><a href="modeling.html#cb96-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="fu">plasma</span>(<span class="dv">1</span>)) <span class="sc">+</span> </span>
<span id="cb96-7"><a href="modeling.html#cb96-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb96-8"><a href="modeling.html#cb96-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span> <span class="fu">ylim</span>(<span class="dv">0</span>,<span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb96-9"><a href="modeling.html#cb96-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb96-10"><a href="modeling.html#cb96-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;XGBoost predictions&quot;</span>,</span>
<span id="cb96-11"><a href="modeling.html#cb96-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;True score&quot;</span>,</span>
<span id="cb96-12"><a href="modeling.html#cb96-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;XGBoost performance for missing mental fatigue score&quot;</span>) <span class="sc">+</span></span>
<span id="cb96-13"><a href="modeling.html#cb96-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb96-14"><a href="modeling.html#cb96-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> ggtext<span class="sc">::</span><span class="fu">element_markdown</span>(<span class="at">size =</span> <span class="dv">11</span>))</span>
<span id="cb96-15"><a href="modeling.html#cb96-15" aria-hidden="true" tabindex="-1"></a>miss_vals_burn_yes</span></code></pre></div>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-87-2.png" width="672" /></p>
<p>The performance for the missing values is indeed not that precise but still quite good. There is at least no huge outlier detectable here. While at first glance the fact that outliers are handled naturally by the model is not astonishing it really is one the core strengths of the model to deal with messy data that includes missing and sparse data. So there is no need for imputation or a second fallback model for missing values.</p>
<p>Now it is interesting to check which model performed the best on the test data set. The results can be viewed below in tabular and graphical form.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="modeling.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the mae and the rmse for all models (random forest and xgboost)</span></span>
<span id="cb97-2"><a href="modeling.html#cb97-2" aria-hidden="true" tabindex="-1"></a>bout_test_perf <span class="ot">&lt;-</span> burnout_test <span class="sc">%&gt;%</span></span>
<span id="cb97-3"><a href="modeling.html#cb97-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rf_pred =</span> <span class="fu">predict</span>(final_bout_rf_wflow,</span>
<span id="cb97-4"><a href="modeling.html#cb97-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">new_data =</span> .)[[<span class="st">&quot;.pred&quot;</span>]],</span>
<span id="cb97-5"><a href="modeling.html#cb97-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">boost_pred =</span> <span class="fu">predict</span>(final_bout_boost_wflow,</span>
<span id="cb97-6"><a href="modeling.html#cb97-6" aria-hidden="true" tabindex="-1"></a>                              <span class="at">new_data =</span> .)[[<span class="st">&quot;.pred&quot;</span>]],</span>
<span id="cb97-7"><a href="modeling.html#cb97-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">boost_trans_pred =</span> <span class="fu">predict</span>(final_bout_boost_wflow_trans,</span>
<span id="cb97-8"><a href="modeling.html#cb97-8" aria-hidden="true" tabindex="-1"></a>                              <span class="at">new_data =</span> .)[[<span class="st">&quot;.pred&quot;</span>]],</span>
<span id="cb97-9"><a href="modeling.html#cb97-9" aria-hidden="true" tabindex="-1"></a>         <span class="co"># transform the predictions back</span></span>
<span id="cb97-10"><a href="modeling.html#cb97-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">boost_trans_pred =</span> (<span class="dv">2</span> <span class="sc">/</span> (<span class="fu">exp</span>(<span class="sc">-</span>boost_trans_pred) <span class="sc">+</span> <span class="dv">1</span>)) <span class="sc">-</span> <span class="fl">0.5</span>,</span>
<span id="cb97-11"><a href="modeling.html#cb97-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercept_pred =</span> <span class="fu">bout_predict_trivial_mean</span>(.),</span>
<span id="cb97-12"><a href="modeling.html#cb97-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">mfs_scored_pred =</span> <span class="fu">bout_predict_trivial_mfs</span>(.)) <span class="sc">%&gt;%</span></span>
<span id="cb97-13"><a href="modeling.html#cb97-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">ends_with</span>(<span class="st">&quot;pred&quot;</span>), <span class="cf">function</span>(col) {</span>
<span id="cb97-14"><a href="modeling.html#cb97-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">case_when</span>(</span>
<span id="cb97-15"><a href="modeling.html#cb97-15" aria-hidden="true" tabindex="-1"></a>      col <span class="sc">&lt;</span> <span class="dv">0</span> <span class="sc">~</span> <span class="dv">0</span>,</span>
<span id="cb97-16"><a href="modeling.html#cb97-16" aria-hidden="true" tabindex="-1"></a>      col <span class="sc">&gt;</span> <span class="dv">1</span> <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb97-17"><a href="modeling.html#cb97-17" aria-hidden="true" tabindex="-1"></a>      <span class="cn">TRUE</span> <span class="sc">~</span> col</span>
<span id="cb97-18"><a href="modeling.html#cb97-18" aria-hidden="true" tabindex="-1"></a>      )</span>
<span id="cb97-19"><a href="modeling.html#cb97-19" aria-hidden="true" tabindex="-1"></a>  })) <span class="sc">%&gt;%</span></span>
<span id="cb97-20"><a href="modeling.html#cb97-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(burn_rate, rf_pred, boost_pred, boost_trans_pred,</span>
<span id="cb97-21"><a href="modeling.html#cb97-21" aria-hidden="true" tabindex="-1"></a>         intercept_pred, mfs_scored_pred) <span class="sc">%&gt;%</span></span>
<span id="cb97-22"><a href="modeling.html#cb97-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>burn_rate, <span class="at">names_to =</span> <span class="st">&quot;model&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb97-23"><a href="modeling.html#cb97-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(model) <span class="sc">%&gt;%</span></span>
<span id="cb97-24"><a href="modeling.html#cb97-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb97-25"><a href="modeling.html#cb97-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">mae =</span> <span class="fu">mae_vec</span>(</span>
<span id="cb97-26"><a href="modeling.html#cb97-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">truth =</span> burn_rate,</span>
<span id="cb97-27"><a href="modeling.html#cb97-27" aria-hidden="true" tabindex="-1"></a>      <span class="at">estimate =</span> value</span>
<span id="cb97-28"><a href="modeling.html#cb97-28" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb97-29"><a href="modeling.html#cb97-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmse =</span> <span class="fu">rmse_vec</span>(</span>
<span id="cb97-30"><a href="modeling.html#cb97-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">truth =</span> burn_rate,</span>
<span id="cb97-31"><a href="modeling.html#cb97-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">estimate =</span> value</span>
<span id="cb97-32"><a href="modeling.html#cb97-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb97-33"><a href="modeling.html#cb97-33" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb97-34"><a href="modeling.html#cb97-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(rmse)</span>
<span id="cb97-35"><a href="modeling.html#cb97-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-36"><a href="modeling.html#cb97-36" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(bout_test_perf, <span class="at">digits =</span> <span class="dv">4</span>,</span>
<span id="cb97-37"><a href="modeling.html#cb97-37" aria-hidden="true" tabindex="-1"></a>             <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb97-38"><a href="modeling.html#cb97-38" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">&quot;Performance on the test data&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:perfBurn">Table 5.1: </span>Performance on the test data</caption>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="right">mae</th>
<th align="right">rmse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">boost_trans_pred</td>
<td align="right">0.0467</td>
<td align="right">0.0592</td>
</tr>
<tr class="even">
<td align="left">boost_pred</td>
<td align="right">0.0467</td>
<td align="right">0.0593</td>
</tr>
<tr class="odd">
<td align="left">rf_pred</td>
<td align="right">0.0474</td>
<td align="right">0.0612</td>
</tr>
<tr class="even">
<td align="left">mfs_scored_pred</td>
<td align="right">0.0628</td>
<td align="right">0.0870</td>
</tr>
<tr class="odd">
<td align="left">intercept_pred</td>
<td align="right">0.1593</td>
<td align="right">0.1980</td>
</tr>
</tbody>
</table>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<p>It can be observed that already the really simple baseline model that just scales the mental fatigue score (so it reflects just a single linear influence) has a really low MAE and RMSE. Still both random forest as well as the boosting model can further improve this metric but the huge linear influence of the mental fatigue score obviously leaves not much room for improvement. By the way the simple linear model with just this one predictor has already an <span class="math inline">\(R^2\)</span> of more than 0.92. XGBoost manages to get a slightly better performance on the test data set but this would only be nice in a machine learning competition as in real life this difference would negligible. Actually in this use case for a real life application a very easy explainable linear model might be somewhat better than a complex model like XGBoost as the difference in performance is not too big. Nevertheless in my opinion the predictor <code>mental_fatigue_score</code> should be treated with extreme care as in a real life situation the collection of this score could be as costly or hard as the one of the outcome. There might be even latent variables that are highly linearly correlated to both scores. But this data was not intended to be used in a real life application but was shared at a machine learning competition and actually many of the best submissions there used XGBoost models. The transformation of the outcome variable did actually not change the predictive power of the model as the result for both the model with the raw target as well as the one with the transformed one performed equally good. Below one can see a scatterplot comparing the individual predictions of these two models on the test set which perfectly underlines the hypothesis that the models are basically the same as there is almost no variation around the identity slope.</p>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-90-1.png" width="672" /></p>
<p>So all in all for this data set it was not a way better predictive performance (if one is not in an artificial machine learning setup) that was the core strength of the tree-based gradient boosting model but the minimal pre-processing and exploratory work (for example no interactions have to be detected manually or be tested for significance) that was needed and the natural handling of missing values to achieve the model. This of course came to a quite high computational price. The famous predictive performance could probably be displayed better when having a data set with more complex non-linear patterns.</p>
<p>This finishes the analysis of the burnout data set. But no worries there is still one data set and boosting model left to explore namely the insurance data set.</p>
</div>
</div>
<div id="insurance-data" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Insurance data</h2>
<div id="baseline-models-1" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Baseline models</h3>
<p>The first thing is to set up the trivial <strong>baseline models</strong>.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="modeling.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the trivial intercept only model:</span></span>
<span id="cb98-2"><a href="modeling.html#cb98-2" aria-hidden="true" tabindex="-1"></a>ins_predict_trivial_mean <span class="ot">&lt;-</span> <span class="cf">function</span>(new_data) {</span>
<span id="cb98-3"><a href="modeling.html#cb98-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">mean</span>(ins_train<span class="sc">$</span>log10_charges), <span class="fu">nrow</span>(new_data))</span>
<span id="cb98-4"><a href="modeling.html#cb98-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-5"><a href="modeling.html#cb98-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-6"><a href="modeling.html#cb98-6" aria-hidden="true" tabindex="-1"></a><span class="co"># the trivial linear model without any interactions (as we do not have </span></span>
<span id="cb98-7"><a href="modeling.html#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="co"># missing values does not have to be dealt with them)</span></span>
<span id="cb98-8"><a href="modeling.html#cb98-8" aria-hidden="true" tabindex="-1"></a>ins_baseline_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(log10_charges <span class="sc">~</span> age <span class="sc">+</span> sex <span class="sc">+</span> bmi <span class="sc">+</span></span>
<span id="cb98-9"><a href="modeling.html#cb98-9" aria-hidden="true" tabindex="-1"></a>                        children <span class="sc">+</span> smoker <span class="sc">+</span> region,</span>
<span id="cb98-10"><a href="modeling.html#cb98-10" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> ins_train <span class="sc">%&gt;%</span> </span>
<span id="cb98-11"><a href="modeling.html#cb98-11" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.character), as.factor)))</span>
<span id="cb98-12"><a href="modeling.html#cb98-12" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ins_baseline_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log10_charges ~ age + sex + bmi + children + smoker + 
##     region, data = ins_train %&gt;% mutate(across(where(is.character), 
##     as.factor)))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.46395 -0.08466 -0.01955  0.02643  0.93557 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      3.0685262  0.0357167  85.913  &lt; 2e-16 ***
## age              0.0149190  0.0004316  34.566  &lt; 2e-16 ***
## sexmale         -0.0251970  0.0119527  -2.108 0.035260 *  
## bmi              0.0052551  0.0010243   5.130 3.44e-07 ***
## children         0.0413979  0.0050235   8.241 5.00e-16 ***
## smokeryes        0.6841462  0.0147963  46.238  &lt; 2e-16 ***
## regionnorthwest -0.0178125  0.0172137  -1.035 0.301003    
## regionsoutheast -0.0613744  0.0172229  -3.564 0.000382 ***
## regionsouthwest -0.0512729  0.0172868  -2.966 0.003084 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1945 on 1061 degrees of freedom
## Multiple R-squared:  0.764,  Adjusted R-squared:  0.7622 
## F-statistic: 429.4 on 8 and 1061 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The predictions of these baseline models on the test data set will be compared with the predictions of the tree-based models that will be constructed.</p>
</div>
<div id="model-specification-1" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Model specification</h3>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="modeling.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Models:</span></span>
<span id="cb100-2"><a href="modeling.html#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="modeling.html#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest model for comparison</span></span>
<span id="cb100-4"><a href="modeling.html#cb100-4" aria-hidden="true" tabindex="-1"></a>ins_rf_model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(<span class="at">trees =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-5"><a href="modeling.html#cb100-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">mtry =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb100-6"><a href="modeling.html#cb100-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb100-7"><a href="modeling.html#cb100-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb100-8"><a href="modeling.html#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="modeling.html#cb100-9" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost model</span></span>
<span id="cb100-10"><a href="modeling.html#cb100-10" aria-hidden="true" tabindex="-1"></a>ins_boost_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-11"><a href="modeling.html#cb100-11" aria-hidden="true" tabindex="-1"></a>                               <span class="at">learn_rate =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-12"><a href="modeling.html#cb100-12" aria-hidden="true" tabindex="-1"></a>                               <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-13"><a href="modeling.html#cb100-13" aria-hidden="true" tabindex="-1"></a>                               <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-14"><a href="modeling.html#cb100-14" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-15"><a href="modeling.html#cb100-15" aria-hidden="true" tabindex="-1"></a>                               <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb100-16"><a href="modeling.html#cb100-16" aria-hidden="true" tabindex="-1"></a>                               <span class="at">stop_iter =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb100-17"><a href="modeling.html#cb100-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb100-18"><a href="modeling.html#cb100-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="modeling.html#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Workflows: model + recipe</span></span>
<span id="cb101-2"><a href="modeling.html#cb101-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-3"><a href="modeling.html#cb101-3" aria-hidden="true" tabindex="-1"></a>ins_rf_wflow <span class="ot">&lt;-</span></span>
<span id="cb101-4"><a href="modeling.html#cb101-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb101-5"><a href="modeling.html#cb101-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ins_rf_model) <span class="sc">%&gt;%</span></span>
<span id="cb101-6"><a href="modeling.html#cb101-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(ins_rec_rf)</span>
<span id="cb101-7"><a href="modeling.html#cb101-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-8"><a href="modeling.html#cb101-8" aria-hidden="true" tabindex="-1"></a>ins_boost_wflow <span class="ot">&lt;-</span></span>
<span id="cb101-9"><a href="modeling.html#cb101-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb101-10"><a href="modeling.html#cb101-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(ins_boost_model) <span class="sc">%&gt;%</span></span>
<span id="cb101-11"><a href="modeling.html#cb101-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(ins_rec_boost)</span></code></pre></div>
</div>
<div id="tuning-1" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Tuning</h3>
<p>For the hyperparameter tuning one needs validation sets to monitor the models on unseen data. To do this 5-fold cross validation (CV) is used here.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="modeling.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Resampling object</span></span>
<span id="cb102-2"><a href="modeling.html#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb102-3"><a href="modeling.html#cb102-3" aria-hidden="true" tabindex="-1"></a>ins_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(ins_train, <span class="at">v =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>Now the parameter objects will be fixed for the grid searches analogously to above.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="modeling.html#cb103-1" aria-hidden="true" tabindex="-1"></a>ins_rf_params <span class="ot">&lt;-</span> ins_rf_wflow <span class="sc">%&gt;%</span></span>
<span id="cb103-2"><a href="modeling.html#cb103-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb103-3"><a href="modeling.html#cb103-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">trees =</span> <span class="fu">trees</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">2000</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb103-4"><a href="modeling.html#cb103-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(ins_train)</span>
<span id="cb103-5"><a href="modeling.html#cb103-5" aria-hidden="true" tabindex="-1"></a>ins_rf_params <span class="sc">%&gt;%</span> <span class="fu">pull_dials_object</span>(<span class="st">&quot;trees&quot;</span>)</span></code></pre></div>
<pre><code>## # Trees (quantitative)
## Range: [100, 2000]</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="modeling.html#cb105-1" aria-hidden="true" tabindex="-1"></a>ins_rf_params <span class="sc">%&gt;%</span> <span class="fu">pull_dials_object</span>(<span class="st">&quot;mtry&quot;</span>)</span></code></pre></div>
<pre><code>## # Randomly Selected Predictors (quantitative)
## Range: [1, 8]</code></pre>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="modeling.html#cb107-1" aria-hidden="true" tabindex="-1"></a>ins_boost_params <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb107-2"><a href="modeling.html#cb107-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb107-3"><a href="modeling.html#cb107-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">trees =</span> <span class="fu">trees</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">2000</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb107-4"><a href="modeling.html#cb107-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(ins_train)</span>
<span id="cb107-5"><a href="modeling.html#cb107-5" aria-hidden="true" tabindex="-1"></a>ins_boost_params</span></code></pre></div>
<pre><code>## Collection of 6 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[+]
##           trees          trees nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]</code></pre>
<p>The <strong>random forest model</strong> goes first with the tuning.</p>
<p>Here there are as seen above only two hyperparameters to be tuned thus 30 combinations should suffice.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="modeling.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 2 minutes</span></span>
<span id="cb109-2"><a href="modeling.html#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb109-3"><a href="modeling.html#cb109-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb109-4"><a href="modeling.html#cb109-4" aria-hidden="true" tabindex="-1"></a>  ins_rf_tune <span class="ot">&lt;-</span> ins_rf_wflow <span class="sc">%&gt;%</span></span>
<span id="cb109-5"><a href="modeling.html#cb109-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb109-6"><a href="modeling.html#cb109-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  ins_folds,</span>
<span id="cb109-7"><a href="modeling.html#cb109-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> ins_rf_params <span class="sc">%&gt;%</span></span>
<span id="cb109-8"><a href="modeling.html#cb109-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(<span class="at">size =</span> <span class="dv">30</span>, <span class="at">original =</span> <span class="cn">FALSE</span>),</span>
<span id="cb109-9"><a href="modeling.html#cb109-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb109-10"><a href="modeling.html#cb109-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb109-11"><a href="modeling.html#cb109-11" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb109-12"><a href="modeling.html#cb109-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-13"><a href="modeling.html#cb109-13" aria-hidden="true" tabindex="-1"></a><span class="co"># visualization of the tuning results (snapshot of the output below)</span></span>
<span id="cb109-14"><a href="modeling.html#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(ins_rf_tune) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb109-15"><a href="modeling.html#cb109-15" aria-hidden="true" tabindex="-1"></a><span class="co"># this functions shows the best combinations wrt the rmse metric of all the</span></span>
<span id="cb109-16"><a href="modeling.html#cb109-16" aria-hidden="true" tabindex="-1"></a><span class="co"># combinations in the grid</span></span>
<span id="cb109-17"><a href="modeling.html#cb109-17" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_rf_tune, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:rfInstuneplot"></span>
<img src="_pictures/rf_ins_tune_plot.png" alt="Result of a spacefilling grid search for the random forest model." width="70%" />
<p class="caption">
Figure 5.5: Result of a spacefilling grid search for the random forest model.
</p>
</div>
<p>The visualization alongside the best performing results suggest that a value of <code>mtry</code>of 4 and 1000 <code>trees</code> should give good results. Thus one can finalize and fit this model.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="modeling.html#cb110-1" aria-hidden="true" tabindex="-1"></a>final_ins_rf_wflow <span class="ot">&lt;-</span> </span>
<span id="cb110-2"><a href="modeling.html#cb110-2" aria-hidden="true" tabindex="-1"></a>  ins_rf_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb110-3"><a href="modeling.html#cb110-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(<span class="fu">tibble</span>(</span>
<span id="cb110-4"><a href="modeling.html#cb110-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb110-5"><a href="modeling.html#cb110-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">4</span></span>
<span id="cb110-6"><a href="modeling.html#cb110-6" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb110-7"><a href="modeling.html#cb110-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(ins_train)</span></code></pre></div>
<p>Now the <strong>boosting model</strong>.</p>
<p>Again one starts to tune over the number of trees first (this time we also use three different tree depths to visualize the impact of this parameter too)</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="modeling.html#cb111-1" aria-hidden="true" tabindex="-1"></a>first_grid_boost_ins <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb111-2"><a href="modeling.html#cb111-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">250</span>, <span class="dv">2000</span>, <span class="dv">250</span>),</span>
<span id="cb111-3"><a href="modeling.html#cb111-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">8</span>,</span>
<span id="cb111-4"><a href="modeling.html#cb111-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">6</span>),</span>
<span id="cb111-5"><a href="modeling.html#cb111-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fl">0.000001</span>,</span>
<span id="cb111-6"><a href="modeling.html#cb111-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb111-7"><a href="modeling.html#cb111-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb111-8"><a href="modeling.html#cb111-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="modeling.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly half a minute</span></span>
<span id="cb112-2"><a href="modeling.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb112-3"><a href="modeling.html#cb112-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb112-4"><a href="modeling.html#cb112-4" aria-hidden="true" tabindex="-1"></a>  ins_boost_tune_first <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb112-5"><a href="modeling.html#cb112-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb112-6"><a href="modeling.html#cb112-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  ins_folds,</span>
<span id="cb112-7"><a href="modeling.html#cb112-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> first_grid_boost_ins,</span>
<span id="cb112-8"><a href="modeling.html#cb112-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb112-9"><a href="modeling.html#cb112-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb112-10"><a href="modeling.html#cb112-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb112-11"><a href="modeling.html#cb112-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-12"><a href="modeling.html#cb112-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-13"><a href="modeling.html#cb112-13" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_boost_tune_first)</span></code></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="modeling.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the tuning results (output in the figure below)</span></span>
<span id="cb113-2"><a href="modeling.html#cb113-2" aria-hidden="true" tabindex="-1"></a>ins_boost_tune_first <span class="sc">%&gt;%</span></span>
<span id="cb113-3"><a href="modeling.html#cb113-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb113-4"><a href="modeling.html#cb113-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> trees, <span class="at">y =</span> mean, <span class="at">col =</span> <span class="fu">factor</span>(tree_depth))) <span class="sc">+</span></span>
<span id="cb113-5"><a href="modeling.html#cb113-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb113-6"><a href="modeling.html#cb113-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb113-7"><a href="modeling.html#cb113-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> std_err, <span class="at">ymax =</span> mean <span class="sc">+</span> std_err)) <span class="sc">+</span></span>
<span id="cb113-8"><a href="modeling.html#cb113-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">col =</span> <span class="st">&quot;Max tree depth&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Number of trees&quot;</span>,</span>
<span id="cb113-9"><a href="modeling.html#cb113-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb113-10"><a href="modeling.html#cb113-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">option =</span> <span class="st">&quot;C&quot;</span>) <span class="sc">+</span></span>
<span id="cb113-11"><a href="modeling.html#cb113-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric) <span class="sc">+</span></span>
<span id="cb113-12"><a href="modeling.html#cb113-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:boostInstuneplot1"></span>
<img src="_pictures/boost_ins_tune_plot1.png" alt="Comparison of the initial grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates." width="70%" />
<p class="caption">
Figure 5.6: Comparison of the initial grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates.
</p>
</div>
<p>This visualization clearly shows that one has to have a closer look at the region around 500 trees. More than 500 trees might lead to overfitting as seen here.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="modeling.html#cb114-1" aria-hidden="true" tabindex="-1"></a>second_grid_boost_ins <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb114-2"><a href="modeling.html#cb114-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">250</span>, <span class="dv">750</span>, <span class="dv">50</span>),</span>
<span id="cb114-3"><a href="modeling.html#cb114-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">8</span>,</span>
<span id="cb114-4"><a href="modeling.html#cb114-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>),</span>
<span id="cb114-5"><a href="modeling.html#cb114-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fl">0.000001</span>,</span>
<span id="cb114-6"><a href="modeling.html#cb114-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fl">0.01</span>,</span>
<span id="cb114-7"><a href="modeling.html#cb114-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb114-8"><a href="modeling.html#cb114-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="modeling.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 15 seconds</span></span>
<span id="cb115-2"><a href="modeling.html#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb115-3"><a href="modeling.html#cb115-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb115-4"><a href="modeling.html#cb115-4" aria-hidden="true" tabindex="-1"></a>  ins_boost_tune_second <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb115-5"><a href="modeling.html#cb115-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb115-6"><a href="modeling.html#cb115-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  ins_folds,</span>
<span id="cb115-7"><a href="modeling.html#cb115-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> second_grid_boost_ins,</span>
<span id="cb115-8"><a href="modeling.html#cb115-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb115-9"><a href="modeling.html#cb115-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb115-10"><a href="modeling.html#cb115-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb115-11"><a href="modeling.html#cb115-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-12"><a href="modeling.html#cb115-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-13"><a href="modeling.html#cb115-13" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_boost_tune_second)</span></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="modeling.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the tuning results (output in the figure below)</span></span>
<span id="cb116-2"><a href="modeling.html#cb116-2" aria-hidden="true" tabindex="-1"></a>ins_boost_tune_second <span class="sc">%&gt;%</span></span>
<span id="cb116-3"><a href="modeling.html#cb116-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb116-4"><a href="modeling.html#cb116-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> trees, <span class="at">y =</span> mean, <span class="at">col =</span> <span class="fu">factor</span>(tree_depth))) <span class="sc">+</span></span>
<span id="cb116-5"><a href="modeling.html#cb116-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb116-6"><a href="modeling.html#cb116-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb116-7"><a href="modeling.html#cb116-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> std_err, <span class="at">ymax =</span> mean <span class="sc">+</span> std_err)) <span class="sc">+</span></span>
<span id="cb116-8"><a href="modeling.html#cb116-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">col =</span> <span class="st">&quot;Max tree depth&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Number of trees&quot;</span>,</span>
<span id="cb116-9"><a href="modeling.html#cb116-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb116-10"><a href="modeling.html#cb116-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">option =</span> <span class="st">&quot;C&quot;</span>) <span class="sc">+</span></span>
<span id="cb116-11"><a href="modeling.html#cb116-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric) <span class="sc">+</span></span>
<span id="cb116-12"><a href="modeling.html#cb116-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:boostInstuneplot2"></span>
<img src="_pictures/boost_ins_tune_plot2.png" alt="Comparison of the second grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates." width="70%" />
<p class="caption">
Figure 5.7: Comparison of the second grid search for the number of trees w.r.t. the maximum tree depth. Actually with tiny confidence bands around the estimates.
</p>
</div>
<p>So from this visualization one can conclude that a number of trees of 600 should suffice to get a decent model. So the workflow will be updated and the number of trees fixed. After that the first major space filling grid search will be performed. Moreover with the previous visualizations in mind one can reduce the bound of the parameter space of the maximum tree depth quite a bit from 15 to 9. A minimum tree depth of 2 seems also appropriate.
Before one does that mainly for a view on the influence of the learning rate one can tune one round only with the learning rate and some tree numbers for comparison.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="modeling.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tune mainly learn rate</span></span>
<span id="cb117-2"><a href="modeling.html#cb117-2" aria-hidden="true" tabindex="-1"></a>lrate_grid_boost_ins <span class="ot">&lt;-</span> <span class="fu">crossing</span>(</span>
<span id="cb117-3"><a href="modeling.html#cb117-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="fu">seq</span>(<span class="dv">200</span>, <span class="dv">1500</span>, <span class="dv">100</span>),</span>
<span id="cb117-4"><a href="modeling.html#cb117-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="dv">8</span>,</span>
<span id="cb117-5"><a href="modeling.html#cb117-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="fu">c</span>(<span class="dv">3</span>),</span>
<span id="cb117-6"><a href="modeling.html#cb117-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fu">c</span>(<span class="fl">0.000001</span>),</span>
<span id="cb117-7"><a href="modeling.html#cb117-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.01</span>, <span class="fl">0.001</span>, <span class="fl">0.0001</span>),</span>
<span id="cb117-8"><a href="modeling.html#cb117-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="dv">1</span></span>
<span id="cb117-9"><a href="modeling.html#cb117-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="modeling.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 20 seconds</span></span>
<span id="cb118-2"><a href="modeling.html#cb118-2" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb118-3"><a href="modeling.html#cb118-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb118-4"><a href="modeling.html#cb118-4" aria-hidden="true" tabindex="-1"></a>  ins_boost_tune_lrate <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb118-5"><a href="modeling.html#cb118-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb118-6"><a href="modeling.html#cb118-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span>  ins_folds,</span>
<span id="cb118-7"><a href="modeling.html#cb118-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> lrate_grid_boost_ins,</span>
<span id="cb118-8"><a href="modeling.html#cb118-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb118-9"><a href="modeling.html#cb118-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb118-10"><a href="modeling.html#cb118-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb118-11"><a href="modeling.html#cb118-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-12"><a href="modeling.html#cb118-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-13"><a href="modeling.html#cb118-13" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_boost_tune_lrate)</span></code></pre></div>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="modeling.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the tuning results (output in the figure below)</span></span>
<span id="cb119-2"><a href="modeling.html#cb119-2" aria-hidden="true" tabindex="-1"></a>ins_boost_tune_lrate <span class="sc">%&gt;%</span></span>
<span id="cb119-3"><a href="modeling.html#cb119-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span></span>
<span id="cb119-4"><a href="modeling.html#cb119-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> trees, <span class="at">y =</span> mean, <span class="at">col =</span> <span class="fu">factor</span>(learn_rate))) <span class="sc">+</span></span>
<span id="cb119-5"><a href="modeling.html#cb119-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb119-6"><a href="modeling.html#cb119-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb119-7"><a href="modeling.html#cb119-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> mean <span class="sc">-</span> std_err, <span class="at">ymax =</span> mean <span class="sc">+</span> std_err)) <span class="sc">+</span></span>
<span id="cb119-8"><a href="modeling.html#cb119-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of trees&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">col =</span> <span class="st">&quot;Learning rate&quot;</span>,</span>
<span id="cb119-9"><a href="modeling.html#cb119-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;&quot;</span>) <span class="sc">+</span></span>
<span id="cb119-10"><a href="modeling.html#cb119-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">option =</span> <span class="st">&quot;C&quot;</span>) <span class="sc">+</span></span>
<span id="cb119-11"><a href="modeling.html#cb119-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> .metric) <span class="sc">+</span></span>
<span id="cb119-12"><a href="modeling.html#cb119-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:boostInstuneplotlrate"></span>
<img src="_pictures/boost_ins_tune_lrate.png" alt="Comparison of the grid search for the number of trees w.r.t. the learning rate. Actually with tiny confidence bands around the estimates." width="70%" />
<p class="caption">
Figure 5.8: Comparison of the grid search for the number of trees w.r.t. the learning rate. Actually with tiny confidence bands around the estimates.
</p>
</div>
<p>This showcases the fact that indeed a learning rate that is too small can blow up the computational costs.</p>
<p>Now fix the number of the <code>trees</code> hyperparameter.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="modeling.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix the number of trees by redefining the boostin model with a </span></span>
<span id="cb120-2"><a href="modeling.html#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="co"># fixed number of trees.</span></span>
<span id="cb120-3"><a href="modeling.html#cb120-3" aria-hidden="true" tabindex="-1"></a>ins_boost_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(<span class="at">trees =</span> <span class="dv">600</span>,</span>
<span id="cb120-4"><a href="modeling.html#cb120-4" aria-hidden="true" tabindex="-1"></a>                               <span class="at">learn_rate =</span> <span class="fu">tune</span>(),</span>
<span id="cb120-5"><a href="modeling.html#cb120-5" aria-hidden="true" tabindex="-1"></a>                               <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb120-6"><a href="modeling.html#cb120-6" aria-hidden="true" tabindex="-1"></a>                               <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb120-7"><a href="modeling.html#cb120-7" aria-hidden="true" tabindex="-1"></a>                               <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb120-8"><a href="modeling.html#cb120-8" aria-hidden="true" tabindex="-1"></a>                               <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb120-9"><a href="modeling.html#cb120-9" aria-hidden="true" tabindex="-1"></a>                               <span class="at">stop_iter =</span> <span class="dv">10</span>) <span class="sc">%&gt;%</span></span>
<span id="cb120-10"><a href="modeling.html#cb120-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;xgboost&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb120-11"><a href="modeling.html#cb120-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb120-12"><a href="modeling.html#cb120-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-13"><a href="modeling.html#cb120-13" aria-hidden="true" tabindex="-1"></a><span class="co"># update the workflow</span></span>
<span id="cb120-14"><a href="modeling.html#cb120-14" aria-hidden="true" tabindex="-1"></a>ins_boost_wflow <span class="ot">&lt;-</span></span>
<span id="cb120-15"><a href="modeling.html#cb120-15" aria-hidden="true" tabindex="-1"></a>  ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb120-16"><a href="modeling.html#cb120-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_model</span>(ins_boost_model)</span>
<span id="cb120-17"><a href="modeling.html#cb120-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-18"><a href="modeling.html#cb120-18" aria-hidden="true" tabindex="-1"></a>ins_boost_params <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb120-19"><a href="modeling.html#cb120-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">parameters</span>() <span class="sc">%&gt;%</span></span>
<span id="cb120-20"><a href="modeling.html#cb120-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update</span>(<span class="at">tree_depth =</span> <span class="fu">tree_depth</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">9</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb120-21"><a href="modeling.html#cb120-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize</span>(ins_train)</span>
<span id="cb120-22"><a href="modeling.html#cb120-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-23"><a href="modeling.html#cb120-23" aria-hidden="true" tabindex="-1"></a><span class="co"># reduced hyperparameter space</span></span>
<span id="cb120-24"><a href="modeling.html#cb120-24" aria-hidden="true" tabindex="-1"></a>ins_boost_params</span></code></pre></div>
<pre><code>## Collection of 5 parameters for tuning
## 
##      identifier           type    object
##            mtry           mtry nparam[+]
##      tree_depth     tree_depth nparam[+]
##      learn_rate     learn_rate nparam[+]
##  loss_reduction loss_reduction nparam[+]
##     sample_size    sample_size nparam[+]</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="modeling.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now tune all the remaining hyperparameters with a large space filling grid</span></span>
<span id="cb122-2"><a href="modeling.html#cb122-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-3"><a href="modeling.html#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 10 minutes</span></span>
<span id="cb122-4"><a href="modeling.html#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb122-5"><a href="modeling.html#cb122-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb122-6"><a href="modeling.html#cb122-6" aria-hidden="true" tabindex="-1"></a>  ins_boost_tune_major1 <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb122-7"><a href="modeling.html#cb122-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb122-8"><a href="modeling.html#cb122-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span> ins_folds,</span>
<span id="cb122-9"><a href="modeling.html#cb122-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> ins_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb122-10"><a href="modeling.html#cb122-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(</span>
<span id="cb122-11"><a href="modeling.html#cb122-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">size =</span> <span class="dv">300</span>),</span>
<span id="cb122-12"><a href="modeling.html#cb122-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb122-13"><a href="modeling.html#cb122-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb122-14"><a href="modeling.html#cb122-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb122-15"><a href="modeling.html#cb122-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-16"><a href="modeling.html#cb122-16" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_boost_tune_major1, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:insparallelcoord"></span>
<img src="_pictures/tuning_ins_parallelcoord.png" alt="Visualize the tuning results with a parallel coordinate plot. The y axis represents the scaled range for each of the hyperparameter spaces." width="70%" />
<p class="caption">
Figure 5.9: Visualize the tuning results with a parallel coordinate plot. The y axis represents the scaled range for each of the hyperparameter spaces.
</p>
</div>
<p>The most prominent suggestions of the visualizations and the table of the best performing ones are combinations of hyperparameters with a very low <code>loss_reduction</code> , a low <code>learn_rate</code>, a medium to high value of <code>mtry</code>, a not too big <code>tree_depth</code> as well as a rather high value for the <code>sample_size</code>.
These observations will be used to refine the search space and perform once more a space filling grid search.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="modeling.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># now tune all the remaining hyperparameters with a refined space filling grid</span></span>
<span id="cb123-2"><a href="modeling.html#cb123-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-3"><a href="modeling.html#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="co"># took roughly 15 minutes</span></span>
<span id="cb123-4"><a href="modeling.html#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({</span>
<span id="cb123-5"><a href="modeling.html#cb123-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb123-6"><a href="modeling.html#cb123-6" aria-hidden="true" tabindex="-1"></a>  ins_boost_tune_major2 <span class="ot">&lt;-</span> ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb123-7"><a href="modeling.html#cb123-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tune_grid</span>(</span>
<span id="cb123-8"><a href="modeling.html#cb123-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">resamples =</span> ins_folds,</span>
<span id="cb123-9"><a href="modeling.html#cb123-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">grid =</span> ins_boost_params <span class="sc">%&gt;%</span></span>
<span id="cb123-10"><a href="modeling.html#cb123-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">update</span>(</span>
<span id="cb123-11"><a href="modeling.html#cb123-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">mtry =</span> <span class="fu">mtry</span>(<span class="fu">c</span>(<span class="dv">6</span>,<span class="dv">8</span>)),</span>
<span id="cb123-12"><a href="modeling.html#cb123-12" aria-hidden="true" tabindex="-1"></a>          <span class="at">tree_depth =</span> <span class="fu">tree_depth</span>(<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">4</span>)),</span>
<span id="cb123-13"><a href="modeling.html#cb123-13" aria-hidden="true" tabindex="-1"></a>          <span class="at">learn_rate =</span> <span class="fu">learn_rate</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.7</span>, <span class="sc">-</span><span class="fl">1.5</span>)),</span>
<span id="cb123-14"><a href="modeling.html#cb123-14" aria-hidden="true" tabindex="-1"></a>          <span class="at">loss_reduction =</span> <span class="fu">loss_reduction</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="sc">-</span><span class="fl">1.5</span>)),</span>
<span id="cb123-15"><a href="modeling.html#cb123-15" aria-hidden="true" tabindex="-1"></a>          <span class="at">sample_size =</span> <span class="fu">sample_prop</span>(<span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.9</span>))</span>
<span id="cb123-16"><a href="modeling.html#cb123-16" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">%&gt;%</span></span>
<span id="cb123-17"><a href="modeling.html#cb123-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">grid_latin_hypercube</span>(</span>
<span id="cb123-18"><a href="modeling.html#cb123-18" aria-hidden="true" tabindex="-1"></a>          <span class="at">size =</span> <span class="dv">300</span>),</span>
<span id="cb123-19"><a href="modeling.html#cb123-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">metrics =</span> regr_metrics</span>
<span id="cb123-20"><a href="modeling.html#cb123-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb123-21"><a href="modeling.html#cb123-21" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb123-22"><a href="modeling.html#cb123-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-23"><a href="modeling.html#cb123-23" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(ins_boost_tune_major2, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<p>The results from this grid search were quite clear. One will further use a <code>mtry</code> value of 7, a <code>tree_depth</code> of 3, a <code>learn_rate</code> of 0.02, a <code>loss_reduction</code> of 0.03 and a <code>sample_size</code> of 0.8.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="modeling.html#cb124-1" aria-hidden="true" tabindex="-1"></a>final_ins_boost_wflow <span class="ot">&lt;-</span> </span>
<span id="cb124-2"><a href="modeling.html#cb124-2" aria-hidden="true" tabindex="-1"></a>  ins_boost_wflow <span class="sc">%&gt;%</span> </span>
<span id="cb124-3"><a href="modeling.html#cb124-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(<span class="fu">tibble</span>(</span>
<span id="cb124-4"><a href="modeling.html#cb124-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">7</span>,</span>
<span id="cb124-5"><a href="modeling.html#cb124-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">tree_depth =</span> <span class="dv">3</span>,</span>
<span id="cb124-6"><a href="modeling.html#cb124-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">learn_rate =</span> <span class="fl">0.02</span>,</span>
<span id="cb124-7"><a href="modeling.html#cb124-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss_reduction =</span> <span class="fl">0.03</span>,</span>
<span id="cb124-8"><a href="modeling.html#cb124-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> <span class="fl">0.8</span></span>
<span id="cb124-9"><a href="modeling.html#cb124-9" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">%&gt;%</span></span>
<span id="cb124-10"><a href="modeling.html#cb124-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(ins_train)</span></code></pre></div>
<p>From here no computational intensive task will be performed so one stops the cluster.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="modeling.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># stop cluster</span></span>
<span id="cb125-2"><a href="modeling.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cl)</span></code></pre></div>
</div>
<div id="evaluate-and-understand-the-model-1" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Evaluate and understand the model</h3>
<p>First a visualization of the variable importance. The variable importance is again calculated by measuring the gain w.r.t. the loss of each feature in the single trees and splits.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="modeling.html#cb126-1" aria-hidden="true" tabindex="-1"></a>vip_ins <span class="ot">&lt;-</span> final_ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb126-2"><a href="modeling.html#cb126-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>() <span class="sc">%&gt;%</span></span>
<span id="cb126-3"><a href="modeling.html#cb126-3" aria-hidden="true" tabindex="-1"></a>  vip<span class="sc">::</span><span class="fu">vip</span>() <span class="sc">+</span> </span>
<span id="cb126-4"><a href="modeling.html#cb126-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb126-5"><a href="modeling.html#cb126-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Variable importance of the XGBoost model&quot;</span>)</span>
<span id="cb126-6"><a href="modeling.html#cb126-6" aria-hidden="true" tabindex="-1"></a>vip_ins</span></code></pre></div>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="modeling.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsave</span>(<span class="st">&quot;_pictures/vip_ins.png&quot;</span>, <span class="at">plot =</span> vip_ins)</span>
<span id="cb127-2"><a href="modeling.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">remove</span>(vip_ins)</span></code></pre></div>
<p>Here one can clearly see that the trends that were observable during the EDA are reflected here again. The most influential variable is indeed the smoker variable, closely followed by the age variable. Also the bmi and the number of children seem to be relevant. To get an even better sense for where which variable was mostly used one can have a look at the visualization below which shows the final model in a compressed form as a single tree. At each node the most important (again by the feature importance score like above) 5 variables are listed with their respective raw importance scores in brackets. The ‘Leaf’ variable just corresponds to the case where trees ended at this point.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="modeling.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization of the ensemble of trees as a single collective unit</span></span>
<span id="cb128-2"><a href="modeling.html#cb128-2" aria-hidden="true" tabindex="-1"></a>final_ins_boost_fit <span class="ot">&lt;-</span> final_ins_boost_wflow <span class="sc">%&gt;%</span></span>
<span id="cb128-3"><a href="modeling.html#cb128-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull_workflow_fit</span>()</span>
<span id="cb128-4"><a href="modeling.html#cb128-4" aria-hidden="true" tabindex="-1"></a>final_ins_boost_fit<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb128-5"><a href="modeling.html#cb128-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.plot.multi.trees</span>(<span class="at">render =</span> T)</span>
<span id="cb128-6"><a href="modeling.html#cb128-6" aria-hidden="true" tabindex="-1"></a><span class="co"># output as figure below as this returns a htmlwidget which is not that</span></span>
<span id="cb128-7"><a href="modeling.html#cb128-7" aria-hidden="true" tabindex="-1"></a><span class="co"># intuitively handled by latex (pdf output)</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:insmultitree"></span>
<img src="_pictures/ins_multitree_xgb.png" alt="Visualization of the final ensemble of trees as a single collective unit." width="70%" />
<p class="caption">
Figure 5.10: Visualization of the final ensemble of trees as a single collective unit.
</p>
</div>
<p>It is quite interesting to see that most of the time the smoker feature was used just once in the first node but not multiple times. This suggests a quite linear influence of smokers and of course the binary character of the feature can support this behavior. Age on the other hand is represented in multiple depths with high importance which suggests a non-linear influence which was also visible during the EDA. Interestingly the children variable for example mostly is used at depth 3 for a split.</p>
<p>Also a residual plot of the XGBoost predictions on the test data set can shed some light on the way the model works. This 3D plot is an interactive html widget which works not in the pdf output but just on the website. Besides the residuals on the test set also the residuals on the training data set are shown below</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="modeling.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare the data for plotting i.e. calculate raw residuals on the test </span></span>
<span id="cb129-2"><a href="modeling.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and the training data</span></span>
<span id="cb129-3"><a href="modeling.html#cb129-3" aria-hidden="true" tabindex="-1"></a>resid_plot_ins_data_test <span class="ot">&lt;-</span> ins_test <span class="sc">%&gt;%</span></span>
<span id="cb129-4"><a href="modeling.html#cb129-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="at">pred =</span> <span class="fu">predict</span>(final_ins_boost_wflow, <span class="at">new_data =</span> ins_test)[[<span class="st">&quot;.pred&quot;</span>]]) <span class="sc">%&gt;%</span></span>
<span id="cb129-5"><a href="modeling.html#cb129-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">resid =</span> charges <span class="sc">-</span> <span class="dv">10</span><span class="sc">^</span>pred)</span>
<span id="cb129-6"><a href="modeling.html#cb129-6" aria-hidden="true" tabindex="-1"></a>resid_plot_ins_data_train <span class="ot">&lt;-</span> ins_train <span class="sc">%&gt;%</span></span>
<span id="cb129-7"><a href="modeling.html#cb129-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="at">pred =</span> <span class="fu">predict</span>(final_ins_boost_wflow, <span class="at">new_data =</span> ins_train)[[<span class="st">&quot;.pred&quot;</span>]]) <span class="sc">%&gt;%</span></span>
<span id="cb129-8"><a href="modeling.html#cb129-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">resid =</span> charges <span class="sc">-</span> <span class="dv">10</span><span class="sc">^</span>pred)</span>
<span id="cb129-9"><a href="modeling.html#cb129-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-10"><a href="modeling.html#cb129-10" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(resid_plot_ins_data_test,</span>
<span id="cb129-11"><a href="modeling.html#cb129-11" aria-hidden="true" tabindex="-1"></a>     resid_plot_ins_data_train,</span>
<span id="cb129-12"><a href="modeling.html#cb129-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">file =</span> <span class="st">&quot;_data/resid_data_ins.RData&quot;</span>)</span>
<span id="cb129-13"><a href="modeling.html#cb129-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-14"><a href="modeling.html#cb129-14" aria-hidden="true" tabindex="-1"></a><span class="co"># test residuals</span></span>
<span id="cb129-15"><a href="modeling.html#cb129-15" aria-hidden="true" tabindex="-1"></a>resid_plot_ins_data_test <span class="sc">%&gt;%</span></span>
<span id="cb129-16"><a href="modeling.html#cb129-16" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">plot_ly</span>(<span class="at">x =</span> <span class="sc">~</span>age, <span class="at">z =</span> <span class="sc">~</span>resid, <span class="at">y =</span> <span class="sc">~</span>bmi,</span>
<span id="cb129-17"><a href="modeling.html#cb129-17" aria-hidden="true" tabindex="-1"></a>                  <span class="at">color =</span> <span class="sc">~</span><span class="fu">factor</span>(smoker),</span>
<span id="cb129-18"><a href="modeling.html#cb129-18" aria-hidden="true" tabindex="-1"></a>                  <span class="at">symbol =</span> <span class="sc">~</span><span class="fu">factor</span>(smoker),</span>
<span id="cb129-19"><a href="modeling.html#cb129-19" aria-hidden="true" tabindex="-1"></a>                  <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste</span>(<span class="st">&quot;Age:&quot;</span>, age, <span class="st">&quot;BMI:&quot;</span>, bmi),</span>
<span id="cb129-20"><a href="modeling.html#cb129-20" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hoverinfo =</span> <span class="st">&quot;text&quot;</span>,</span>
<span id="cb129-21"><a href="modeling.html#cb129-21" aria-hidden="true" tabindex="-1"></a>                  <span class="at">symbols =</span> <span class="fu">c</span>(<span class="st">&#39;x&#39;</span>,<span class="st">&#39;circle&#39;</span>),</span>
<span id="cb129-22"><a href="modeling.html#cb129-22" aria-hidden="true" tabindex="-1"></a>                  <span class="at">colors =</span> <span class="fu">plasma</span>(<span class="dv">3</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb129-23"><a href="modeling.html#cb129-23" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">add_markers</span>(<span class="at">opacity =</span> <span class="fl">0.9</span>,</span>
<span id="cb129-24"><a href="modeling.html#cb129-24" aria-hidden="true" tabindex="-1"></a>                      <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb129-25"><a href="modeling.html#cb129-25" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">layout</span>(<span class="at">scene =</span> <span class="fu">list</span>(</span>
<span id="cb129-26"><a href="modeling.html#cb129-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;Age&quot;</span>),</span>
<span id="cb129-27"><a href="modeling.html#cb129-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;BMI&quot;</span>),</span>
<span id="cb129-28"><a href="modeling.html#cb129-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">zaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;Raw residuals&quot;</span>)),</span>
<span id="cb129-29"><a href="modeling.html#cb129-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Raw test residuals of the insurance XGBoost model&quot;</span>,</span>
<span id="cb129-30"><a href="modeling.html#cb129-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="fu">list</span>(<span class="at">text =</span> <span class="st">&quot;Smoker&quot;</span>)))</span></code></pre></div>
<div id="htmlwidget-fff7cdbc7f44e62ab8ba" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-fff7cdbc7f44e62ab8ba">{"x":{"visdat":{"2ffc77df7b58":["function () ","plotlyVisDat"]},"cur_data":"2ffc77df7b58","attrs":{"2ffc77df7b58":{"x":{},"z":{},"y":{},"text":{},"hoverinfo":"text","color":{},"symbol":{},"colors":["#CC4678FF","#0D0887FF"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"symbols":["x","circle"],"type":"scatter3d","mode":"markers","opacity":0.9,"size":2,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Age"},"yaxis":{"title":"BMI"},"zaxis":{"title":"Raw residuals"}},"title":"Raw test residuals of the insurance XGBoost model","legend":{"title":{"text":"Smoker"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[18,32,31,52,23,19,24,18,64,28,40,31,53,58,57,31,54,55,41,52,37,18,20,53,48,54,41,18,63,40,53,26,24,41,47,59,44,19,55,58,53,19,52,28,58,49,52,34,26,57,52,64,49,34,57,33,49,56,57,64,62,48,52,38,19,52,25,60,35,40,35,39,24,57,62,18,63,54,31,37,22,51,38,33,20,25,46,34,19,19,18,62,25,19,27,28,59,29,24,51,48,39,48,18,19,33,53,40,24,56,47,33,62,18,45,21,58,24,31,47,64,38,61,44,45,31,22,39,64,18,46,36,60,63,35,51,25,57,55,51,40,50,33,41,23,61,26,60,44,22,44,24,34,62,26,18,19,31,24,46,52,35,39,34,22,19,50,28,21,61,54,64,36,60,32,32,57,52,23,18,49,50,26,41,52,35,36,20,32,43,32,37,19,22,59,41,56,58,58,45,18,28,55,43,35,22,18,58,20,18,18,51,57,23,18],"z":[-559.895768193102,-285.798447994573,166.160130995318,-1640.34546472001,-841.651523903832,358.447628157622,-169.701965867938,-685.081443005199,16349.4056686668,-851.692829443274,-630.121902461979,649.245475345141,-452.425878910602,-880.912683262219,-910.731849348191,-674.572891311772,-163.325438080859,-2205.40390170798,36.2723567525627,-1208.78049151623,-941.930253981824,-113.909497029493,-191.837734497546,-753.384252870612,-2553.60361276063,-1250.74403447937,-123.883329375256,-595.89018115075,341.697428494565,-1218.13011500114,-1031.72258178435,-70.6149855363142,22468.5031571188,-373.123834813202,-1588.93863486007,-660.158989675843,-1458.67365176814,-3.91786930278226,-893.050836708253,-809.210589437957,7369.62281165481,-2606.77076780426,14041.3679410583,14764.7693435901,-597.996093318228,-1580.31807113277,-2056.82324085295,-1291.89613148762,18095.4773045501,-1719.98399330942,-1754.44106426169,1030.66515862553,-1048.59123360993,-427.982526652509,-797.531410734979,7295.34928621457,-1223.46757021579,-266.564344534811,-312.410136150553,1307.38303704728,13019.2141432638,-1422.45690857707,-2868.01579405431,81.2832558119817,-366.305118199377,-2138.8987348861,-274.861084923185,-1493.32988046182,-470.80782272924,-809.911007089193,-1322.42280813002,-1134.61649916576,-508.49528427246,-1134.90393368421,-2044.85137737716,-385.544020862301,-2618.68783885339,301.600056090625,-103.73665774984,-660.974884838872,-133.356362446797,-1285.87555137442,-571.525150974553,-289.278966909756,-1149.03383917436,14656.0284826427,-1073.90284508596,-1038.02324878726,-442.033568384102,-499.027511288761,-443.822468965725,16735.9909808734,67.3341905862767,-189.006796546968,-432.275690601863,-1557.52250871349,-838.544728485411,-252.249682422645,-737.826652866634,-914.959418759438,-884.52521405699,-699.718741028778,-1531.72950749062,-664.541092690685,-189.562796546968,-741.404083151854,-1349.60262615873,-693.386120146081,-387.804914584638,-826.896535287045,-1108.83551031424,-745.994750846805,-478.024898887792,-364.807492050718,-1309.16907944847,-241.059658766796,-516.088293490186,11587.8603010242,-938.896810272773,-1089.59547811426,516.90512356317,-211.530320187307,14257.0397157496,3875.86341226283,-1971.4171332944,-293.119337664407,186.178458810755,-812.039778157851,43.1967593313657,-725.978883562773,314.191336495951,-1020.05304791368,-1018.397174133,-1230.58334056061,-923.488425507269,-206.322216716055,14836.506636078,-1156.96702894438,-914.597768840076,-1266.22282907153,-632.500519165698,-1556.36669025607,-282.964617493845,-512.550192151025,-1347.71425127897,19.5674783858667,-488.456637490524,-532.143219107114,-1012.05218233062,-104.062123364966,-1212.32022903771,-120.250240677897,-1084.79113764454,-620.882156794403,136.521664733659,-1175.3865312323,-229.579594716033,-730.538419795329,9087.55011919952,-290.766328712811,13682.8364774795,-1367.11256404613,131.918320950323,-491.83622891452,172.58588479824,-161.314058819569,-665.737158187845,-1459.35424436821,-135.139800021246,-1745.89624219914,-52.2766259278251,528.317876464553,-318.739453299797,-206.737440092335,-715.755614900831,-511.282084148733,-925.349584204841,-961.382813943577,-776.757414875316,-982.541502990347,-1308.3291535601,-1120.1848119651,-271.895676021659,539.238964873791,15765.235406239,-978.920710768336,-95.3123198050644,-445.884874425795,-98.4091044249517,-983.708397936819,-486.430387347862,-662.698381734972,12483.2458632989,-100.634486318195,23496.4629312962,-579.585257359172,-1366.74477791316,-880.483090145364,136.916002460091,-869.632988496947,-631.362709349541,180.949020693814,16017.4165304662,-989.115460874464,-1239.17838050253,-28.6927859825091,-685.317753667974,-728.137358275964,-217.945051653008,-100.830546113186,8849.71320341624,-1148.4343694331,-1029.95396393204,7952.25535406233,-503.287510573287],"y":[33.77,28.88,25.74,30.78,23.845,28.6,26.6,35.625,24.7,25.935,36.19,28.5,28.1,32.01,34.01,26.885,30.8,38.28,31.6,32.205,23.37,23.75,28.975,35.9,29.7,39.6,32.2,34.43,31.8,41.23,26.6,29.92,23.21,31.635,25.46,27.83,38.06,20.9,25.365,25.2,38.06,20.615,26.4,27.5,34.865,35.86,33.25,25.27,29.64,40.945,36.7,34.5,41.47,29.26,23.18,35.245,30.78,32.3,22.23,30.115,31.46,31.445,38.38,21.12,17.48,34.1,30.59,33.11,28.9,29.6,38.6,29.6,23.4,30.495,38.095,24.09,41.325,21.47,23.6,30.875,31.35,22.42,28.025,38.9,31.79,41.325,33.44,34.21,35.53,30.495,37.29,36.86,23.465,20.7,25.175,26.98,28.785,26.03,29.3,39.7,30.78,26.22,31.13,33.66,20.3,18.5,26.41,41.69,23.655,33.725,29.545,32.9,37.4,40.28,24.035,28.975,22.77,33.63,27.645,32.3,39.7,19.475,36.1,36.48,39.805,29.26,23.18,31.92,35.97,30.14,30.8,34.43,24.32,33.1,23.465,34.2,32.23,28.1,33.535,25.4,29.9,36.2,33.44,28.8,27.36,44,27.265,35.1,32.34,28.31,27.5,33.99,35.815,39.16,46.53,26.18,22.61,39.49,26.79,24.795,36.765,27.1,34.32,23.56,20.235,40.5,31.6,29.26,34.6,38.38,23,26.41,28.595,18.335,27.835,31.5,31.54,47.74,32.7,31.35,29.925,26.22,30,32.6,24.86,35.815,22.135,30.59,41.1,34.58,35.2,34.105,27.93,32.11,34.8,23.94,34.43,30.305,23.3,27.83,33.33,24.3,37.715,29.9,27.61,30.4,30.03,25.175,22,26.125,28.31,30.03,25.74,33.4,36.85],"text":["Age: 18 BMI: 33.77","Age: 32 BMI: 28.88","Age: 31 BMI: 25.74","Age: 52 BMI: 30.78","Age: 23 BMI: 23.845","Age: 19 BMI: 28.6","Age: 24 BMI: 26.6","Age: 18 BMI: 35.625","Age: 64 BMI: 24.7","Age: 28 BMI: 25.935","Age: 40 BMI: 36.19","Age: 31 BMI: 28.5","Age: 53 BMI: 28.1","Age: 58 BMI: 32.01","Age: 57 BMI: 34.01","Age: 31 BMI: 26.885","Age: 54 BMI: 30.8","Age: 55 BMI: 38.28","Age: 41 BMI: 31.6","Age: 52 BMI: 32.205","Age: 37 BMI: 23.37","Age: 18 BMI: 23.75","Age: 20 BMI: 28.975","Age: 53 BMI: 35.9","Age: 48 BMI: 29.7","Age: 54 BMI: 39.6","Age: 41 BMI: 32.2","Age: 18 BMI: 34.43","Age: 63 BMI: 31.8","Age: 40 BMI: 41.23","Age: 53 BMI: 26.6","Age: 26 BMI: 29.92","Age: 24 BMI: 23.21","Age: 41 BMI: 31.635","Age: 47 BMI: 25.46","Age: 59 BMI: 27.83","Age: 44 BMI: 38.06","Age: 19 BMI: 20.9","Age: 55 BMI: 25.365","Age: 58 BMI: 25.2","Age: 53 BMI: 38.06","Age: 19 BMI: 20.615","Age: 52 BMI: 26.4","Age: 28 BMI: 27.5","Age: 58 BMI: 34.865","Age: 49 BMI: 35.86","Age: 52 BMI: 33.25","Age: 34 BMI: 25.27","Age: 26 BMI: 29.64","Age: 57 BMI: 40.945","Age: 52 BMI: 36.7","Age: 64 BMI: 34.5","Age: 49 BMI: 41.47","Age: 34 BMI: 29.26","Age: 57 BMI: 23.18","Age: 33 BMI: 35.245","Age: 49 BMI: 30.78","Age: 56 BMI: 32.3","Age: 57 BMI: 22.23","Age: 64 BMI: 30.115","Age: 62 BMI: 31.46","Age: 48 BMI: 31.445","Age: 52 BMI: 38.38","Age: 38 BMI: 21.12","Age: 19 BMI: 17.48","Age: 52 BMI: 34.1","Age: 25 BMI: 30.59","Age: 60 BMI: 33.11","Age: 35 BMI: 28.9","Age: 40 BMI: 29.6","Age: 35 BMI: 38.6","Age: 39 BMI: 29.6","Age: 24 BMI: 23.4","Age: 57 BMI: 30.495","Age: 62 BMI: 38.095","Age: 18 BMI: 24.09","Age: 63 BMI: 41.325","Age: 54 BMI: 21.47","Age: 31 BMI: 23.6","Age: 37 BMI: 30.875","Age: 22 BMI: 31.35","Age: 51 BMI: 22.42","Age: 38 BMI: 28.025","Age: 33 BMI: 38.9","Age: 20 BMI: 31.79","Age: 25 BMI: 41.325","Age: 46 BMI: 33.44","Age: 34 BMI: 34.21","Age: 19 BMI: 35.53","Age: 19 BMI: 30.495","Age: 18 BMI: 37.29","Age: 62 BMI: 36.86","Age: 25 BMI: 23.465","Age: 19 BMI: 20.7","Age: 27 BMI: 25.175","Age: 28 BMI: 26.98","Age: 59 BMI: 28.785","Age: 29 BMI: 26.03","Age: 24 BMI: 29.3","Age: 51 BMI: 39.7","Age: 48 BMI: 30.78","Age: 39 BMI: 26.22","Age: 48 BMI: 31.13","Age: 18 BMI: 33.66","Age: 19 BMI: 20.3","Age: 33 BMI: 18.5","Age: 53 BMI: 26.41","Age: 40 BMI: 41.69","Age: 24 BMI: 23.655","Age: 56 BMI: 33.725","Age: 47 BMI: 29.545","Age: 33 BMI: 32.9","Age: 62 BMI: 37.4","Age: 18 BMI: 40.28","Age: 45 BMI: 24.035","Age: 21 BMI: 28.975","Age: 58 BMI: 22.77","Age: 24 BMI: 33.63","Age: 31 BMI: 27.645","Age: 47 BMI: 32.3","Age: 64 BMI: 39.7","Age: 38 BMI: 19.475","Age: 61 BMI: 36.1","Age: 44 BMI: 36.48","Age: 45 BMI: 39.805","Age: 31 BMI: 29.26","Age: 22 BMI: 23.18","Age: 39 BMI: 31.92","Age: 64 BMI: 35.97","Age: 18 BMI: 30.14","Age: 46 BMI: 30.8","Age: 36 BMI: 34.43","Age: 60 BMI: 24.32","Age: 63 BMI: 33.1","Age: 35 BMI: 23.465","Age: 51 BMI: 34.2","Age: 25 BMI: 32.23","Age: 57 BMI: 28.1","Age: 55 BMI: 33.535","Age: 51 BMI: 25.4","Age: 40 BMI: 29.9","Age: 50 BMI: 36.2","Age: 33 BMI: 33.44","Age: 41 BMI: 28.8","Age: 23 BMI: 27.36","Age: 61 BMI: 44","Age: 26 BMI: 27.265","Age: 60 BMI: 35.1","Age: 44 BMI: 32.34","Age: 22 BMI: 28.31","Age: 44 BMI: 27.5","Age: 24 BMI: 33.99","Age: 34 BMI: 35.815","Age: 62 BMI: 39.16","Age: 26 BMI: 46.53","Age: 18 BMI: 26.18","Age: 19 BMI: 22.61","Age: 31 BMI: 39.49","Age: 24 BMI: 26.79","Age: 46 BMI: 24.795","Age: 52 BMI: 36.765","Age: 35 BMI: 27.1","Age: 39 BMI: 34.32","Age: 34 BMI: 23.56","Age: 22 BMI: 20.235","Age: 19 BMI: 40.5","Age: 50 BMI: 31.6","Age: 28 BMI: 29.26","Age: 21 BMI: 34.6","Age: 61 BMI: 38.38","Age: 54 BMI: 23","Age: 64 BMI: 26.41","Age: 36 BMI: 28.595","Age: 60 BMI: 18.335","Age: 32 BMI: 27.835","Age: 32 BMI: 31.5","Age: 57 BMI: 31.54","Age: 52 BMI: 47.74","Age: 23 BMI: 32.7","Age: 18 BMI: 31.35","Age: 49 BMI: 29.925","Age: 50 BMI: 26.22","Age: 26 BMI: 30","Age: 41 BMI: 32.6","Age: 52 BMI: 24.86","Age: 35 BMI: 35.815","Age: 36 BMI: 22.135","Age: 20 BMI: 30.59","Age: 32 BMI: 41.1","Age: 43 BMI: 34.58","Age: 32 BMI: 35.2","Age: 37 BMI: 34.105","Age: 19 BMI: 27.93","Age: 22 BMI: 32.11","Age: 59 BMI: 34.8","Age: 41 BMI: 23.94","Age: 56 BMI: 34.43","Age: 58 BMI: 30.305","Age: 58 BMI: 23.3","Age: 45 BMI: 27.83","Age: 18 BMI: 33.33","Age: 28 BMI: 24.3","Age: 55 BMI: 37.715","Age: 43 BMI: 29.9","Age: 35 BMI: 27.61","Age: 22 BMI: 30.4","Age: 18 BMI: 30.03","Age: 58 BMI: 25.175","Age: 20 BMI: 22","Age: 18 BMI: 26.125","Age: 18 BMI: 28.31","Age: 51 BMI: 30.03","Age: 57 BMI: 25.74","Age: 23 BMI: 33.4","Age: 18 BMI: 36.85"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","opacity":0.9,"name":"no","marker":{"color":"rgba(204,70,120,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","symbol":"x","line":{"color":"rgba(204,70,120,1)"}},"textfont":{"color":"rgba(204,70,120,1)","size":55},"error_y":{"color":"rgba(204,70,120,1)","width":55},"error_x":{"color":"rgba(204,70,120,1)","width":55},"line":{"color":"rgba(204,70,120,1)","width":55},"frame":null},{"x":[31,45,20,19,42,63,56,47,53,50,44,36,63,64,61,40,24,21,39,57,54,35,48,31,18,42,50,53,27,37,47,44,34,27,30,18,20,43,22,47,48,23,18,23,43,52,52,24,18,62,32,30,62],"z":[718.439595977252,-2474.32791442279,163.862855918855,-562.445485375792,-616.081182383175,1041.55323564354,3143.71837891788,-1850.34353618616,-329.494262305605,193.887932563564,-1236.68064644067,-616.402794832837,1147.52147126736,807.364109688744,594.406661754227,-1232.82071366354,16605.0826519252,-1285.19746053166,29.6819771721894,2743.04078714739,19918.060429483,626.492913010443,423.586209927445,13979.0506891743,-3493.20571614619,11456.4007187653,-2421.89033677694,-242.84702924508,-479.029109853149,6797.69454657003,78.8573345539335,1461.587870512,-226.944800443358,-3189.22618434969,-3021.13937201994,-1018.16082160738,-649.879939689017,-1729.18011680482,11659.663655504,-1866.54167909923,-148.166383813448,-3022.11817953986,168.85072278915,-1824.65965524794,-2388.22020395241,17923.5920514336,1999.42107871245,-2993.49281159062,-3952.66077544965,2796.88985886247,-342.732420896598,-1510.46944299202,614.74905595959],"y":[36.3,22.895,28.025,28.3,24.64,27.74,33.63,25.41,22.61,32.3,20.235,22.6,26.98,33.88,35.86,32.775,28.5,25.7,28.3,42.13,47.41,34.105,40.565,38.095,33.535,28.31,27.6,20.9,28.5,47.6,38.94,30.2,27.835,20.045,22.99,21.565,30.685,24.7,52.58,36.19,25.85,31.4,27.36,28.49,25.27,34.485,41.8,29.83,21.66,30.875,28.12,23.655,26.695],"text":["Age: 31 BMI: 36.3","Age: 45 BMI: 22.895","Age: 20 BMI: 28.025","Age: 19 BMI: 28.3","Age: 42 BMI: 24.64","Age: 63 BMI: 27.74","Age: 56 BMI: 33.63","Age: 47 BMI: 25.41","Age: 53 BMI: 22.61","Age: 50 BMI: 32.3","Age: 44 BMI: 20.235","Age: 36 BMI: 22.6","Age: 63 BMI: 26.98","Age: 64 BMI: 33.88","Age: 61 BMI: 35.86","Age: 40 BMI: 32.775","Age: 24 BMI: 28.5","Age: 21 BMI: 25.7","Age: 39 BMI: 28.3","Age: 57 BMI: 42.13","Age: 54 BMI: 47.41","Age: 35 BMI: 34.105","Age: 48 BMI: 40.565","Age: 31 BMI: 38.095","Age: 18 BMI: 33.535","Age: 42 BMI: 28.31","Age: 50 BMI: 27.6","Age: 53 BMI: 20.9","Age: 27 BMI: 28.5","Age: 37 BMI: 47.6","Age: 47 BMI: 38.94","Age: 44 BMI: 30.2","Age: 34 BMI: 27.835","Age: 27 BMI: 20.045","Age: 30 BMI: 22.99","Age: 18 BMI: 21.565","Age: 20 BMI: 30.685","Age: 43 BMI: 24.7","Age: 22 BMI: 52.58","Age: 47 BMI: 36.19","Age: 48 BMI: 25.85","Age: 23 BMI: 31.4","Age: 18 BMI: 27.36","Age: 23 BMI: 28.49","Age: 43 BMI: 25.27","Age: 52 BMI: 34.485","Age: 52 BMI: 41.8","Age: 24 BMI: 29.83","Age: 18 BMI: 21.66","Age: 62 BMI: 30.875","Age: 32 BMI: 28.12","Age: 30 BMI: 23.655","Age: 62 BMI: 26.695"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","opacity":0.9,"name":"yes","marker":{"color":"rgba(13,8,135,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","symbol":"circle","line":{"color":"rgba(13,8,135,1)"}},"textfont":{"color":"rgba(13,8,135,1)","size":55},"error_y":{"color":"rgba(13,8,135,1)","width":55},"error_x":{"color":"rgba(13,8,135,1)","width":55},"line":{"color":"rgba(13,8,135,1)","width":55},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="modeling.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train residuals</span></span>
<span id="cb130-2"><a href="modeling.html#cb130-2" aria-hidden="true" tabindex="-1"></a>resid_plot_ins_data_train <span class="sc">%&gt;%</span></span>
<span id="cb130-3"><a href="modeling.html#cb130-3" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">plot_ly</span>(<span class="at">x =</span> <span class="sc">~</span>age, <span class="at">z =</span> <span class="sc">~</span>resid, <span class="at">y =</span> <span class="sc">~</span>bmi,</span>
<span id="cb130-4"><a href="modeling.html#cb130-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">color =</span> <span class="sc">~</span><span class="fu">factor</span>(smoker),</span>
<span id="cb130-5"><a href="modeling.html#cb130-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">symbol =</span> <span class="sc">~</span><span class="fu">factor</span>(smoker),</span>
<span id="cb130-6"><a href="modeling.html#cb130-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste</span>(<span class="st">&quot;Age:&quot;</span>, age, <span class="st">&quot;BMI:&quot;</span>, bmi),</span>
<span id="cb130-7"><a href="modeling.html#cb130-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hoverinfo =</span> <span class="st">&quot;text&quot;</span>,</span>
<span id="cb130-8"><a href="modeling.html#cb130-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">symbols =</span> <span class="fu">c</span>(<span class="st">&#39;x&#39;</span>,<span class="st">&#39;circle&#39;</span>),</span>
<span id="cb130-9"><a href="modeling.html#cb130-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">colors =</span> <span class="fu">plasma</span>(<span class="dv">3</span>)[<span class="dv">2</span><span class="sc">:</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb130-10"><a href="modeling.html#cb130-10" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">add_markers</span>(<span class="at">opacity =</span> <span class="fl">0.9</span>,</span>
<span id="cb130-11"><a href="modeling.html#cb130-11" aria-hidden="true" tabindex="-1"></a>                      <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb130-12"><a href="modeling.html#cb130-12" aria-hidden="true" tabindex="-1"></a>  plotly<span class="sc">::</span><span class="fu">layout</span>(<span class="at">scene =</span> <span class="fu">list</span>(</span>
<span id="cb130-13"><a href="modeling.html#cb130-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;Age&quot;</span>),</span>
<span id="cb130-14"><a href="modeling.html#cb130-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">yaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;BMI&quot;</span>),</span>
<span id="cb130-15"><a href="modeling.html#cb130-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">zaxis =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="st">&quot;Raw residuals&quot;</span>)),</span>
<span id="cb130-16"><a href="modeling.html#cb130-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Raw train residuals of the insurance XGBoost model&quot;</span>,</span>
<span id="cb130-17"><a href="modeling.html#cb130-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend =</span> <span class="fu">list</span>(<span class="at">title =</span> <span class="fu">list</span>(<span class="at">text =</span> <span class="st">&quot;Smoker&quot;</span>)))</span></code></pre></div>
<div id="htmlwidget-219530c2ad540109c712" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-219530c2ad540109c712">{"x":{"visdat":{"2ffc17a152a8":["function () ","plotlyVisDat"]},"cur_data":"2ffc17a152a8","attrs":{"2ffc17a152a8":{"x":{},"z":{},"y":{},"text":{},"hoverinfo":"text","color":{},"symbol":{},"colors":["#CC4678FF","#0D0887FF"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"symbols":["x","circle"],"type":"scatter3d","mode":"markers","opacity":0.9,"size":2,"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Age"},"yaxis":{"title":"BMI"},"zaxis":{"title":"Raw residuals"}},"title":"Raw train residuals of the insurance XGBoost model","legend":{"title":{"text":"Smoker"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[26,36,43,19,41,42,31,61,43,56,23,23,61,18,42,34,42,51,59,29,38,31,58,30,59,21,54,24,19,38,63,28,35,37,45,47,38,55,49,47,60,30,41,31,56,18,49,42,47,22,40,47,18,35,21,22,53,39,38,44,34,19,18,49,38,53,34,34,35,46,25,26,31,43,23,61,45,25,52,31,57,18,19,47,62,61,18,27,49,42,21,51,45,39,23,47,27,64,62,42,49,36,40,29,60,38,33,48,30,22,25,39,41,48,33,30,62,38,18,26,30,25,54,29,23,48,19,25,48,27,31,60,25,26,47,41,63,26,44,41,51,38,18,45,26,42,53,34,63,53,58,42,26,54,58,45,26,56,28,26,61,27,25,59,40,41,28,37,42,41,39,38,36,63,57,48,54,18,63,35,47,41,57,25,46,63,37,63,46,19,39,53,19,27,37,64,61,37,28,40,29,32,51,28,20,59,55,57,38,28,29,30,46,57,55,40,48,21,21,50,56,56,18,42,28,38,35,49,18,22,23,38,53,22,22,34,24,21,55,25,57,56,29,49,29,33,31,38,36,45,40,24,47,49,44,37,45,19,61,40,26,34,52,28,53,50,46,48,40,27,34,36,50,23,42,20,21,25,27,64,58,18,47,26,19,18,21,31,46,55,54,36,45,28,50,19,57,25,39,57,45,48,30,28,38,53,43,26,51,52,41,21,37,60,36,57,40,27,60,58,51,21,46,52,46,63,18,42,62,18,41,18,57,40,37,32,34,51,60,59,52,37,30,40,31,37,50,29,37,31,58,21,18,29,28,26,18,55,44,25,19,63,22,62,46,18,60,28,48,50,19,41,19,20,19,28,19,60,48,59,42,21,22,62,54,54,35,30,53,36,51,18,50,22,29,22,39,29,19,54,21,27,64,27,19,53,50,24,24,28,21,27,24,22,55,59,18,45,50,48,62,40,49,33,18,53,20,58,18,59,19,35,43,32,36,20,22,34,50,56,46,45,58,59,50,55,50,18,48,58,44,21,55,49,53,31,26,56,18,32,25,49,27,60,45,41,32,18,20,43,48,49,50,38,53,45,30,18,27,32,30,29,55,46,55,43,35,54,34,58,51,57,32,21,48,63,57,59,49,22,36,42,55,59,20,44,19,29,24,32,29,44,51,40,46,18,18,19,59,56,18,51,41,64,45,60,26,25,64,27,51,26,40,18,33,44,34,19,52,45,36,49,55,33,49,19,50,30,29,31,50,46,52,36,42,48,36,24,55,27,24,24,32,49,22,39,23,35,46,31,46,26,19,29,25,52,49,50,33,61,37,39,28,56,46,58,57,58,55,33,59,64,29,49,54,19,51,62,34,19,19,39,50,28,32,21,19,32,43,25,46,45,53,38,60,23,62,38,49,44,56,56,51,43,61,19,44,51,43,61,35,60,31,18,30,44,54,28,34,36,46,38,50,41,29,54,63,62,28,50,20,63,40,62,30,35,47,23,55,32,20,20,36,32,35,50,45,19,56,50,61,54,33,23,63,47,25,54,21,23,61,44,27,29,50,18,20,23,62,48,58,48,41,18,43,20,19,55,26,32,55,29,38,18,30,45,59,55,40,24,35,57,42,43,44,27,33,45,58,58,41,62,59,44,19,56,33,51,19,58,62,39,45,24,52,46,21,40,56,64,19,47,19,59,39,54,18,54,47,21,19,64,18,19,20,48,59,55,53,59,46,34,35,44,51,25,26,48,21,18,33,56,58,44,61,30,19,39,54,23,33,56,27,34,54,18,39,28,41,52,25,23,47,60,53,52,49,21,48,63,52,19,21,20,36,42,43,47,22,56,32,52,42,30,33,46,18,21,19,30,63,61,22,38,31,41,23,18,20,53,33,32,56,60,24,37,41,20,26,42,54,51,44,24,28,39,53,45,23],"z":[-84.8279233505582,-117.194496249884,-1490.05949424891,-328.023916377704,-900.944990778936,-590.350783681061,-129.612708918789,-714.993231953697,-1222.16807877132,-696.159994960026,-545.432950184949,-527.23156513365,294.579689680346,-445.309281368597,-288.182748601808,-937.498352218561,15.9518464564599,-558.73091542894,-2008.27065718466,11358.9154374854,-939.522575837647,-847.681594816514,-464.39649932871,-21.7953518695167,8604.54710466506,375.719170694412,-1660.21608656422,-1054.68972514506,-272.561774095205,-546.33767129628,147.145152365199,-616.833124076289,-399.354856101149,-332.822959822694,-670.802462487069,-339.385873547197,-181.459423958279,-1216.3705927041,-727.722253847149,-816.829369013398,-2503.08999453639,-841.277670967305,-244.542277719311,-482.15581051815,-665.99576414588,-1069.95991519953,-713.272932660811,-192.176231680907,-891.554880360802,18.9607480654076,-921.083388386088,-990.582254954954,-770.958177248272,-677.735148560443,-395.976126195909,266.233838257206,-507.833394162613,245.984355182168,-753.938056320479,-1008.76330714419,-881.212567014662,-423.618584380157,-602.240576868492,-411.920734396224,-230.650556516233,-1248.0084312538,-828.393186341787,-123.09721184158,-1067.35978664706,-1478.00778043767,-326.871780899282,-91.1370766604246,-79.7956812478565,7546.3165572356,-834.480129652555,-1142.42762924367,-1142.49877972523,-509.470824934159,10932.7058747977,49.2377501583414,-1141.56217753763,-236.374036645379,73.3750172757193,-620.132636907832,-170.694218233757,-758.849376546073,-267.157522893018,-640.850419617993,-814.077669355864,-721.601475148879,-1636.66486422276,-1192.29983951317,9167.42158852379,-112.371578680027,-1409.62459703872,-857.934625744057,-755.816663128819,37.5447786194691,-136.025846228944,-116.579912001132,-1306.62684936412,-268.127015275757,-534.507552327764,-473.082283023826,-938.331077732386,-291.985357602939,-329.702943821197,17991.8033711734,190.573994063907,26.7380606474717,-48.9522962299011,-49.674374206068,-875.739103499088,-1756.00056483712,-1458.14256061475,14124.5763429741,-341.662024870793,-928.652860299046,18011.5287615491,-33.1343949773468,-653.085729881318,-260.99905159646,-1805.80864026764,13128.8931409845,-832.232769259865,-1186.05944258666,-143.611435654845,-294.742353367353,-1618.01792982088,-1711.17111675814,-203.633629334772,-1639.61678687892,-135.8962106391,-991.188707209576,15979.7980021777,-15.2363461738187,1218.37012089965,-252.486513339256,-220.977420443603,-410.485214413128,-661.927926727405,-727.883806361056,9780.8392858673,-897.177828076943,-66.9006767044457,-120.222371493558,-1516.39103096807,-920.763405681522,115.080099227738,-1180.21056982333,-524.493686100135,50.5591034993968,-294.478050421091,-688.764915429967,-634.073158749778,-1242.22380406481,84.3512413137009,-1142.58821000306,-369.496398706593,21.5958644043462,-1016.18479840352,-488.22159449642,-1304.72118164354,-942.501647958257,-1064.61749590793,-318.176377737547,17832.5781941607,-1060.01749146115,-20.7245225553952,-595.797073295726,-843.337342593673,-108.296252540231,-635.748676541974,849.627959719926,-533.03051386701,-1586.76139521284,-1235.12144384135,4201.73976339365,-255.651704071504,-644.394322064135,-1089.22199870297,-729.194296377169,-1052.49764433101,-75.6233882355732,-658.901494293963,499.02622669536,-1413.95568667444,-548.457930042638,-1383.45653498083,20789.0767249808,-1031.54291913774,15856.655024571,-174.647546340466,-384.687312187317,-826.966871465183,310.524667118521,-519.037133770231,-738.678082957855,127.219363205351,18529.0580649855,-42.3542545103064,-847.9812173589,-200.646139648015,-1413.22380276979,-584.780687291868,-1516.05934057434,-1188.52963336335,-722.916166186311,-541.761094397053,-901.873318854334,14343.8977092466,313.106723634593,-1240.23680560959,-629.944783268111,-1478.1731963547,-793.841243375158,-1013.36979022128,-1983.99968599141,-1083.46933681296,-1375.35251096839,-1398.85513922083,-680.716232413586,-104.444203860311,-169.031468397699,-357.159606546442,-378.776666377736,16367.867702969,-925.251243204395,-236.985636645379,-154.105925360633,15455.7589635886,-572.841714758729,-1490.12248664822,-171.552916668361,40.0233087865859,-863.219973048903,-455.17628065253,-298.623259600195,-1517.05377807365,-107.748973368895,579.032314829972,-1019.91699192046,-530.120825591549,-906.494161866387,-319.390285486792,-939.768720941547,-73.0903039972854,-515.751853553433,-146.385340461137,-709.495125952821,7092.36759525736,-568.519185586619,-1647.10253465973,-433.047109399406,-840.030000526605,-1201.15097010606,12.4633199152267,-270.779198328613,16553.8842780287,-677.07873775968,-1052.1501431929,-1120.93083573972,-1486.24953372219,-426.737517637246,-1551.02833418227,-1386.79527958845,-801.468785390218,-1725.21128949816,-712.989683034538,-329.935850925262,4964.00619287591,-428.95793347193,-1045.00425807442,-633.588271109805,-353.965313665985,-361.375972744695,14246.5793425214,-77.3024178801061,-1072.56902123686,1045.84458122472,-417.673266295977,-255.781551090782,-538.429412772346,-246.026421759507,-529.528845727302,-729.888868369294,-182.313366920712,-376.164403518154,-94.8763405283316,-1117.67301923848,-1846.25674880851,5.7168182209798,-431.009972117949,-924.174238600799,-826.25595195905,-174.515496340466,25.4823848730503,308.308060483841,-601.409241861983,-1571.26259221794,-1104.16011414129,-1318.50065410396,-522.691167518785,-623.91412192541,-913.043584652825,-992.000960887432,-857.897928625729,59.3814021228695,-990.52881498747,-456.90934564656,-82.5377719239768,-13.9439131900554,-144.534742066918,-1281.77478715686,-454.597735443739,-968.672073826801,-257.575267356034,-334.51336987924,-1311.06891403576,-1233.58011994558,-1252.67416996332,-128.2624578849,-346.031985492418,-1343.20300391673,-844.923277833763,644.121363071905,-150.28844425561,178.214483133132,601.074646759011,-70.0103735565783,-664.6415952044,-239.8762596099,8493.3367568933,-842.486772832408,-863.543371823185,-422.036278723696,-1425.41244308796,-1138.22554932982,-1572.68535684787,-1002.27683426546,-1557.54402782161,14270.7162452453,-356.161188697189,-517.170435675793,-102.475786512974,238.741411665766,13513.668782472,-1056.84168574169,-694.058364939948,-523.521555935985,-840.281478081852,-435.282554898066,-356.978360484512,15.5249172022932,-603.682762446978,157.08328304938,-445.003481368597,-1169.98160698774,-990.011437389034,-719.929815348157,-417.677486218246,283.797594439775,-230.353538807921,-330.9669260097,212.446956913829,7396.16405672616,-1361.20273687124,-789.702587136474,11083.4333889244,-414.32099198075,-478.317611412194,-576.952834869577,-226.774243977042,24287.1660208013,-190.257796546968,-659.447940884912,-378.601900790738,14932.1370979076,-1984.22768440061,-1132.31041911969,-500.564126154191,-68.865539936882,-560.228925694946,-683.850531331427,-1421.44474104146,-98.8517038827194,-394.333204667001,-190.953268833763,-1755.72272629353,-125.632979266351,-56.4666586534731,-442.476192572365,-1250.71773684401,-168.001011248323,-1153.61377436281,-110.359385182182,15949.5570327905,-372.614041979532,48.7942496072569,13977.1639741442,175.599220932161,12585.2583815867,-441.318676631294,-567.306824427285,-142.295279951429,15854.0394159056,-354.426659109517,-240.127417157862,-436.99831235553,-719.226195855743,19910.1169951173,11252.563243462,-1479.84375859433,-39.0082189141594,-1283.13687148327,-660.311889675844,11431.2566348005,-849.78837073356,-1345.44010444264,-1393.8024804439,-447.85895223634,16.3595361333328,532.543614194157,5673.90652468693,-364.939542050718,-1031.89940273447,-357.989944485919,-1311.54187212975,-691.964751708403,-641.199648882748,-128.877989356755,-166.813816228118,9141.66650762302,-632.803189692952,-525.400124058926,-245.057700521287,59.1053923705654,-1458.9506216678,-915.2128441157,-680.980332413586,-830.274211911415,-649.274051424607,-1335.47331478431,-1424.37539639382,-606.025126597053,-631.459831536957,-1552.50881689945,-104.312153860311,-1646.27767976576,-282.223118469195,-1153.21280626519,-197.367523840243,-1068.80776641628,-1295.58467590917,-1816.13354767195,34.7616475320228,16.6178640584549,-1007.90221120174,-567.649694533518,-88.5731915681508,-536.441378977913,15237.8474425617,-783.678367148392,-1390.85054172194,18624.8384785325,-800.68112276005,313.117470103251,8959.75830073988,563.11209343279,100.649482033292,-1703.5089378618,-1111.08507528412,-1520.75570582928,89.8477628579558,-1306.469232622,-1346.69018040457,-518.677774511591,-1199.94400541226,-379.008437124341,-884.401226158236,-444.135416820655,-762.113753008933,-1090.45468653648,-544.739493502606,-1602.54262419976,-1091.67261925461,-1012.5459043806,-1265.63342412463,19513.122710209,-609.488364660885,-634.182063658101,7422.73579669058,12073.9966978104,-1180.07808584757,-1550.51929790526,230.463606018626,-438.790692807004,-2724.73017708507,-1300.16715188479,-168.574136994557,-831.312001534387,-46.7746901030796,9084.66960233388,13713.7461968431,-511.246582304384,-1312.14656812106,-173.535225244735,-924.764034487202,-276.511177341819,-27.827186801765,-638.7260400387,-954.820125123253,-1045.66978734132,-51.4167925800666,-1000.75125444677,-1129.84608845086,-68.4377786682403,-102.886602575697,-1328.34305092395,-664.616495898681,-157.232989973309,-889.331745604888,-53.5092877688867,836.629672190547,352.849573192294,-1594.54284652814,-498.360205162373,-46.7871188018557,-604.027302598171,-409.009832881047,-692.346994353646,119.731842121376,-534.010290554218,-201.936343785509,-1404.48405102274,-663.303350142407,8232.18480839341,-30.5477481728431,-822.437900927469,-2143.82059786892,345.390882770135,-1479.04336304271,8056.77247897757,-730.705895945157,104.847934284615,-380.079307438856,-425.636105914795,-639.071847042559,-1126.46737854076,193.350701561134,-1437.53212384788,-810.256833815354,-1539.09387205531,-316.294170468643,-361.572259909576,-581.511771321553,-299.639526523083,-449.783517030281,-77.242058212325,-493.486077011759,15512.715542652,-388.375106804381,-912.883090874986,-398.917818172451,-829.575576931805,-656.330186223242,9501.93978346681,-787.39207244394,-298.283170755778,-600.17691528853,289.66638919901,-302.468254205877,-484.681646771858,-930.171138175225,-305.537883810842,-1449.9001864566,-1070.43478838762,18653.3356768479,-1484.5403016534,9970.57299542399,13449.7612185885,-745.885470701328,-549.216711903805,-251.246957692354,-857.868571526798,11172.5337181109,-485.139270055277,-781.731795375199,-932.896963503848,-864.489338868584,292.153805967784,656.151966921829,-1443.85495819021,-158.895435408214,12994.5305939719,-529.528845727302,-910.67228810025,-334.944772173973,-586.371205202297,-72.3809049488432,-306.835441886743,-523.387989412637,-838.358978926384,-887.56955229583,167.660103111674,164.098117023012,-223.562275235025,-919.694177596258,-1269.02119837239,-8.03277531943468,-1413.56989830625,-1741.23231940913,-1979.69549200072,-773.270668825849,-1663.13548013382,-949.300343425411,-1023.25568514298,-84.7935762727793,-1257.32153322233,-705.67542983608,-284.59500645251,-1582.2648666799,-946.060204560505,-969.148875078386,-352.876118855911,-277.771867993808,-1147.41129860059,-1056.08516909495,-983.9871685117,-145.924002453792,10420.6129382407,16335.5979260518,156.880194102901,-201.16973113607,-113.825421057195,-828.976027511129,-1478.29875258225,-462.506449234011,-530.769819770425,-951.823649805374,-858.625368216663,-322.972595552271,8384.1907429889,-126.431073140982,-235.226481535621,-2002.01997200078,419.081951291124,-113.55330532775,15580.6236416833,14474.0073084876,-230.207413709752,375.22782865768,-932.600623082775,-812.657403551608,-490.113152795228,-950.372951921972,-1071.29254766398,-669.668382685475,21786.3280664323,83.6013093505762,-386.516014015243,-63.226197873515,-949.819119479318,-423.171969152557,-1133.02701460051,-459.419378781158,-868.237883722861,16337.2213755709,-283.013283546781,-1366.16853190948,-546.058922751463,-490.132288783885,-890.371135706403,-843.76257919776,-262.199766896505,-450.594681598299,21.5762428859039,-1395.56534876068,31.9552204043612,-272.180232483508,-904.277964035764,-1551.81009456229,-550.16483464743,-1443.32675819021,-982.667375941295,-2923.01955232236,-479.483436420813,-603.250520909607,-399.398669051778,-1305.02291327283,-443.180254979967,-820.144794724607,-237.650967657505,-392.476247035301,-1440.21527482415,-1209.14672538622,-208.55214235182,-1506.63853074965,24.7053785424919,-32.2050187875557,-1802.66449513787,-765.860051255951,-152.850273416332,-1218.02898447067,-1017.16369126947,-571.213967093723,-1411.56527334446,-1241.63811845642,-24.1953230883537,-334.716077816546,-1344.89939677488,-668.119385793509,-120.182526850717,4436.66391213036,-728.087497755648,13547.208869441,16776.9964816725,-298.405116921094,-873.534618960279,-1080.41794805951,6144.55658963808,808.709519616479,-1037.12129135191,-1027.09425640162,-118.216232058134,308.467408001628,-666.688391521596,-1137.46410648123,-477.187903162674,-273.947051997224,-94.7169265690081,-254.672803147191,-1144.99274769472,-576.842989346787,-1108.73336637923,321.517679407732,-299.008150317499,-948.399557496671,-525.796023744144,607.587823723539,16719.5893115384,-1356.70530568145,-469.867934553307,-1071.32672924452,-493.442728346764,12485.5149269577,-125.473243131497,-1666.36455663561,10519.3502196033,-243.942413788279,-883.316325784889,164.765100822786,-391.427412223621,-464.942671024589,-589.699973158552,-79.769689829438,-793.556485946299,-1004.08270681681,-1050.5295918729,-43.2244116363654,15237.9197101565,-1274.83937768478,-512.741833519716,21230.3752468228,-1390.2697722909,-398.992649540754,-589.329901237438,15362.3852823241,-307.622148307674,-470.047854004381,-274.452754383309,-1053.95649012294,-738.925995624681,-1263.88678624028,-389.957804088872,-424.857077981978,-133.160983577855,-1068.34146062016,-1802.68721636709,-422.027830983822,-685.077857379003,-721.773832008626,-539.945875158469,-594.91746433382,-865.071981328092,-275.02009661736,120.803157645953,-1264.53969200276,-694.092692666834,19425.9929344472,17804.1061689662,7245.29012833711,-1185.86342234455,-986.649213014567,-1102.38573393634,333.590512933712,-1145.45072671016,-150.979391345626,-1348.08568391863,-342.439234567202,-1632.46363239145,-538.978633348722,-73.343332026011,-161.575875448126,46.5698077833049,125.23694132801,-899.337179249937,-851.459354132034,49.3054343308522,-913.780753578683,-461.689490103779,-1063.64585426538,-123.503575684069,-266.028355834178,-891.22394594753,-417.493440612851,-564.567205084761,-469.358889932618,-72.4945543268141,-566.925693253585,-61.631220492538,-33.2674494221574,51.4539661571293,-724.764054097453,-498.381302688403,-170.737997719188,-223.4379974403,-318.699004954542,-801.221640871942,-454.806881192573,-631.955468260136,-923.313032661104,-963.829273146974,-772.389316848026,-53.6432464902587,-1268.57452565797,-379.70751728888,-224.582764602347,128.160575874513,-259.454879867253,-1720.93399492907,-1270.20658305053,-1308.43256385366,-340.125754742476,-174.717162465289,-454.797235606865,-95.1207549102637,-675.072688096825,15100.6539394653],"y":[35.42,27.74,35.64,37.43,37.05,37.18,31.065,33.915,26.03,25.935,32.56,37.1,21.09,31.13,36.195,42.9,24.86,39.5,27.5,29.735,37.05,38.39,33.44,27.93,37.4,16.815,24.035,30.21,27.835,34.7,35.2,33,27.7,27.74,21.375,19.19,28,33.88,22.61,29.83,29.64,24.13,32.2,25.935,28.31,38.28,34.77,35.8,28.215,34.8,32.3,32,30.305,34.32,31.1,39.805,28.6,34.1,27.265,32.015,26.41,29.8,34.1,32.3,30.21,23.75,33.7,19,24.13,33.345,27.55,31.065,20.4,35.31,24.51,31.57,36.3,22.515,30.875,30.495,28.7,40.26,20.6,45.32,39.2,33.535,43.01,24.1,22.515,35.97,23.75,34.1,31.79,23.275,17.385,23.6,30.5,39.33,33.2,26.18,33.345,29.92,30.875,27.94,30.5,37.73,26.695,36.67,19.95,31.73,20.8,23.87,30.59,27.265,35.75,38.83,30.02,29.26,30.115,20.8,31.4,35.625,32.775,33.345,28.12,22.8,25.555,25.84,35.625,33.155,30.875,27.55,25.74,29.355,24.1,33.155,39.8,33.915,21.85,33.55,24.415,40.565,39.14,30.2,29.15,29,33.25,34.675,31.445,28.88,35.7,34.1,34.2,24.605,31.825,30.495,22.23,41.91,25.8,29.48,28.2,33.66,26.79,26.505,22.705,28.405,24.32,28.025,26.315,36.08,21.85,40.15,29.92,21.66,28.785,33.33,33.63,29.165,36.765,31,36,21.78,27.94,28.595,28.05,33.66,29.83,36.3,40.375,33.1,24.51,32.3,24.51,30.3,30.8,39.16,23.655,22.705,17.29,41.42,38.83,33.82,21.56,22.515,32.395,35.2,29.9,38,31,28.88,29.64,30.9,38.17,33.63,30.14,29.81,28.88,33.63,21.89,26.6,33.66,28.785,22.99,33.155,34.77,19.95,38.095,25.84,39.82,26.84,18.715,28.27,39.6,39.5,36,26.73,24.225,31.255,32.67,33.99,20.1,37.51,29.59,23.18,25.9,30.25,29.1,30.69,26.885,39.995,29.3,25.8,24.32,42.68,25,29.64,25.7,35.15,33.33,29.355,30.875,33.25,18.335,33.4,37.43,37.07,32.3,28.9,25.46,21.47,27,25.9,26.41,34.4,26.125,33.3,31.02,33.66,31.255,25.6,34.39,20.79,19.57,32.49,30.59,33.155,34.87,36.63,25.745,30.5,32.68,29.04,30.9,37.1,23.54,24.605,43.7,23.9,45.43,40.37,35.3,32.3,22.895,38.06,27.835,26.7,32.6,42.4,32.3,46.75,37.1,26.4,46.53,24.035,31.5,31.825,33,18.905,36.005,33.1,35.97,35.72,48.07,23.18,26.62,21.66,53.13,32.87,32.965,21.47,34.2,28.5,23.98,34.105,29.5,31.54,37.335,31.635,25.74,24.7,31.73,29.8,27.7,25.08,25.8,17.29,32.11,38.94,30.8,28.595,36.48,36.85,28.215,25.6,37.62,19.8,31.35,32.395,25.365,26.8,31.825,28.31,27.1,32.68,19.95,21.78,28.9,30.875,29.6,28.16,34.1,33.06,28.9,35.31,19.8,33,39.615,25.84,41.23,25.46,41.325,25.8,21.28,39.93,31.6,46.7,43.34,31.57,30.495,26.2,20.6,35.2,30.115,19.95,28.975,24.3,34.1,31.16,17.8,31.9,17.4,30.4,37.905,23.21,25.555,31.35,46.09,27.72,22.6,35.435,32.68,30.59,28.5,25.175,32.775,27.72,38.28,28.7,25.6,37.29,25,28.69,31.9,42.46,40.185,24.795,30.115,39.05,38.17,32.395,20.425,26.125,35.72,29.735,27.55,40.47,28.82,42.13,30.97,28.595,22.3,23.56,36.08,27.5,44.77,40.81,27.075,23.085,36.575,28.595,27.4,27.36,32.775,29.83,29.48,21.755,29.45,25.3,37.29,33.155,24.3,27.1,32.585,36.955,27.645,29.64,20.52,33.88,37,34.4,40.15,37.51,25.3,16.815,24.32,35.815,44.22,30.4,23.1,30.03,21.945,20.235,28.975,28.9,27.645,30.1,35.86,28.88,22.42,32.395,36.385,40.28,23.65,25.745,27.36,26.22,18.335,29.7,27.17,33.77,30.875,37.9,37.3,36.52,33,23.98,25.175,37.29,25.27,28.93,24.6,36.955,37.73,23.37,27.74,30.115,15.96,24.6,26.4,33.82,26.315,33.33,32.965,39.05,20.35,24.53,29.92,26.22,38.19,26.03,25.8,40.185,26.315,25.08,24.605,26.41,32.8,18.6,33.3,38.285,19.855,36.85,33,28.27,21.3,28.7,28.12,37.43,32.11,26.62,32.205,33.725,38.6,28.88,24.985,27.93,30.02,29.925,21.5,32.67,27.6,35.86,37.335,36.63,34.58,26.315,28,34.21,30.2,32.775,43.89,17.67,30.4,27.2,30.3,31.2,28.7,25.365,27.455,25.08,36.19,42.655,26.315,26.6,27.72,41.91,23.7,29,35.245,39.82,32.1,31.825,31.73,28.69,25.46,30.59,18.05,32.11,27.72,22.515,36.575,32.5,32.3,23.8,44.22,22.135,21.755,29.8,25.08,42.13,39.425,33.1,41.47,27.6,38.06,34.96,38.83,19.95,30.3,37.1,35.8,27.2,27.74,27.36,32.3,32.11,30.69,33.915,23.2,22.04,39.71,28.595,31.065,23.32,43.12,22.135,32.3,26.51,21.375,33.82,33.44,28.93,27.83,31.02,35.53,31.24,23.085,30.495,33.82,27.36,31.46,30.8,27.4,29.92,28.405,30.5,26.6,26.51,26.8,30.8,29.6,28.785,29.7,46.53,17.86,33.7,33.7,27.265,22.1,27.455,31.16,21.01,42.94,39.27,36.85,33.915,34.485,29.2,26.03,34.865,35.91,39.52,45.9,32.11,44.745,38.665,29.735,35.2,31.73,32.3,49.06,30.2,28.05,39.16,30.685,31.13,28.4,29.83,22.61,37.145,29.7,22.515,34.8,32.12,27.645,27.5,31.79,26.98,35.3,33.345,34.77,34.295,29.48,25.52,25.8,32.395,22.705,24.31,32.965,38,21.755,21.4,25.46,29.81,28.4,36.1,36.29,37,35.4,28.215,27.55,22.8,25.175,30.1,32.775,25.8,20.235,24.97,25.65,32.965,30.59,36.2,32.9,31.35,41.8,30.02,25.46,30.21,33.345,23.21,23.4,40.48,41.14,34.4,33.33,34.3,37.1,37.1,36.1,26.695,27.6,27.5,34.8,29.735,40.66,26.695,23.7,35.91,36.86,29.37,42.4,39.82,27.17,34.32,39.1,32.4,25.745,32.34,31.9,41.91,29.4,32.11,34.8,38,35.815,26.73,24.225,23.845,34.21,37.525,24.985,23.18,29.37,28.7,31.16,44.7,31.35,22.3,32.23,41.47,37.4,27.6,39.49,27.93,25.84,31.255,30.115,47.52,28.88,40.3,29.59,30.2,25.3,25.46,22.135,19.855,31.92,35.53,24.7,33.33,25.08,43.4,28.05,27.835,32.68,28.31,50.38,23.21,33,36.6,24.31,37.18,39.6,24.32,39.49,24.32,40.26,31.92,28.785,26.9,27.645,36.67,27.645,32.01,33.11,32.8,21.4,28.6,24.225],"text":["Age: 26 BMI: 35.42","Age: 36 BMI: 27.74","Age: 43 BMI: 35.64","Age: 19 BMI: 37.43","Age: 41 BMI: 37.05","Age: 42 BMI: 37.18","Age: 31 BMI: 31.065","Age: 61 BMI: 33.915","Age: 43 BMI: 26.03","Age: 56 BMI: 25.935","Age: 23 BMI: 32.56","Age: 23 BMI: 37.1","Age: 61 BMI: 21.09","Age: 18 BMI: 31.13","Age: 42 BMI: 36.195","Age: 34 BMI: 42.9","Age: 42 BMI: 24.86","Age: 51 BMI: 39.5","Age: 59 BMI: 27.5","Age: 29 BMI: 29.735","Age: 38 BMI: 37.05","Age: 31 BMI: 38.39","Age: 58 BMI: 33.44","Age: 30 BMI: 27.93","Age: 59 BMI: 37.4","Age: 21 BMI: 16.815","Age: 54 BMI: 24.035","Age: 24 BMI: 30.21","Age: 19 BMI: 27.835","Age: 38 BMI: 34.7","Age: 63 BMI: 35.2","Age: 28 BMI: 33","Age: 35 BMI: 27.7","Age: 37 BMI: 27.74","Age: 45 BMI: 21.375","Age: 47 BMI: 19.19","Age: 38 BMI: 28","Age: 55 BMI: 33.88","Age: 49 BMI: 22.61","Age: 47 BMI: 29.83","Age: 60 BMI: 29.64","Age: 30 BMI: 24.13","Age: 41 BMI: 32.2","Age: 31 BMI: 25.935","Age: 56 BMI: 28.31","Age: 18 BMI: 38.28","Age: 49 BMI: 34.77","Age: 42 BMI: 35.8","Age: 47 BMI: 28.215","Age: 22 BMI: 34.8","Age: 40 BMI: 32.3","Age: 47 BMI: 32","Age: 18 BMI: 30.305","Age: 35 BMI: 34.32","Age: 21 BMI: 31.1","Age: 22 BMI: 39.805","Age: 53 BMI: 28.6","Age: 39 BMI: 34.1","Age: 38 BMI: 27.265","Age: 44 BMI: 32.015","Age: 34 BMI: 26.41","Age: 19 BMI: 29.8","Age: 18 BMI: 34.1","Age: 49 BMI: 32.3","Age: 38 BMI: 30.21","Age: 53 BMI: 23.75","Age: 34 BMI: 33.7","Age: 34 BMI: 19","Age: 35 BMI: 24.13","Age: 46 BMI: 33.345","Age: 25 BMI: 27.55","Age: 26 BMI: 31.065","Age: 31 BMI: 20.4","Age: 43 BMI: 35.31","Age: 23 BMI: 24.51","Age: 61 BMI: 31.57","Age: 45 BMI: 36.3","Age: 25 BMI: 22.515","Age: 52 BMI: 30.875","Age: 31 BMI: 30.495","Age: 57 BMI: 28.7","Age: 18 BMI: 40.26","Age: 19 BMI: 20.6","Age: 47 BMI: 45.32","Age: 62 BMI: 39.2","Age: 61 BMI: 33.535","Age: 18 BMI: 43.01","Age: 27 BMI: 24.1","Age: 49 BMI: 22.515","Age: 42 BMI: 35.97","Age: 21 BMI: 23.75","Age: 51 BMI: 34.1","Age: 45 BMI: 31.79","Age: 39 BMI: 23.275","Age: 23 BMI: 17.385","Age: 47 BMI: 23.6","Age: 27 BMI: 30.5","Age: 64 BMI: 39.33","Age: 62 BMI: 33.2","Age: 42 BMI: 26.18","Age: 49 BMI: 33.345","Age: 36 BMI: 29.92","Age: 40 BMI: 30.875","Age: 29 BMI: 27.94","Age: 60 BMI: 30.5","Age: 38 BMI: 37.73","Age: 33 BMI: 26.695","Age: 48 BMI: 36.67","Age: 30 BMI: 19.95","Age: 22 BMI: 31.73","Age: 25 BMI: 20.8","Age: 39 BMI: 23.87","Age: 41 BMI: 30.59","Age: 48 BMI: 27.265","Age: 33 BMI: 35.75","Age: 30 BMI: 38.83","Age: 62 BMI: 30.02","Age: 38 BMI: 29.26","Age: 18 BMI: 30.115","Age: 26 BMI: 20.8","Age: 30 BMI: 31.4","Age: 25 BMI: 35.625","Age: 54 BMI: 32.775","Age: 29 BMI: 33.345","Age: 23 BMI: 28.12","Age: 48 BMI: 22.8","Age: 19 BMI: 25.555","Age: 25 BMI: 25.84","Age: 48 BMI: 35.625","Age: 27 BMI: 33.155","Age: 31 BMI: 30.875","Age: 60 BMI: 27.55","Age: 25 BMI: 25.74","Age: 26 BMI: 29.355","Age: 47 BMI: 24.1","Age: 41 BMI: 33.155","Age: 63 BMI: 39.8","Age: 26 BMI: 33.915","Age: 44 BMI: 21.85","Age: 41 BMI: 33.55","Age: 51 BMI: 24.415","Age: 38 BMI: 40.565","Age: 18 BMI: 39.14","Age: 45 BMI: 30.2","Age: 26 BMI: 29.15","Age: 42 BMI: 29","Age: 53 BMI: 33.25","Age: 34 BMI: 34.675","Age: 63 BMI: 31.445","Age: 53 BMI: 28.88","Age: 58 BMI: 35.7","Age: 42 BMI: 34.1","Age: 26 BMI: 34.2","Age: 54 BMI: 24.605","Age: 58 BMI: 31.825","Age: 45 BMI: 30.495","Age: 26 BMI: 22.23","Age: 56 BMI: 41.91","Age: 28 BMI: 25.8","Age: 26 BMI: 29.48","Age: 61 BMI: 28.2","Age: 27 BMI: 33.66","Age: 25 BMI: 26.79","Age: 59 BMI: 26.505","Age: 40 BMI: 22.705","Age: 41 BMI: 28.405","Age: 28 BMI: 24.32","Age: 37 BMI: 28.025","Age: 42 BMI: 26.315","Age: 41 BMI: 36.08","Age: 39 BMI: 21.85","Age: 38 BMI: 40.15","Age: 36 BMI: 29.92","Age: 63 BMI: 21.66","Age: 57 BMI: 28.785","Age: 48 BMI: 33.33","Age: 54 BMI: 33.63","Age: 18 BMI: 29.165","Age: 63 BMI: 36.765","Age: 35 BMI: 31","Age: 47 BMI: 36","Age: 41 BMI: 21.78","Age: 57 BMI: 27.94","Age: 25 BMI: 28.595","Age: 46 BMI: 28.05","Age: 63 BMI: 33.66","Age: 37 BMI: 29.83","Age: 63 BMI: 36.3","Age: 46 BMI: 40.375","Age: 19 BMI: 33.1","Age: 39 BMI: 24.51","Age: 53 BMI: 32.3","Age: 19 BMI: 24.51","Age: 27 BMI: 30.3","Age: 37 BMI: 30.8","Age: 64 BMI: 39.16","Age: 61 BMI: 23.655","Age: 37 BMI: 22.705","Age: 28 BMI: 17.29","Age: 40 BMI: 41.42","Age: 29 BMI: 38.83","Age: 32 BMI: 33.82","Age: 51 BMI: 21.56","Age: 28 BMI: 22.515","Age: 20 BMI: 32.395","Age: 59 BMI: 35.2","Age: 55 BMI: 29.9","Age: 57 BMI: 38","Age: 38 BMI: 31","Age: 28 BMI: 28.88","Age: 29 BMI: 29.64","Age: 30 BMI: 30.9","Age: 46 BMI: 38.17","Age: 57 BMI: 33.63","Age: 55 BMI: 30.14","Age: 40 BMI: 29.81","Age: 48 BMI: 28.88","Age: 21 BMI: 33.63","Age: 21 BMI: 21.89","Age: 50 BMI: 26.6","Age: 56 BMI: 33.66","Age: 56 BMI: 28.785","Age: 18 BMI: 22.99","Age: 42 BMI: 33.155","Age: 28 BMI: 34.77","Age: 38 BMI: 19.95","Age: 35 BMI: 38.095","Age: 49 BMI: 25.84","Age: 18 BMI: 39.82","Age: 22 BMI: 26.84","Age: 23 BMI: 18.715","Age: 38 BMI: 28.27","Age: 53 BMI: 39.6","Age: 22 BMI: 39.5","Age: 22 BMI: 36","Age: 34 BMI: 26.73","Age: 24 BMI: 24.225","Age: 21 BMI: 31.255","Age: 55 BMI: 32.67","Age: 25 BMI: 33.99","Age: 57 BMI: 20.1","Age: 56 BMI: 37.51","Age: 29 BMI: 29.59","Age: 49 BMI: 23.18","Age: 29 BMI: 25.9","Age: 33 BMI: 30.25","Age: 31 BMI: 29.1","Age: 38 BMI: 30.69","Age: 36 BMI: 26.885","Age: 45 BMI: 39.995","Age: 40 BMI: 29.3","Age: 24 BMI: 25.8","Age: 47 BMI: 24.32","Age: 49 BMI: 42.68","Age: 44 BMI: 25","Age: 37 BMI: 29.64","Age: 45 BMI: 25.7","Age: 19 BMI: 35.15","Age: 61 BMI: 33.33","Age: 40 BMI: 29.355","Age: 26 BMI: 30.875","Age: 34 BMI: 33.25","Age: 52 BMI: 18.335","Age: 28 BMI: 33.4","Age: 53 BMI: 37.43","Age: 50 BMI: 37.07","Age: 46 BMI: 32.3","Age: 48 BMI: 28.9","Age: 40 BMI: 25.46","Age: 27 BMI: 21.47","Age: 34 BMI: 27","Age: 36 BMI: 25.9","Age: 50 BMI: 26.41","Age: 23 BMI: 34.4","Age: 42 BMI: 26.125","Age: 20 BMI: 33.3","Age: 21 BMI: 31.02","Age: 25 BMI: 33.66","Age: 27 BMI: 31.255","Age: 64 BMI: 25.6","Age: 58 BMI: 34.39","Age: 18 BMI: 20.79","Age: 47 BMI: 19.57","Age: 26 BMI: 32.49","Age: 19 BMI: 30.59","Age: 18 BMI: 33.155","Age: 21 BMI: 34.87","Age: 31 BMI: 36.63","Age: 46 BMI: 25.745","Age: 55 BMI: 30.5","Age: 54 BMI: 32.68","Age: 36 BMI: 29.04","Age: 45 BMI: 30.9","Age: 28 BMI: 37.1","Age: 50 BMI: 23.54","Age: 19 BMI: 24.605","Age: 57 BMI: 43.7","Age: 25 BMI: 23.9","Age: 39 BMI: 45.43","Age: 57 BMI: 40.37","Age: 45 BMI: 35.3","Age: 48 BMI: 32.3","Age: 30 BMI: 22.895","Age: 28 BMI: 38.06","Age: 38 BMI: 27.835","Age: 53 BMI: 26.7","Age: 43 BMI: 32.6","Age: 26 BMI: 42.4","Age: 51 BMI: 32.3","Age: 52 BMI: 46.75","Age: 41 BMI: 37.1","Age: 21 BMI: 26.4","Age: 37 BMI: 46.53","Age: 60 BMI: 24.035","Age: 36 BMI: 31.5","Age: 57 BMI: 31.825","Age: 40 BMI: 33","Age: 27 BMI: 18.905","Age: 60 BMI: 36.005","Age: 58 BMI: 33.1","Age: 51 BMI: 35.97","Age: 21 BMI: 35.72","Age: 46 BMI: 48.07","Age: 52 BMI: 23.18","Age: 46 BMI: 26.62","Age: 63 BMI: 21.66","Age: 18 BMI: 53.13","Age: 42 BMI: 32.87","Age: 62 BMI: 32.965","Age: 18 BMI: 21.47","Age: 41 BMI: 34.2","Age: 18 BMI: 28.5","Age: 57 BMI: 23.98","Age: 40 BMI: 34.105","Age: 37 BMI: 29.5","Age: 32 BMI: 31.54","Age: 34 BMI: 37.335","Age: 51 BMI: 31.635","Age: 60 BMI: 25.74","Age: 59 BMI: 24.7","Age: 52 BMI: 31.73","Age: 37 BMI: 29.8","Age: 30 BMI: 27.7","Age: 40 BMI: 25.08","Age: 31 BMI: 25.8","Age: 37 BMI: 17.29","Age: 50 BMI: 32.11","Age: 29 BMI: 38.94","Age: 37 BMI: 30.8","Age: 31 BMI: 28.595","Age: 58 BMI: 36.48","Age: 21 BMI: 36.85","Age: 18 BMI: 28.215","Age: 29 BMI: 25.6","Age: 28 BMI: 37.62","Age: 26 BMI: 19.8","Age: 18 BMI: 31.35","Age: 55 BMI: 32.395","Age: 44 BMI: 25.365","Age: 25 BMI: 26.8","Age: 19 BMI: 31.825","Age: 63 BMI: 28.31","Age: 22 BMI: 27.1","Age: 62 BMI: 32.68","Age: 46 BMI: 19.95","Age: 18 BMI: 21.78","Age: 60 BMI: 28.9","Age: 28 BMI: 30.875","Age: 48 BMI: 29.6","Age: 50 BMI: 28.16","Age: 19 BMI: 34.1","Age: 41 BMI: 33.06","Age: 19 BMI: 28.9","Age: 20 BMI: 35.31","Age: 19 BMI: 19.8","Age: 28 BMI: 33","Age: 19 BMI: 39.615","Age: 60 BMI: 25.84","Age: 48 BMI: 41.23","Age: 59 BMI: 25.46","Age: 42 BMI: 41.325","Age: 21 BMI: 25.8","Age: 22 BMI: 21.28","Age: 62 BMI: 39.93","Age: 54 BMI: 31.6","Age: 54 BMI: 46.7","Age: 35 BMI: 43.34","Age: 30 BMI: 31.57","Age: 53 BMI: 30.495","Age: 36 BMI: 26.2","Age: 51 BMI: 20.6","Age: 18 BMI: 35.2","Age: 50 BMI: 30.115","Age: 22 BMI: 19.95","Age: 29 BMI: 28.975","Age: 22 BMI: 24.3","Age: 39 BMI: 34.1","Age: 29 BMI: 31.16","Age: 19 BMI: 17.8","Age: 54 BMI: 31.9","Age: 21 BMI: 17.4","Age: 27 BMI: 30.4","Age: 64 BMI: 37.905","Age: 27 BMI: 23.21","Age: 19 BMI: 25.555","Age: 53 BMI: 31.35","Age: 50 BMI: 46.09","Age: 24 BMI: 27.72","Age: 24 BMI: 22.6","Age: 28 BMI: 35.435","Age: 21 BMI: 32.68","Age: 27 BMI: 30.59","Age: 24 BMI: 28.5","Age: 22 BMI: 25.175","Age: 55 BMI: 32.775","Age: 59 BMI: 27.72","Age: 18 BMI: 38.28","Age: 45 BMI: 28.7","Age: 50 BMI: 25.6","Age: 48 BMI: 37.29","Age: 62 BMI: 25","Age: 40 BMI: 28.69","Age: 49 BMI: 31.9","Age: 33 BMI: 42.46","Age: 18 BMI: 40.185","Age: 53 BMI: 24.795","Age: 20 BMI: 30.115","Age: 58 BMI: 39.05","Age: 18 BMI: 38.17","Age: 59 BMI: 32.395","Age: 19 BMI: 20.425","Age: 35 BMI: 26.125","Age: 43 BMI: 35.72","Age: 32 BMI: 29.735","Age: 36 BMI: 27.55","Age: 20 BMI: 40.47","Age: 22 BMI: 28.82","Age: 34 BMI: 42.13","Age: 50 BMI: 30.97","Age: 56 BMI: 28.595","Age: 46 BMI: 22.3","Age: 45 BMI: 23.56","Age: 58 BMI: 36.08","Age: 59 BMI: 27.5","Age: 50 BMI: 44.77","Age: 55 BMI: 40.81","Age: 50 BMI: 27.075","Age: 18 BMI: 23.085","Age: 48 BMI: 36.575","Age: 58 BMI: 28.595","Age: 44 BMI: 27.4","Age: 21 BMI: 27.36","Age: 55 BMI: 32.775","Age: 49 BMI: 29.83","Age: 53 BMI: 29.48","Age: 31 BMI: 21.755","Age: 26 BMI: 29.45","Age: 56 BMI: 25.3","Age: 18 BMI: 37.29","Age: 32 BMI: 33.155","Age: 25 BMI: 24.3","Age: 49 BMI: 27.1","Age: 27 BMI: 32.585","Age: 60 BMI: 36.955","Age: 45 BMI: 27.645","Age: 41 BMI: 29.64","Age: 32 BMI: 20.52","Age: 18 BMI: 33.88","Age: 20 BMI: 37","Age: 43 BMI: 34.4","Age: 48 BMI: 40.15","Age: 49 BMI: 37.51","Age: 50 BMI: 25.3","Age: 38 BMI: 16.815","Age: 53 BMI: 24.32","Age: 45 BMI: 35.815","Age: 30 BMI: 44.22","Age: 18 BMI: 30.4","Age: 27 BMI: 23.1","Age: 32 BMI: 30.03","Age: 30 BMI: 21.945","Age: 29 BMI: 20.235","Age: 55 BMI: 28.975","Age: 46 BMI: 28.9","Age: 55 BMI: 27.645","Age: 43 BMI: 30.1","Age: 35 BMI: 35.86","Age: 54 BMI: 28.88","Age: 34 BMI: 22.42","Age: 58 BMI: 32.395","Age: 51 BMI: 36.385","Age: 57 BMI: 40.28","Age: 32 BMI: 23.65","Age: 21 BMI: 25.745","Age: 48 BMI: 27.36","Age: 63 BMI: 26.22","Age: 57 BMI: 18.335","Age: 59 BMI: 29.7","Age: 49 BMI: 27.17","Age: 22 BMI: 33.77","Age: 36 BMI: 30.875","Age: 42 BMI: 37.9","Age: 55 BMI: 37.3","Age: 59 BMI: 36.52","Age: 20 BMI: 33","Age: 44 BMI: 23.98","Age: 19 BMI: 25.175","Age: 29 BMI: 37.29","Age: 24 BMI: 25.27","Age: 32 BMI: 28.93","Age: 29 BMI: 24.6","Age: 44 BMI: 36.955","Age: 51 BMI: 37.73","Age: 40 BMI: 23.37","Age: 46 BMI: 27.74","Age: 18 BMI: 30.115","Age: 18 BMI: 15.96","Age: 19 BMI: 24.6","Age: 59 BMI: 26.4","Age: 56 BMI: 33.82","Age: 18 BMI: 26.315","Age: 51 BMI: 33.33","Age: 41 BMI: 32.965","Age: 64 BMI: 39.05","Age: 45 BMI: 20.35","Age: 60 BMI: 24.53","Age: 26 BMI: 29.92","Age: 25 BMI: 26.22","Age: 64 BMI: 38.19","Age: 27 BMI: 26.03","Age: 51 BMI: 25.8","Age: 26 BMI: 40.185","Age: 40 BMI: 26.315","Age: 18 BMI: 25.08","Age: 33 BMI: 24.605","Age: 44 BMI: 26.41","Age: 34 BMI: 32.8","Age: 19 BMI: 18.6","Age: 52 BMI: 33.3","Age: 45 BMI: 38.285","Age: 36 BMI: 19.855","Age: 49 BMI: 36.85","Age: 55 BMI: 33","Age: 33 BMI: 28.27","Age: 49 BMI: 21.3","Age: 19 BMI: 28.7","Age: 50 BMI: 28.12","Age: 30 BMI: 37.43","Age: 29 BMI: 32.11","Age: 31 BMI: 26.62","Age: 50 BMI: 32.205","Age: 46 BMI: 33.725","Age: 52 BMI: 38.6","Age: 36 BMI: 28.88","Age: 42 BMI: 24.985","Age: 48 BMI: 27.93","Age: 36 BMI: 30.02","Age: 24 BMI: 29.925","Age: 55 BMI: 21.5","Age: 27 BMI: 32.67","Age: 24 BMI: 27.6","Age: 24 BMI: 35.86","Age: 32 BMI: 37.335","Age: 49 BMI: 36.63","Age: 22 BMI: 34.58","Age: 39 BMI: 26.315","Age: 23 BMI: 28","Age: 35 BMI: 34.21","Age: 46 BMI: 30.2","Age: 31 BMI: 32.775","Age: 46 BMI: 43.89","Age: 26 BMI: 17.67","Age: 19 BMI: 30.4","Age: 29 BMI: 27.2","Age: 25 BMI: 30.3","Age: 52 BMI: 31.2","Age: 49 BMI: 28.7","Age: 50 BMI: 25.365","Age: 33 BMI: 27.455","Age: 61 BMI: 25.08","Age: 37 BMI: 36.19","Age: 39 BMI: 42.655","Age: 28 BMI: 26.315","Age: 56 BMI: 26.6","Age: 46 BMI: 27.72","Age: 58 BMI: 41.91","Age: 57 BMI: 23.7","Age: 58 BMI: 29","Age: 55 BMI: 35.245","Age: 33 BMI: 39.82","Age: 59 BMI: 32.1","Age: 64 BMI: 31.825","Age: 29 BMI: 31.73","Age: 49 BMI: 28.69","Age: 54 BMI: 25.46","Age: 19 BMI: 30.59","Age: 51 BMI: 18.05","Age: 62 BMI: 32.11","Age: 34 BMI: 27.72","Age: 19 BMI: 22.515","Age: 19 BMI: 36.575","Age: 39 BMI: 32.5","Age: 50 BMI: 32.3","Age: 28 BMI: 23.8","Age: 32 BMI: 44.22","Age: 21 BMI: 22.135","Age: 19 BMI: 21.755","Age: 32 BMI: 29.8","Age: 43 BMI: 25.08","Age: 25 BMI: 42.13","Age: 46 BMI: 39.425","Age: 45 BMI: 33.1","Age: 53 BMI: 41.47","Age: 38 BMI: 27.6","Age: 60 BMI: 38.06","Age: 23 BMI: 34.96","Age: 62 BMI: 38.83","Age: 38 BMI: 19.95","Age: 49 BMI: 30.3","Age: 44 BMI: 37.1","Age: 56 BMI: 35.8","Age: 56 BMI: 27.2","Age: 51 BMI: 27.74","Age: 43 BMI: 27.36","Age: 61 BMI: 32.3","Age: 19 BMI: 32.11","Age: 44 BMI: 30.69","Age: 51 BMI: 33.915","Age: 43 BMI: 23.2","Age: 61 BMI: 22.04","Age: 35 BMI: 39.71","Age: 60 BMI: 28.595","Age: 31 BMI: 31.065","Age: 18 BMI: 23.32","Age: 30 BMI: 43.12","Age: 44 BMI: 22.135","Age: 54 BMI: 32.3","Age: 28 BMI: 26.51","Age: 34 BMI: 21.375","Age: 36 BMI: 33.82","Age: 46 BMI: 33.44","Age: 38 BMI: 28.93","Age: 50 BMI: 27.83","Age: 41 BMI: 31.02","Age: 29 BMI: 35.53","Age: 54 BMI: 31.24","Age: 63 BMI: 23.085","Age: 62 BMI: 30.495","Age: 28 BMI: 33.82","Age: 50 BMI: 27.36","Age: 20 BMI: 31.46","Age: 63 BMI: 30.8","Age: 40 BMI: 27.4","Age: 62 BMI: 29.92","Age: 30 BMI: 28.405","Age: 35 BMI: 30.5","Age: 47 BMI: 26.6","Age: 23 BMI: 26.51","Age: 55 BMI: 26.8","Age: 32 BMI: 30.8","Age: 20 BMI: 29.6","Age: 20 BMI: 28.785","Age: 36 BMI: 29.7","Age: 32 BMI: 46.53","Age: 35 BMI: 17.86","Age: 50 BMI: 33.7","Age: 45 BMI: 33.7","Age: 19 BMI: 27.265","Age: 56 BMI: 22.1","Age: 50 BMI: 27.455","Age: 61 BMI: 31.16","Age: 54 BMI: 21.01","Age: 33 BMI: 42.94","Age: 23 BMI: 39.27","Age: 63 BMI: 36.85","Age: 47 BMI: 33.915","Age: 25 BMI: 34.485","Age: 54 BMI: 29.2","Age: 21 BMI: 26.03","Age: 23 BMI: 34.865","Age: 61 BMI: 35.91","Age: 44 BMI: 39.52","Age: 27 BMI: 45.9","Age: 29 BMI: 32.11","Age: 50 BMI: 44.745","Age: 18 BMI: 38.665","Age: 20 BMI: 29.735","Age: 23 BMI: 35.2","Age: 62 BMI: 31.73","Age: 48 BMI: 32.3","Age: 58 BMI: 49.06","Age: 48 BMI: 30.2","Age: 41 BMI: 28.05","Age: 18 BMI: 39.16","Age: 43 BMI: 30.685","Age: 20 BMI: 31.13","Age: 19 BMI: 28.4","Age: 55 BMI: 29.83","Age: 26 BMI: 22.61","Age: 32 BMI: 37.145","Age: 55 BMI: 29.7","Age: 29 BMI: 22.515","Age: 38 BMI: 34.8","Age: 18 BMI: 32.12","Age: 30 BMI: 27.645","Age: 45 BMI: 27.5","Age: 59 BMI: 31.79","Age: 55 BMI: 26.98","Age: 40 BMI: 35.3","Age: 24 BMI: 33.345","Age: 35 BMI: 34.77","Age: 57 BMI: 34.295","Age: 42 BMI: 29.48","Age: 43 BMI: 25.52","Age: 44 BMI: 25.8","Age: 27 BMI: 32.395","Age: 33 BMI: 22.705","Age: 45 BMI: 24.31","Age: 58 BMI: 32.965","Age: 58 BMI: 38","Age: 41 BMI: 21.755","Age: 62 BMI: 21.4","Age: 59 BMI: 25.46","Age: 44 BMI: 29.81","Age: 19 BMI: 28.4","Age: 56 BMI: 36.1","Age: 33 BMI: 36.29","Age: 51 BMI: 37","Age: 19 BMI: 35.4","Age: 58 BMI: 28.215","Age: 62 BMI: 27.55","Age: 39 BMI: 22.8","Age: 45 BMI: 25.175","Age: 24 BMI: 30.1","Age: 52 BMI: 32.775","Age: 46 BMI: 25.8","Age: 21 BMI: 20.235","Age: 40 BMI: 24.97","Age: 56 BMI: 25.65","Age: 64 BMI: 32.965","Age: 19 BMI: 30.59","Age: 47 BMI: 36.2","Age: 19 BMI: 32.9","Age: 59 BMI: 31.35","Age: 39 BMI: 41.8","Age: 54 BMI: 30.02","Age: 18 BMI: 25.46","Age: 54 BMI: 30.21","Age: 47 BMI: 33.345","Age: 21 BMI: 23.21","Age: 19 BMI: 23.4","Age: 64 BMI: 40.48","Age: 18 BMI: 41.14","Age: 19 BMI: 34.4","Age: 20 BMI: 33.33","Age: 48 BMI: 34.3","Age: 59 BMI: 37.1","Age: 55 BMI: 37.1","Age: 53 BMI: 36.1","Age: 59 BMI: 26.695","Age: 46 BMI: 27.6","Age: 34 BMI: 27.5","Age: 35 BMI: 34.8","Age: 44 BMI: 29.735","Age: 51 BMI: 40.66","Age: 25 BMI: 26.695","Age: 26 BMI: 23.7","Age: 48 BMI: 35.91","Age: 21 BMI: 36.86","Age: 18 BMI: 29.37","Age: 33 BMI: 42.4","Age: 56 BMI: 39.82","Age: 58 BMI: 27.17","Age: 44 BMI: 34.32","Age: 61 BMI: 39.1","Age: 30 BMI: 32.4","Age: 19 BMI: 25.745","Age: 39 BMI: 32.34","Age: 54 BMI: 31.9","Age: 23 BMI: 41.91","Age: 33 BMI: 29.4","Age: 56 BMI: 32.11","Age: 27 BMI: 34.8","Age: 34 BMI: 38","Age: 54 BMI: 35.815","Age: 18 BMI: 26.73","Age: 39 BMI: 24.225","Age: 28 BMI: 23.845","Age: 41 BMI: 34.21","Age: 52 BMI: 37.525","Age: 25 BMI: 24.985","Age: 23 BMI: 23.18","Age: 47 BMI: 29.37","Age: 60 BMI: 28.7","Age: 53 BMI: 31.16","Age: 52 BMI: 44.7","Age: 49 BMI: 31.35","Age: 21 BMI: 22.3","Age: 48 BMI: 32.23","Age: 63 BMI: 41.47","Age: 52 BMI: 37.4","Age: 19 BMI: 27.6","Age: 21 BMI: 39.49","Age: 20 BMI: 27.93","Age: 36 BMI: 25.84","Age: 42 BMI: 31.255","Age: 43 BMI: 30.115","Age: 47 BMI: 47.52","Age: 22 BMI: 28.88","Age: 56 BMI: 40.3","Age: 32 BMI: 29.59","Age: 52 BMI: 30.2","Age: 42 BMI: 25.3","Age: 30 BMI: 25.46","Age: 33 BMI: 22.135","Age: 46 BMI: 19.855","Age: 18 BMI: 31.92","Age: 21 BMI: 35.53","Age: 19 BMI: 24.7","Age: 30 BMI: 33.33","Age: 63 BMI: 25.08","Age: 61 BMI: 43.4","Age: 22 BMI: 28.05","Age: 38 BMI: 27.835","Age: 31 BMI: 32.68","Age: 41 BMI: 28.31","Age: 23 BMI: 50.38","Age: 18 BMI: 23.21","Age: 20 BMI: 33","Age: 53 BMI: 36.6","Age: 33 BMI: 24.31","Age: 32 BMI: 37.18","Age: 56 BMI: 39.6","Age: 60 BMI: 24.32","Age: 24 BMI: 39.49","Age: 37 BMI: 24.32","Age: 41 BMI: 40.26","Age: 20 BMI: 31.92","Age: 26 BMI: 28.785","Age: 42 BMI: 26.9","Age: 54 BMI: 27.645","Age: 51 BMI: 36.67","Age: 44 BMI: 27.645","Age: 24 BMI: 32.01","Age: 28 BMI: 33.11","Age: 39 BMI: 32.8","Age: 53 BMI: 21.4","Age: 45 BMI: 28.6","Age: 23 BMI: 24.225"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","opacity":0.9,"name":"no","marker":{"color":"rgba(204,70,120,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","symbol":"x","line":{"color":"rgba(204,70,120,1)"}},"textfont":{"color":"rgba(204,70,120,1)","size":55},"error_y":{"color":"rgba(204,70,120,1)","width":55},"error_x":{"color":"rgba(204,70,120,1)","width":55},"line":{"color":"rgba(204,70,120,1)","width":55},"frame":null},{"x":[19,27,39,43,37,30,40,42,45,59,23,34,35,23,64,25,37,30,43,33,29,49,42,63,53,21,56,32,34,56,44,45,24,22,48,33,60,29,18,60,30,36,26,25,41,37,49,18,20,39,18,18,43,19,59,43,61,47,26,23,40,44,45,27,43,18,20,53,19,36,36,47,43,31,18,32,49,22,40,42,23,61,42,50,51,52,19,47,20,19,37,48,57,19,64,64,60,19,25,19,29,59,35,48,64,36,19,55,63,19,28,28,29,22,57,51,51,18,36,62,43,38,20,19,61,51,63,43,31,31,19,54,56,42,22,30,34,32,33,20,44,32,61,33,27,50,27,19,35,37,27,53,37,54,46,18,19,20,54,30,61,33,52,34,25,28,39,30,37,58,22,38,30,60,27,51,45,64,23,41,37,64,19,52,46,20,27,46,43,35,46,24,19,60,59,29,24,47,54,44,39,52,62,24,19,25,51,57,47,40,47,43,47,46,42,26,55,29,33,49,39],"z":[-319.880800964987,-422.876914522341,1464.65642520123,2952.79764959174,-1841.49872798439,-94.7727833355311,-299.779009742364,17083.7537208725,-723.308713296363,379.389766806744,-2928.02601050643,-1057.00345061228,354.101870873466,-4357.76251948244,-219.125635318487,5807.82322643926,-10.7781718896549,-473.454628842115,-950.220586254931,-398.408296019661,-2396.4859410337,-581.640197718538,1991.83921976845,1826.68785701192,1667.56190897525,-3186.13069745724,1602.56094684114,-1080.84334878805,6018.37465808857,611.020601606935,2715.21666308736,-1875.6778995986,-207.127155821116,-2736.82391306815,-544.438912389625,-1491.87031477634,1918.31539326369,-2930.50595458806,3638.22379720755,-381.176010287534,469.777782034605,-696.68401608651,-1174.49109142209,-1374.73020516637,-529.396065055756,2025.27350929275,-180.614599674787,-4728.1530044997,-5879.85075431352,44.7147752340679,360.338815476973,158.518015402151,-1521.45190184959,2427.17726923989,2352.43176492196,-936.590515372118,1245.46347152894,-1098.18738215714,-2829.47316474521,-2256.35164186746,-992.977804269951,-1493.19346561651,12691.7031427803,267.950423440077,-1173.6441694029,-2793.9678728431,1165.31990625164,-1309.78511765488,279.471094687549,-379.05875299708,-227.231017370417,-1222.54993436765,-1560.46994267853,205.420560197635,-1919.61610107838,210.15767064711,-258.276875161224,-3797.00950644836,420.480473706655,-2264.82780512369,-129.536488991987,1219.16538376179,-520.600889579553,1863.62997532023,-611.009398971153,-1333.48640723313,2512.52629620274,965.466064102944,4125.48220271586,2957.49779606815,-384.125765152068,-1758.26893555812,2468.31554807148,-1591.09160121848,3298.15927563215,2435.71112760648,2286.48774344494,-146.738078793751,-546.303755082394,-403.125242371691,-456.950699314526,-1511.98548416061,-463.141249031622,-1599.4333197645,3779.5193143957,200.667124594005,1523.35290548704,1537.84076216353,3004.47166329277,7504.99195388329,13202.4993035676,222.391553809459,6436.89853316117,685.575957174733,-322.966292709381,794.462781108727,-839.299856672467,308.321185104913,383.807239876071,-341.87686711612,-849.19384563337,679.246713421293,8675.13393729246,-1290.94269251033,1755.76226396374,1343.65995328132,1432.76789989798,13490.4715117707,585.614681581621,-873.371091266454,-1553.19197871182,-92.1941827167357,888.509078243547,1002.06789793666,2631.10808805311,5.2051272360186,-919.036840345972,12572.148005804,16164.4373057932,-2198.39963708742,-1321.89863046704,-1524.95510708792,1577.06641615783,-1613.08723782219,-2573.20879232339,220.720038725041,-4494.88366361306,750.47692843241,-1898.37311151707,-934.559549213285,91.9248724270728,2335.6981464192,-1705.36303110518,438.223960654657,1885.88167612113,1058.9146946633,685.432798368463,-547.79966459517,6.55164207988855,440.500260509129,-1597.00480849715,-1862.80910966906,-1580.27925120793,-1524.38369751166,96.455518285351,-1596.25328227523,-44.1634502730631,-328.931332922322,-778.243927683594,2916.61112965149,3223.27972355834,-1294.3040090149,-1182.59680042892,2213.64276654823,-1743.71560105481,1763.28050078049,21802.9592671656,1528.03542126736,-3455.37395998298,-650.217633603526,-1084.68086782698,-9.63559037935192,-1075.54861025872,-1146.92030660639,-572.92500635334,-2877.85554016219,2881.54678076464,-1519.17972886895,-879.735885173439,-550.911219109457,-1141.96598379641,-2811.8333664057,2378.13826923988,6575.72116023416,1315.86487128848,-2678.83940481713,4203.43579633217,-1325.70401341199,1547.70074674443,5927.68288597985,-2224.42184715726,-276.423208756845,1559.12800917884,-177.549832073964,-889.040713196298,-1632.15277811851,3189.48539062598,1203.47969568669,-1040.6743893371,-923.628506238616,-2370.37450807389,-1857.01510045808,-661.065197221578,1016.44653285496,-421.969699818044,157.82810981154,1087.5364464411,-420.811589931916,-2517.65584536554,208.643756821297,-642.045386181522],"y":[28.88,31.13,35.3,46.2,30.78,28.38,32.775,26.07,36.48,23.655,28.31,25.3,28.025,36.67,22.99,45.54,26.4,24.4,38.06,33.5,21.85,23.845,40.37,37.7,34.105,21.85,26.695,24.6,30.21,31.79,43.89,30.495,31.065,30.4,33.11,35.75,40.92,21.755,42.24,32.45,28.69,41.895,32.9,29.7,30.78,34.8,25.6,17.29,35.625,26.41,25.175,31.73,26.885,34.9,41.14,35.97,36.385,36.08,17.195,32.78,19.8,31.35,22.895,29.15,34.96,27.28,39.4,22.88,27.7,34.43,35.2,27.645,20.045,34.39,36.85,28.93,30.9,31.02,28.12,30,42.75,29.07,23.37,34.2,24.795,24.13,36.955,28.215,21.8,31.92,25.555,24.42,31.16,30.02,31.3,36.96,31.35,32.49,30.2,28.31,27.94,29.83,27.74,28,33.8,28.025,30.25,35.2,32.2,44.88,36.4,31.68,35.5,37.07,29.81,34.96,23.21,31.68,33.4,26.29,26.7,38.39,24.42,34.7,36.3,37.05,35.09,27.8,25.9,29.81,33.11,25.1,19.95,26.6,37.62,35.3,30.8,17.765,35.53,26.84,38.95,33.63,28.31,24.795,31.4,31.825,17.955,29.07,36.67,37.07,36.08,36.86,34.1,34.21,42.35,38.17,26.03,27.3,30.8,39.05,29.92,27.1,25.3,31.92,33.33,23.98,24.89,37.8,34.2,36.955,35.6,19.3,35.53,39.9,24.75,38.06,30.36,26.885,31.73,35.75,38.39,23.76,27.9,24.32,30.495,22.42,42.13,23.655,32.56,24.42,35.53,20.52,34.8,32.8,36.765,22.895,40.15,27.83,40.565,38.06,29.925,27.36,32.015,32.7,21.7,24.13,42.9,28.975,26.125,22.22,29.8,20.13,36.63,34.6,24.605,27.06,30.685,34.4,19.095,25.84,18.3],"text":["Age: 19 BMI: 28.88","Age: 27 BMI: 31.13","Age: 39 BMI: 35.3","Age: 43 BMI: 46.2","Age: 37 BMI: 30.78","Age: 30 BMI: 28.38","Age: 40 BMI: 32.775","Age: 42 BMI: 26.07","Age: 45 BMI: 36.48","Age: 59 BMI: 23.655","Age: 23 BMI: 28.31","Age: 34 BMI: 25.3","Age: 35 BMI: 28.025","Age: 23 BMI: 36.67","Age: 64 BMI: 22.99","Age: 25 BMI: 45.54","Age: 37 BMI: 26.4","Age: 30 BMI: 24.4","Age: 43 BMI: 38.06","Age: 33 BMI: 33.5","Age: 29 BMI: 21.85","Age: 49 BMI: 23.845","Age: 42 BMI: 40.37","Age: 63 BMI: 37.7","Age: 53 BMI: 34.105","Age: 21 BMI: 21.85","Age: 56 BMI: 26.695","Age: 32 BMI: 24.6","Age: 34 BMI: 30.21","Age: 56 BMI: 31.79","Age: 44 BMI: 43.89","Age: 45 BMI: 30.495","Age: 24 BMI: 31.065","Age: 22 BMI: 30.4","Age: 48 BMI: 33.11","Age: 33 BMI: 35.75","Age: 60 BMI: 40.92","Age: 29 BMI: 21.755","Age: 18 BMI: 42.24","Age: 60 BMI: 32.45","Age: 30 BMI: 28.69","Age: 36 BMI: 41.895","Age: 26 BMI: 32.9","Age: 25 BMI: 29.7","Age: 41 BMI: 30.78","Age: 37 BMI: 34.8","Age: 49 BMI: 25.6","Age: 18 BMI: 17.29","Age: 20 BMI: 35.625","Age: 39 BMI: 26.41","Age: 18 BMI: 25.175","Age: 18 BMI: 31.73","Age: 43 BMI: 26.885","Age: 19 BMI: 34.9","Age: 59 BMI: 41.14","Age: 43 BMI: 35.97","Age: 61 BMI: 36.385","Age: 47 BMI: 36.08","Age: 26 BMI: 17.195","Age: 23 BMI: 32.78","Age: 40 BMI: 19.8","Age: 44 BMI: 31.35","Age: 45 BMI: 22.895","Age: 27 BMI: 29.15","Age: 43 BMI: 34.96","Age: 18 BMI: 27.28","Age: 20 BMI: 39.4","Age: 53 BMI: 22.88","Age: 19 BMI: 27.7","Age: 36 BMI: 34.43","Age: 36 BMI: 35.2","Age: 47 BMI: 27.645","Age: 43 BMI: 20.045","Age: 31 BMI: 34.39","Age: 18 BMI: 36.85","Age: 32 BMI: 28.93","Age: 49 BMI: 30.9","Age: 22 BMI: 31.02","Age: 40 BMI: 28.12","Age: 42 BMI: 30","Age: 23 BMI: 42.75","Age: 61 BMI: 29.07","Age: 42 BMI: 23.37","Age: 50 BMI: 34.2","Age: 51 BMI: 24.795","Age: 52 BMI: 24.13","Age: 19 BMI: 36.955","Age: 47 BMI: 28.215","Age: 20 BMI: 21.8","Age: 19 BMI: 31.92","Age: 37 BMI: 25.555","Age: 48 BMI: 24.42","Age: 57 BMI: 31.16","Age: 19 BMI: 30.02","Age: 64 BMI: 31.3","Age: 64 BMI: 36.96","Age: 60 BMI: 31.35","Age: 19 BMI: 32.49","Age: 25 BMI: 30.2","Age: 19 BMI: 28.31","Age: 29 BMI: 27.94","Age: 59 BMI: 29.83","Age: 35 BMI: 27.74","Age: 48 BMI: 28","Age: 64 BMI: 33.8","Age: 36 BMI: 28.025","Age: 19 BMI: 30.25","Age: 55 BMI: 35.2","Age: 63 BMI: 32.2","Age: 19 BMI: 44.88","Age: 28 BMI: 36.4","Age: 28 BMI: 31.68","Age: 29 BMI: 35.5","Age: 22 BMI: 37.07","Age: 57 BMI: 29.81","Age: 51 BMI: 34.96","Age: 51 BMI: 23.21","Age: 18 BMI: 31.68","Age: 36 BMI: 33.4","Age: 62 BMI: 26.29","Age: 43 BMI: 26.7","Age: 38 BMI: 38.39","Age: 20 BMI: 24.42","Age: 19 BMI: 34.7","Age: 61 BMI: 36.3","Age: 51 BMI: 37.05","Age: 63 BMI: 35.09","Age: 43 BMI: 27.8","Age: 31 BMI: 25.9","Age: 31 BMI: 29.81","Age: 19 BMI: 33.11","Age: 54 BMI: 25.1","Age: 56 BMI: 19.95","Age: 42 BMI: 26.6","Age: 22 BMI: 37.62","Age: 30 BMI: 35.3","Age: 34 BMI: 30.8","Age: 32 BMI: 17.765","Age: 33 BMI: 35.53","Age: 20 BMI: 26.84","Age: 44 BMI: 38.95","Age: 32 BMI: 33.63","Age: 61 BMI: 28.31","Age: 33 BMI: 24.795","Age: 27 BMI: 31.4","Age: 50 BMI: 31.825","Age: 27 BMI: 17.955","Age: 19 BMI: 29.07","Age: 35 BMI: 36.67","Age: 37 BMI: 37.07","Age: 27 BMI: 36.08","Age: 53 BMI: 36.86","Age: 37 BMI: 34.1","Age: 54 BMI: 34.21","Age: 46 BMI: 42.35","Age: 18 BMI: 38.17","Age: 19 BMI: 26.03","Age: 20 BMI: 27.3","Age: 54 BMI: 30.8","Age: 30 BMI: 39.05","Age: 61 BMI: 29.92","Age: 33 BMI: 27.1","Age: 52 BMI: 25.3","Age: 34 BMI: 31.92","Age: 25 BMI: 33.33","Age: 28 BMI: 23.98","Age: 39 BMI: 24.89","Age: 30 BMI: 37.8","Age: 37 BMI: 34.2","Age: 58 BMI: 36.955","Age: 22 BMI: 35.6","Age: 38 BMI: 19.3","Age: 30 BMI: 35.53","Age: 60 BMI: 39.9","Age: 27 BMI: 24.75","Age: 51 BMI: 38.06","Age: 45 BMI: 30.36","Age: 64 BMI: 26.885","Age: 23 BMI: 31.73","Age: 41 BMI: 35.75","Age: 37 BMI: 38.39","Age: 64 BMI: 23.76","Age: 19 BMI: 27.9","Age: 52 BMI: 24.32","Age: 46 BMI: 30.495","Age: 20 BMI: 22.42","Age: 27 BMI: 42.13","Age: 46 BMI: 23.655","Age: 43 BMI: 32.56","Age: 35 BMI: 24.42","Age: 46 BMI: 35.53","Age: 24 BMI: 20.52","Age: 19 BMI: 34.8","Age: 60 BMI: 32.8","Age: 59 BMI: 36.765","Age: 29 BMI: 22.895","Age: 24 BMI: 40.15","Age: 47 BMI: 27.83","Age: 54 BMI: 40.565","Age: 44 BMI: 38.06","Age: 39 BMI: 29.925","Age: 52 BMI: 27.36","Age: 62 BMI: 32.015","Age: 24 BMI: 32.7","Age: 19 BMI: 21.7","Age: 25 BMI: 24.13","Age: 51 BMI: 42.9","Age: 57 BMI: 28.975","Age: 47 BMI: 26.125","Age: 40 BMI: 22.22","Age: 47 BMI: 29.8","Age: 43 BMI: 20.13","Age: 47 BMI: 36.63","Age: 46 BMI: 34.6","Age: 42 BMI: 24.605","Age: 26 BMI: 27.06","Age: 55 BMI: 30.685","Age: 29 BMI: 34.4","Age: 33 BMI: 19.095","Age: 49 BMI: 25.84","Age: 39 BMI: 18.3"],"hoverinfo":["text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text","text"],"type":"scatter3d","mode":"markers","opacity":0.9,"name":"yes","marker":{"color":"rgba(13,8,135,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","symbol":"circle","line":{"color":"rgba(13,8,135,1)"}},"textfont":{"color":"rgba(13,8,135,1)","size":55},"error_y":{"color":"rgba(13,8,135,1)","width":55},"error_x":{"color":"rgba(13,8,135,1)","width":55},"line":{"color":"rgba(13,8,135,1)","width":55},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>For the train residuals no clear pattern in the residuals is visible. Looking at the test residuals one can see where the model has the most difficulties. Interesting enough the model has the biggest outliers with non smokers of either quite low or quite high age with a more or less not that extreme BMI. This could be due to chronic diseases especially for the younger ones but also some randomness that life holds. For example a car accident could cause such high charges. Of course it could be also due to not observed latent variables.</p>
<p>Which model performed the best on the test data set is the next interesting question. The results can be viewed below in tabular and graphical form.</p>
<table>
<caption><span id="tab:perfIns">Table 5.2: </span>Performance on the test data</caption>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="right">mae</th>
<th align="right">rmse</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">boost_pred</td>
<td align="right">0.0849</td>
<td align="right">0.1581</td>
</tr>
<tr class="even">
<td align="left">rf_pred</td>
<td align="right">0.0820</td>
<td align="right">0.1586</td>
</tr>
<tr class="odd">
<td align="left">baseline_lm</td>
<td align="right">0.1171</td>
<td align="right">0.1877</td>
</tr>
<tr class="even">
<td align="left">intercept_pred</td>
<td align="right">0.3227</td>
<td align="right">0.4012</td>
</tr>
</tbody>
</table>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
<p>Once without the intercept only model.</p>
<p><img src="boosting_methods_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>So overall the XGBoost model again delivered the best performance on the test data set w.r.t. the main optimization metric RMSE. The baseline linear model that takes all features without interactions into account also goes a long way and the performance w.r.t. the RMSE metric is even comparable to the tree-based models. So again the data did not leave much room to explore more complex non-linear patterns. Whether the rather small difference in performance is worth considering such a model is of course up to the use case. Again the XGBoost model displayed that it reaches a very competitive performance with minimal pre-processing, integrated feature selection and in this case the computational effort was quite small. The major pros and cons of the tree-based gradient boosting models will be shortly reviewed in the next and final section.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-HandsOnMLwithR" class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline"><span class="smallcaps">Boehmke</span>, B. and <span class="smallcaps">Greenwell</span>, B. (2019). <em>Hands-on machine learning with r</em>.</div>
</div>
<div id="ref-xgboost_package" class="csl-entry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline"><span class="smallcaps">Chen</span>, T., <span class="smallcaps">He</span>, T., <span class="smallcaps">Benesty</span>, M., <span class="smallcaps">Khotilovich</span>, V., <span class="smallcaps">Tang</span>, Y., <span class="smallcaps">Cho</span>, H., <span class="smallcaps">Chen</span>, K., <span class="smallcaps">Mitchell</span>, R., <span class="smallcaps">Cano</span>, I., <span class="smallcaps">Zhou</span>, T., <span class="smallcaps">Li</span>, M., <span class="smallcaps">Xie</span>, J., <span class="smallcaps">Lin</span>, M., <span class="smallcaps">Geng</span>, Y. and <span class="smallcaps">Li</span>, Y. (2021). <em>Xgboost: Extreme gradient boosting</em>.</div>
</div>
<div id="ref-ranger_package" class="csl-entry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline"><span class="smallcaps">Wright</span>, M. N. and <span class="smallcaps">Ziegler</span>, A. (2017). <span class="nocase">ranger</span>: A fast implementation of random forests for high dimensional data in <span>C++</span> and <span>R</span>. <em>Journal of Statistical Software</em> <strong>77</strong> 1–7.</div>
</div>
<div id="ref-vipPack" class="csl-entry">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline"><span class="smallcaps">Greenwell</span>, B. M. and <span class="smallcaps">Boehmke</span>, B. C. (2020). Variable importance plots—an introduction to the vip package. <em>The R Journal</em> <strong>12</strong> 343–66.</div>
</div>
<div id="ref-doParallel_package" class="csl-entry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline"><span class="smallcaps">Corporation</span>, M. and <span class="smallcaps">Weston</span>, S. (2019). <em>doParallel: Foreach parallel adaptor for the ’parallel’ package</em>.</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="eda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conclusion.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["boosting_methods.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
